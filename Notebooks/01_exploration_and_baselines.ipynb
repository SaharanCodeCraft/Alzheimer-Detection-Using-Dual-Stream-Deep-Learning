{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fd1bae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                path label     subject\n",
      "0  C:\\Users\\ADMIN\\Documents\\Alz_work\\DATASET\\FINA...    AD  002_S_0619\n",
      "1  C:\\Users\\ADMIN\\Documents\\Alz_work\\DATASET\\FINA...    AD  002_S_0619\n",
      "2  C:\\Users\\ADMIN\\Documents\\Alz_work\\DATASET\\FINA...    AD  002_S_0619\n",
      "3  C:\\Users\\ADMIN\\Documents\\Alz_work\\DATASET\\FINA...    AD  002_S_0619\n",
      "4  C:\\Users\\ADMIN\\Documents\\Alz_work\\DATASET\\FINA...    AD  002_S_0619\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_path = r\"C:\\Users\\ADMIN\\Documents\\Alz_work\\DATASET\\FINAL_BALANCED_DATASET\\FINAL_BALANCED_DATASET\"\n",
    "classes = ['AD', 'CN', 'LMCI']\n",
    "data = []\n",
    "\n",
    "for label in classes:\n",
    "    class_path = os.path.join(base_path, label)\n",
    "    for subject in os.listdir(class_path):\n",
    "        subject_path = os.path.join(class_path, subject, 'sagittal_slices')\n",
    "        if os.path.isdir(subject_path):\n",
    "            slices = sorted(os.listdir(subject_path))\n",
    "            for slice_file in slices:\n",
    "                full_path = os.path.join(subject_path, slice_file)\n",
    "                data.append({'path': full_path, 'label': label, 'subject': subject})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3ca637d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ADMIN\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\ADMIN/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 528M/528M [00:05<00:00, 105MB/s]  \n",
      "c:\\Users\\ADMIN\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Load models\n",
    "vgg = models.vgg16(pretrained=True).features.eval()\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "resnet = torch.nn.Sequential(*list(resnet.children())[:-1])  # Remove classifier\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vgg.to(device)\n",
    "resnet.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd515171",
   "metadata": {},
   "source": [
    "Preprocessing Pipeline for CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1cbddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Define preprocessing pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),                    # Resize to match CNN input\n",
    "    transforms.Grayscale(num_output_channels=3),      # Convert grayscale to RGB\n",
    "    transforms.ToTensor(),                            # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],   # ImageNet mean\n",
    "                         std=[0.229, 0.224, 0.225])    # ImageNet std\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46b91f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "img_path = r\"C:\\Users\\ADMIN\\Documents\\Alz_work\\DATASET\\FINAL_BALANCED_DATASET\\FINAL_BALANCED_DATASET\\AD\\002_S_0619\\sagittal_slices\\sagittal_000.png\"\n",
    "img = Image.open(img_path).convert('L')  # Load as grayscale\n",
    "tensor = transform(img)\n",
    "print(tensor.shape)  # Should be [3, 224, 224]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424db0de",
   "metadata": {},
   "source": [
    "Feature Extraction Function (VGG16 + ResNet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "039a8742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(img_path, vgg_model, resnet_model, transform, device):\n",
    "    try:\n",
    "        # Load and preprocess image\n",
    "        img = Image.open(img_path).convert('L')  # Grayscale\n",
    "        img = transform(img).unsqueeze(0).to(device)  # Add batch dimension\n",
    "\n",
    "        # Extract features\n",
    "        with torch.no_grad():\n",
    "            vgg_feat = vgg_model(img).view(-1)       # Flatten VGG output\n",
    "            resnet_feat = resnet_model(img).view(-1)  # Flatten ResNet output\n",
    "\n",
    "        # Concatenate features\n",
    "        combined_feat = torch.cat((vgg_feat, resnet_feat)).cpu().numpy()\n",
    "        return combined_feat\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ffd55b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ADMIN\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\ADMIN\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load VGG16 (feature extractor only)\n",
    "vgg16 = models.vgg16(pretrained=True).features\n",
    "vgg16.eval().to(device)\n",
    "\n",
    "# Load ResNet50 (remove final FC layer)\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "resnet50 = torch.nn.Sequential(*list(resnet50.children())[:-1])  # Remove classifier\n",
    "resnet50.eval().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86c9bc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27136,)\n"
     ]
    }
   ],
   "source": [
    "feat = extract_features(img_path, vgg16, resnet50, transform, device)\n",
    "print(feat.shape)  # Should be something like (51200,) depending on model output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4da549",
   "metadata": {},
   "source": [
    "Subject-Level Feature Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cca9344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def process_subject(subject_path, vgg_model, resnet_model, transform, device):\n",
    "    # Check for nested 'sagittal_slices' folder\n",
    "    slice_dir = os.path.join(subject_path, 'sagittal_slices')\n",
    "    if os.path.exists(slice_dir):\n",
    "        slice_files = sorted(os.listdir(slice_dir))\n",
    "    else:\n",
    "        # Fallback: assume slices are directly in subject_path\n",
    "        slice_dir = subject_path\n",
    "        slice_files = sorted([f for f in os.listdir(slice_dir) if f.endswith('.png')])\n",
    "\n",
    "    if len(slice_files) == 0:\n",
    "        print(f\"No slices found in: {slice_dir}\")\n",
    "        return None\n",
    "\n",
    "    features = []\n",
    "    for slice_file in slice_files:\n",
    "        slice_path = os.path.join(slice_dir, slice_file)\n",
    "        feat = extract_features(slice_path, vgg_model, resnet_model, transform, device)\n",
    "        if feat is not None:\n",
    "            features.append(feat)\n",
    "\n",
    "    if features:\n",
    "        subject_vector = np.mean(features, axis=0)\n",
    "        return subject_vector\n",
    "    else:\n",
    "        print(f\"All slices failed for: {subject_path}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f926b4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27136,)\n"
     ]
    }
   ],
   "source": [
    "subject_path = r\"C:\\Users\\ADMIN\\Documents\\Alz_work\\DATASET\\FINAL_BALANCED_DATASET\\FINAL_BALANCED_DATASET\\AD\\002_S_0619\"\n",
    "subject_feat = process_subject(subject_path, vgg16, resnet50, transform, device)\n",
    "print(subject_feat.shape)  # Should be (27136,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4a3f15",
   "metadata": {},
   "source": [
    "Dataset-Wide Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "432cb46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def build_feature_matrix(base_path, vgg_model, resnet_model, transform, device):\n",
    "    classes = ['AD', 'CN', 'LMCI']\n",
    "    data = []\n",
    "\n",
    "    for label in classes:\n",
    "        class_path = os.path.join(base_path, label)\n",
    "        subjects = sorted(os.listdir(class_path))\n",
    "\n",
    "        for subject in subjects:\n",
    "            subject_path = os.path.join(class_path, subject)\n",
    "            feat = process_subject(subject_path, vgg_model, resnet_model, transform, device)\n",
    "\n",
    "            if feat is not None:\n",
    "                data.append({'features': feat, 'label': label, 'subject_id': subject})\n",
    "            else:\n",
    "                print(f\"Skipped subject due to missing or invalid data: {subject_path}\")\n",
    "\n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e196929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_matrix_single_class(class_path, label, vgg_model, resnet_model, transform, device):\n",
    "    subjects = sorted(os.listdir(class_path))\n",
    "    data = []\n",
    "\n",
    "    for i, subject in enumerate(subjects):\n",
    "        subject_path = os.path.join(class_path, subject)\n",
    "        print(f\"[{label}] Processing subject {i+1}/{len(subjects)}: {subject}\")\n",
    "        feat = process_subject(subject_path, vgg_model, resnet_model, transform, device)\n",
    "\n",
    "        if feat is not None:\n",
    "            data.append({'features': feat, 'label': label, 'subject_id': subject})\n",
    "        else:\n",
    "            print(f\"Skipped subject due to missing or invalid data: {subject_path}\")\n",
    "\n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f24a6800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AD] Processing subject 1/311: 002_S_0619\n",
      "[AD] Processing subject 2/311: 002_S_0619_aug1\n",
      "[AD] Processing subject 3/311: 002_S_0619_aug2\n",
      "[AD] Processing subject 4/311: 002_S_0816\n",
      "[AD] Processing subject 5/311: 002_S_0816_aug0\n",
      "[AD] Processing subject 6/311: 002_S_0816_aug1\n",
      "[AD] Processing subject 7/311: 002_S_0938\n",
      "[AD] Processing subject 8/311: 002_S_0938_aug0\n",
      "[AD] Processing subject 9/311: 002_S_0938_aug1\n",
      "[AD] Processing subject 10/311: 002_S_1018\n",
      "[AD] Processing subject 11/311: 002_S_1018_aug0\n",
      "[AD] Processing subject 12/311: 002_S_1018_aug1\n",
      "[AD] Processing subject 13/311: 005_S_0221\n",
      "[AD] Processing subject 14/311: 005_S_0221_aug0\n",
      "[AD] Processing subject 15/311: 005_S_0221_aug1\n",
      "[AD] Processing subject 16/311: 005_S_0221_aug2\n",
      "[AD] Processing subject 17/311: 005_S_0814\n",
      "[AD] Processing subject 18/311: 005_S_0814_aug0\n",
      "[AD] Processing subject 19/311: 005_S_0814_aug1\n",
      "[AD] Processing subject 20/311: 005_S_0814_aug2\n",
      "[AD] Processing subject 21/311: 005_S_1341\n",
      "[AD] Processing subject 22/311: 005_S_1341_aug0\n",
      "[AD] Processing subject 23/311: 005_S_1341_aug1\n",
      "[AD] Processing subject 24/311: 005_S_1341_aug2\n",
      "[AD] Processing subject 25/311: 006_S_0547\n",
      "[AD] Processing subject 26/311: 006_S_0547_aug0\n",
      "[AD] Processing subject 27/311: 006_S_0547_aug1\n",
      "[AD] Processing subject 28/311: 006_S_0547_aug2\n",
      "[AD] Processing subject 29/311: 007_S_0316\n",
      "[AD] Processing subject 30/311: 007_S_0316_aug0\n",
      "[AD] Processing subject 31/311: 007_S_0316_aug2\n",
      "[AD] Processing subject 32/311: 007_S_1339\n",
      "[AD] Processing subject 33/311: 007_S_1339_aug1\n",
      "[AD] Processing subject 34/311: 007_S_1339_aug2\n",
      "[AD] Processing subject 35/311: 010_S_0786\n",
      "[AD] Processing subject 36/311: 010_S_0786_aug0\n",
      "[AD] Processing subject 37/311: 010_S_0786_aug1\n",
      "[AD] Processing subject 38/311: 010_S_0786_aug2\n",
      "[AD] Processing subject 39/311: 010_S_0829\n",
      "[AD] Processing subject 40/311: 010_S_0829_aug1\n",
      "[AD] Processing subject 41/311: 011_S_0003\n",
      "[AD] Processing subject 42/311: 011_S_0003_aug1\n",
      "[AD] Processing subject 43/311: 011_S_0003_aug2\n",
      "[AD] Processing subject 44/311: 011_S_0010\n",
      "[AD] Processing subject 45/311: 011_S_0010_aug0\n",
      "[AD] Processing subject 46/311: 011_S_0010_aug1\n",
      "[AD] Processing subject 47/311: 011_S_0010_aug2\n",
      "[AD] Processing subject 48/311: 011_S_0053\n",
      "[AD] Processing subject 49/311: 011_S_0053_aug0\n",
      "[AD] Processing subject 50/311: 011_S_0053_aug1\n",
      "[AD] Processing subject 51/311: 011_S_0053_aug2\n",
      "[AD] Processing subject 52/311: 011_S_0183\n",
      "[AD] Processing subject 53/311: 011_S_0183_aug0\n",
      "[AD] Processing subject 54/311: 011_S_0183_aug1\n",
      "[AD] Processing subject 55/311: 011_S_0183_aug2\n",
      "[AD] Processing subject 56/311: 012_S_0689\n",
      "[AD] Processing subject 57/311: 012_S_0689_aug2\n",
      "[AD] Processing subject 58/311: 012_S_0712\n",
      "[AD] Processing subject 59/311: 012_S_0712_aug0\n",
      "[AD] Processing subject 60/311: 012_S_0720\n",
      "[AD] Processing subject 61/311: 012_S_0720_aug1\n",
      "[AD] Processing subject 62/311: 012_S_0803\n",
      "[AD] Processing subject 63/311: 012_S_0803_aug1\n",
      "[AD] Processing subject 64/311: 012_S_0803_aug2\n",
      "[AD] Processing subject 65/311: 013_S_1205\n",
      "[AD] Processing subject 66/311: 013_S_1205_aug1\n",
      "[AD] Processing subject 67/311: 014_S_0328\n",
      "[AD] Processing subject 68/311: 014_S_0328_aug0\n",
      "[AD] Processing subject 69/311: 014_S_0328_aug1\n",
      "[AD] Processing subject 70/311: 014_S_0328_aug2\n",
      "[AD] Processing subject 71/311: 014_S_1095\n",
      "[AD] Processing subject 72/311: 014_S_1095_aug0\n",
      "[AD] Processing subject 73/311: 014_S_1095_aug1\n",
      "[AD] Processing subject 74/311: 014_S_1095_aug2\n",
      "[AD] Processing subject 75/311: 016_S_0991\n",
      "[AD] Processing subject 76/311: 016_S_0991_aug0\n",
      "[AD] Processing subject 77/311: 016_S_0991_aug1\n",
      "[AD] Processing subject 78/311: 016_S_0991_aug2\n",
      "[AD] Processing subject 79/311: 018_S_0286\n",
      "[AD] Processing subject 80/311: 018_S_0286_aug1\n",
      "[AD] Processing subject 81/311: 018_S_0335\n",
      "[AD] Processing subject 82/311: 018_S_0335_aug0\n",
      "[AD] Processing subject 83/311: 018_S_0335_aug1\n",
      "[AD] Processing subject 84/311: 018_S_0335_aug2\n",
      "[AD] Processing subject 85/311: 018_S_0633\n",
      "[AD] Processing subject 86/311: 018_S_0633_aug0\n",
      "[AD] Processing subject 87/311: 018_S_0633_aug1\n",
      "[AD] Processing subject 88/311: 018_S_0682\n",
      "[AD] Processing subject 89/311: 018_S_0682_aug0\n",
      "[AD] Processing subject 90/311: 018_S_0682_aug1\n",
      "[AD] Processing subject 91/311: 018_S_0682_aug2\n",
      "[AD] Processing subject 92/311: 020_S_0213\n",
      "[AD] Processing subject 93/311: 020_S_0213_aug0\n",
      "[AD] Processing subject 94/311: 020_S_0213_aug2\n",
      "[AD] Processing subject 95/311: 021_S_0343\n",
      "[AD] Processing subject 96/311: 021_S_0343_aug1\n",
      "[AD] Processing subject 97/311: 021_S_0343_aug2\n",
      "[AD] Processing subject 98/311: 021_S_0642\n",
      "[AD] Processing subject 99/311: 021_S_0642_aug0\n",
      "[AD] Processing subject 100/311: 021_S_0642_aug1\n",
      "[AD] Processing subject 101/311: 021_S_0642_aug2\n",
      "[AD] Processing subject 102/311: 021_S_0753\n",
      "[AD] Processing subject 103/311: 021_S_0753_aug0\n",
      "[AD] Processing subject 104/311: 021_S_0753_aug1\n",
      "[AD] Processing subject 105/311: 021_S_0753_aug2\n",
      "[AD] Processing subject 106/311: 021_S_1109\n",
      "[AD] Processing subject 107/311: 021_S_1109_aug1\n",
      "[AD] Processing subject 108/311: 021_S_1109_aug2\n",
      "[AD] Processing subject 109/311: 022_S_0129\n",
      "[AD] Processing subject 110/311: 022_S_0129_aug1\n",
      "[AD] Processing subject 111/311: 022_S_0129_aug2\n",
      "[AD] Processing subject 112/311: 023_S_0083\n",
      "[AD] Processing subject 113/311: 023_S_0083_aug0\n",
      "[AD] Processing subject 114/311: 023_S_0083_aug2\n",
      "[AD] Processing subject 115/311: 023_S_0084\n",
      "[AD] Processing subject 116/311: 023_S_0084_aug0\n",
      "[AD] Processing subject 117/311: 023_S_0084_aug1\n",
      "[AD] Processing subject 118/311: 023_S_0139\n",
      "[AD] Processing subject 119/311: 023_S_0139_aug1\n",
      "[AD] Processing subject 120/311: 023_S_0916\n",
      "[AD] Processing subject 121/311: 023_S_0916_aug0\n",
      "[AD] Processing subject 122/311: 023_S_0916_aug1\n",
      "[AD] Processing subject 123/311: 023_S_0916_aug2\n",
      "[AD] Processing subject 124/311: 023_S_1262\n",
      "[AD] Processing subject 125/311: 024_S_1171\n",
      "[AD] Processing subject 126/311: 024_S_1171_aug0\n",
      "[AD] Processing subject 127/311: 024_S_1171_aug2\n",
      "[AD] Processing subject 128/311: 024_S_1307\n",
      "[AD] Processing subject 129/311: 027_S_0404\n",
      "[AD] Processing subject 130/311: 027_S_0404_aug1\n",
      "[AD] Processing subject 131/311: 027_S_0404_aug2\n",
      "[AD] Processing subject 132/311: 027_S_0850\n",
      "[AD] Processing subject 133/311: 027_S_0850_aug0\n",
      "[AD] Processing subject 134/311: 027_S_0850_aug1\n",
      "[AD] Processing subject 135/311: 027_S_0850_aug2\n",
      "[AD] Processing subject 136/311: 027_S_1081\n",
      "[AD] Processing subject 137/311: 027_S_1081_aug0\n",
      "[AD] Processing subject 138/311: 027_S_1082\n",
      "[AD] Processing subject 139/311: 027_S_1082_aug0\n",
      "[AD] Processing subject 140/311: 027_S_1082_aug2\n",
      "[AD] Processing subject 141/311: 027_S_1254\n",
      "[AD] Processing subject 142/311: 027_S_1254_aug0\n",
      "[AD] Processing subject 143/311: 027_S_1254_aug1\n",
      "[AD] Processing subject 144/311: 027_S_1254_aug2\n",
      "[AD] Processing subject 145/311: 027_S_1385\n",
      "[AD] Processing subject 146/311: 027_S_1385_aug0\n",
      "[AD] Processing subject 147/311: 027_S_1385_aug1\n",
      "[AD] Processing subject 148/311: 027_S_1385_aug2\n",
      "[AD] Processing subject 149/311: 029_S_0836\n",
      "[AD] Processing subject 150/311: 029_S_0836_aug0\n",
      "[AD] Processing subject 151/311: 029_S_0836_aug1\n",
      "[AD] Processing subject 152/311: 029_S_0836_aug2\n",
      "[AD] Processing subject 153/311: 029_S_0999\n",
      "[AD] Processing subject 154/311: 029_S_0999_aug0\n",
      "[AD] Processing subject 155/311: 029_S_0999_aug1\n",
      "[AD] Processing subject 156/311: 029_S_0999_aug2\n",
      "[AD] Processing subject 157/311: 029_S_1056\n",
      "[AD] Processing subject 158/311: 029_S_1056_aug0\n",
      "[AD] Processing subject 159/311: 031_S_0321\n",
      "[AD] Processing subject 160/311: 031_S_0321_aug0\n",
      "[AD] Processing subject 161/311: 031_S_0321_aug2\n",
      "[AD] Processing subject 162/311: 031_S_0554\n",
      "[AD] Processing subject 163/311: 031_S_0554_aug1\n",
      "[AD] Processing subject 164/311: 031_S_0554_aug2\n",
      "[AD] Processing subject 165/311: 031_S_1209\n",
      "[AD] Processing subject 166/311: 031_S_1209_aug0\n",
      "[AD] Processing subject 167/311: 031_S_1209_aug1\n",
      "[AD] Processing subject 168/311: 031_S_1209_aug2\n",
      "[AD] Processing subject 169/311: 032_S_0147\n",
      "[AD] Processing subject 170/311: 032_S_0147_aug0\n",
      "[AD] Processing subject 171/311: 032_S_0147_aug1\n",
      "[AD] Processing subject 172/311: 032_S_0147_aug2\n",
      "[AD] Processing subject 173/311: 032_S_0400\n",
      "[AD] Processing subject 174/311: 032_S_0400_aug0\n",
      "[AD] Processing subject 175/311: 032_S_0400_aug1\n",
      "[AD] Processing subject 176/311: 032_S_0400_aug2\n",
      "[AD] Processing subject 177/311: 032_S_1101\n",
      "[AD] Processing subject 178/311: 032_S_1101_aug0\n",
      "[AD] Processing subject 179/311: 032_S_1101_aug1\n",
      "[AD] Processing subject 180/311: 032_S_1101_aug2\n",
      "[AD] Processing subject 181/311: 033_S_0724\n",
      "[AD] Processing subject 182/311: 033_S_0724_aug0\n",
      "[AD] Processing subject 183/311: 033_S_0724_aug1\n",
      "[AD] Processing subject 184/311: 033_S_0724_aug2\n",
      "[AD] Processing subject 185/311: 033_S_0733\n",
      "[AD] Processing subject 186/311: 033_S_0733_aug0\n",
      "[AD] Processing subject 187/311: 033_S_0733_aug1\n",
      "[AD] Processing subject 188/311: 033_S_0739\n",
      "[AD] Processing subject 189/311: 033_S_0739_aug0\n",
      "[AD] Processing subject 190/311: 033_S_0739_aug1\n",
      "[AD] Processing subject 191/311: 033_S_0739_aug2\n",
      "[AD] Processing subject 192/311: 033_S_0889\n",
      "[AD] Processing subject 193/311: 033_S_0889_aug0\n",
      "[AD] Processing subject 194/311: 033_S_0889_aug2\n",
      "[AD] Processing subject 195/311: 033_S_1281\n",
      "[AD] Processing subject 196/311: 033_S_1281_aug1\n",
      "[AD] Processing subject 197/311: 033_S_1281_aug2\n",
      "[AD] Processing subject 198/311: 033_S_1283\n",
      "[AD] Processing subject 199/311: 033_S_1283_aug1\n",
      "[AD] Processing subject 200/311: 033_S_1283_aug2\n",
      "[AD] Processing subject 201/311: 033_S_1285\n",
      "[AD] Processing subject 202/311: 033_S_1285_aug0\n",
      "[AD] Processing subject 203/311: 033_S_1285_aug1\n",
      "[AD] Processing subject 204/311: 033_S_1285_aug2\n",
      "[AD] Processing subject 205/311: 033_S_1308\n",
      "[AD] Processing subject 206/311: 033_S_1308_aug1\n",
      "[AD] Processing subject 207/311: 033_S_1308_aug2\n",
      "[AD] Processing subject 208/311: 035_S_0341\n",
      "[AD] Processing subject 209/311: 035_S_0341_aug0\n",
      "[AD] Processing subject 210/311: 035_S_0341_aug1\n",
      "[AD] Processing subject 211/311: 035_S_0341_aug2\n",
      "[AD] Processing subject 212/311: 036_S_0577\n",
      "[AD] Processing subject 213/311: 036_S_0577_aug0\n",
      "[AD] Processing subject 214/311: 036_S_0577_aug2\n",
      "[AD] Processing subject 215/311: 036_S_0759\n",
      "[AD] Processing subject 216/311: 036_S_0759_aug0\n",
      "[AD] Processing subject 217/311: 036_S_0759_aug1\n",
      "[AD] Processing subject 218/311: 036_S_0760\n",
      "[AD] Processing subject 219/311: 036_S_0760_aug0\n",
      "[AD] Processing subject 220/311: 036_S_0760_aug2\n",
      "[AD] Processing subject 221/311: 036_S_1001\n",
      "[AD] Processing subject 222/311: 036_S_1001_aug2\n",
      "[AD] Processing subject 223/311: 037_S_0627\n",
      "[AD] Processing subject 224/311: 037_S_0627_aug0\n",
      "[AD] Processing subject 225/311: 037_S_0627_aug1\n",
      "[AD] Processing subject 226/311: 037_S_0627_aug2\n",
      "[AD] Processing subject 227/311: 041_S_1368\n",
      "[AD] Processing subject 228/311: 041_S_1368_aug0\n",
      "[AD] Processing subject 229/311: 041_S_1368_aug1\n",
      "[AD] Processing subject 230/311: 051_S_1296\n",
      "[AD] Processing subject 231/311: 051_S_1296_aug0\n",
      "[AD] Processing subject 232/311: 051_S_1296_aug1\n",
      "[AD] Processing subject 233/311: 051_S_1296_aug2\n",
      "[AD] Processing subject 234/311: 053_S_1044\n",
      "[AD] Processing subject 235/311: 053_S_1044_aug0\n",
      "[AD] Processing subject 236/311: 053_S_1044_aug1\n",
      "[AD] Processing subject 237/311: 053_S_1044_aug2\n",
      "[AD] Processing subject 238/311: 057_S_0474\n",
      "[AD] Processing subject 239/311: 057_S_0474_aug0\n",
      "[AD] Processing subject 240/311: 057_S_0474_aug1\n",
      "[AD] Processing subject 241/311: 057_S_1371\n",
      "[AD] Processing subject 242/311: 057_S_1371_aug0\n",
      "[AD] Processing subject 243/311: 057_S_1371_aug1\n",
      "[AD] Processing subject 244/311: 057_S_1371_aug2\n",
      "[AD] Processing subject 245/311: 057_S_1373\n",
      "[AD] Processing subject 246/311: 057_S_1373_aug0\n",
      "[AD] Processing subject 247/311: 057_S_1373_aug1\n",
      "[AD] Processing subject 248/311: 057_S_1373_aug2\n",
      "[AD] Processing subject 249/311: 057_S_1379\n",
      "[AD] Processing subject 250/311: 057_S_1379_aug0\n",
      "[AD] Processing subject 251/311: 057_S_1379_aug1\n",
      "[AD] Processing subject 252/311: 057_S_1379_aug2\n",
      "[AD] Processing subject 253/311: 062_S_0535\n",
      "[AD] Processing subject 254/311: 062_S_0535_aug0\n",
      "[AD] Processing subject 255/311: 062_S_0535_aug1\n",
      "[AD] Processing subject 256/311: 062_S_0535_aug2\n",
      "[AD] Processing subject 257/311: 062_S_0690\n",
      "[AD] Processing subject 258/311: 062_S_0730\n",
      "[AD] Processing subject 259/311: 062_S_0793\n",
      "[AD] Processing subject 260/311: 067_S_0029\n",
      "[AD] Processing subject 261/311: 067_S_0076\n",
      "[AD] Processing subject 262/311: 068_S_0109\n",
      "[AD] Processing subject 263/311: 073_S_0565\n",
      "[AD] Processing subject 264/311: 082_S_1377\n",
      "[AD] Processing subject 265/311: 094_S_1027\n",
      "[AD] Processing subject 266/311: 094_S_1090\n",
      "[AD] Processing subject 267/311: 094_S_1164\n",
      "[AD] Processing subject 268/311: 094_S_1397\n",
      "[AD] Processing subject 269/311: 094_S_1402\n",
      "[AD] Processing subject 270/311: 098_S_0149\n",
      "[AD] Processing subject 271/311: 099_S_0372\n",
      "[AD] Processing subject 272/311: 099_S_0470\n",
      "[AD] Processing subject 273/311: 099_S_1144\n",
      "[AD] Processing subject 274/311: 109_S_1157\n",
      "[AD] Processing subject 275/311: 114_S_0374\n",
      "[AD] Processing subject 276/311: 114_S_0979\n",
      "[AD] Processing subject 277/311: 116_S_0370\n",
      "[AD] Processing subject 278/311: 116_S_0392\n",
      "[AD] Processing subject 279/311: 116_S_0487\n",
      "[AD] Processing subject 280/311: 123_S_0088\n",
      "[AD] Processing subject 281/311: 123_S_0091\n",
      "[AD] Processing subject 282/311: 123_S_0094\n",
      "[AD] Processing subject 283/311: 123_S_0162\n",
      "[AD] Processing subject 284/311: 126_S_0606\n",
      "[AD] Processing subject 285/311: 126_S_0784\n",
      "[AD] Processing subject 286/311: 126_S_0891\n",
      "[AD] Processing subject 287/311: 126_S_1221\n",
      "[AD] Processing subject 288/311: 127_S_0431\n",
      "[AD] Processing subject 289/311: 127_S_0754\n",
      "[AD] Processing subject 290/311: 127_S_0844\n",
      "[AD] Processing subject 291/311: 127_S_1382\n",
      "[AD] Processing subject 292/311: 130_S_0956\n",
      "[AD] Processing subject 293/311: 130_S_1201\n",
      "[AD] Processing subject 294/311: 130_S_1290\n",
      "[AD] Processing subject 295/311: 130_S_1337\n",
      "[AD] Processing subject 296/311: 131_S_0457\n",
      "[AD] Processing subject 297/311: 131_S_0497\n",
      "[AD] Processing subject 298/311: 133_S_1170\n",
      "[AD] Processing subject 299/311: 136_S_0194\n",
      "[AD] Processing subject 300/311: 136_S_0299\n",
      "[AD] Processing subject 301/311: 136_S_0300\n",
      "[AD] Processing subject 302/311: 136_S_0426\n",
      "[AD] Processing subject 303/311: 137_S_0366\n",
      "[AD] Processing subject 304/311: 137_S_0796\n",
      "[AD] Processing subject 305/311: 137_S_1041\n",
      "[AD] Processing subject 306/311: 141_S_0696\n",
      "[AD] Processing subject 307/311: 141_S_0790\n",
      "[AD] Processing subject 308/311: 141_S_0852\n",
      "[AD] Processing subject 309/311: 141_S_0853\n",
      "[AD] Processing subject 310/311: 141_S_1137\n",
      "[AD] Processing subject 311/311: 141_S_1152\n",
      "[CN] Processing subject 1/311: 002_S_0295\n",
      "[CN] Processing subject 2/311: 002_S_0295_aug0\n",
      "[CN] Processing subject 3/311: 002_S_0295_aug1\n",
      "[CN] Processing subject 4/311: 002_S_0413\n",
      "[CN] Processing subject 5/311: 002_S_0413_aug1\n",
      "[CN] Processing subject 6/311: 002_S_0685\n",
      "[CN] Processing subject 7/311: 002_S_0685_aug0\n",
      "[CN] Processing subject 8/311: 002_S_0685_aug1\n",
      "[CN] Processing subject 9/311: 002_S_1261\n",
      "[CN] Processing subject 10/311: 002_S_1261_aug0\n",
      "[CN] Processing subject 11/311: 002_S_1261_aug1\n",
      "[CN] Processing subject 12/311: 002_S_1280\n",
      "[CN] Processing subject 13/311: 002_S_1280_aug0\n",
      "[CN] Processing subject 14/311: 002_S_1280_aug1\n",
      "[CN] Processing subject 15/311: 003_S_0907\n",
      "[CN] Processing subject 16/311: 003_S_0907_aug0\n",
      "[CN] Processing subject 17/311: 003_S_0907_aug1\n",
      "[CN] Processing subject 18/311: 003_S_0981\n",
      "[CN] Processing subject 19/311: 003_S_0981_aug1\n",
      "[CN] Processing subject 20/311: 005_S_0223\n",
      "[CN] Processing subject 21/311: 005_S_0223_aug0\n",
      "[CN] Processing subject 22/311: 005_S_0223_aug1\n",
      "[CN] Processing subject 23/311: 005_S_0553\n",
      "[CN] Processing subject 24/311: 005_S_0553_aug0\n",
      "[CN] Processing subject 25/311: 005_S_0602\n",
      "[CN] Processing subject 26/311: 005_S_0602_aug1\n",
      "[CN] Processing subject 27/311: 005_S_0610\n",
      "[CN] Processing subject 28/311: 005_S_0610_aug0\n",
      "[CN] Processing subject 29/311: 005_S_0610_aug1\n",
      "[CN] Processing subject 30/311: 006_S_0498\n",
      "[CN] Processing subject 31/311: 006_S_0498_aug0\n",
      "[CN] Processing subject 32/311: 006_S_0498_aug1\n",
      "[CN] Processing subject 33/311: 006_S_0681\n",
      "[CN] Processing subject 34/311: 006_S_0681_aug0\n",
      "[CN] Processing subject 35/311: 006_S_0681_aug1\n",
      "[CN] Processing subject 36/311: 006_S_0731\n",
      "[CN] Processing subject 37/311: 006_S_0731_aug0\n",
      "[CN] Processing subject 38/311: 006_S_0731_aug1\n",
      "[CN] Processing subject 39/311: 007_S_0068\n",
      "[CN] Processing subject 40/311: 007_S_0068_aug0\n",
      "[CN] Processing subject 41/311: 007_S_0068_aug1\n",
      "[CN] Processing subject 42/311: 007_S_0070\n",
      "[CN] Processing subject 43/311: 007_S_0070_aug0\n",
      "[CN] Processing subject 44/311: 007_S_0070_aug1\n",
      "[CN] Processing subject 45/311: 007_S_1206\n",
      "[CN] Processing subject 46/311: 007_S_1206_aug0\n",
      "[CN] Processing subject 47/311: 007_S_1206_aug1\n",
      "[CN] Processing subject 48/311: 007_S_1222\n",
      "[CN] Processing subject 49/311: 007_S_1222_aug0\n",
      "[CN] Processing subject 50/311: 007_S_1222_aug1\n",
      "[CN] Processing subject 51/311: 009_S_0751\n",
      "[CN] Processing subject 52/311: 009_S_0751_aug0\n",
      "[CN] Processing subject 53/311: 009_S_0842\n",
      "[CN] Processing subject 54/311: 009_S_0842_aug0\n",
      "[CN] Processing subject 55/311: 009_S_0862\n",
      "[CN] Processing subject 56/311: 009_S_0862_aug0\n",
      "[CN] Processing subject 57/311: 009_S_0862_aug1\n",
      "[CN] Processing subject 58/311: 010_S_0067\n",
      "[CN] Processing subject 59/311: 010_S_0067_aug0\n",
      "[CN] Processing subject 60/311: 010_S_0067_aug1\n",
      "[CN] Processing subject 61/311: 010_S_0419\n",
      "[CN] Processing subject 62/311: 010_S_0419_aug0\n",
      "[CN] Processing subject 63/311: 010_S_0419_aug1\n",
      "[CN] Processing subject 64/311: 010_S_0472\n",
      "[CN] Processing subject 65/311: 010_S_0472_aug0\n",
      "[CN] Processing subject 66/311: 010_S_0472_aug1\n",
      "[CN] Processing subject 67/311: 011_S_0005\n",
      "[CN] Processing subject 68/311: 011_S_0005_aug0\n",
      "[CN] Processing subject 69/311: 011_S_0005_aug1\n",
      "[CN] Processing subject 70/311: 011_S_0016\n",
      "[CN] Processing subject 71/311: 011_S_0016_aug0\n",
      "[CN] Processing subject 72/311: 011_S_0021\n",
      "[CN] Processing subject 73/311: 011_S_0021_aug0\n",
      "[CN] Processing subject 74/311: 011_S_0022\n",
      "[CN] Processing subject 75/311: 011_S_0022_aug0\n",
      "[CN] Processing subject 76/311: 011_S_0023\n",
      "[CN] Processing subject 77/311: 011_S_0023_aug0\n",
      "[CN] Processing subject 78/311: 011_S_0023_aug1\n",
      "[CN] Processing subject 79/311: 012_S_0637\n",
      "[CN] Processing subject 80/311: 012_S_0637_aug0\n",
      "[CN] Processing subject 81/311: 012_S_0637_aug1\n",
      "[CN] Processing subject 82/311: 012_S_1009\n",
      "[CN] Processing subject 83/311: 012_S_1009_aug0\n",
      "[CN] Processing subject 84/311: 012_S_1009_aug1\n",
      "[CN] Processing subject 85/311: 012_S_1133\n",
      "[CN] Processing subject 86/311: 012_S_1133_aug0\n",
      "[CN] Processing subject 87/311: 012_S_1133_aug1\n",
      "[CN] Processing subject 88/311: 013_S_0502\n",
      "[CN] Processing subject 89/311: 013_S_0502_aug0\n",
      "[CN] Processing subject 90/311: 013_S_0502_aug1\n",
      "[CN] Processing subject 91/311: 013_S_0575\n",
      "[CN] Processing subject 92/311: 013_S_0575_aug0\n",
      "[CN] Processing subject 93/311: 013_S_0575_aug1\n",
      "[CN] Processing subject 94/311: 013_S_1035\n",
      "[CN] Processing subject 95/311: 013_S_1035_aug0\n",
      "[CN] Processing subject 96/311: 013_S_1035_aug1\n",
      "[CN] Processing subject 97/311: 014_S_0519\n",
      "[CN] Processing subject 98/311: 014_S_0519_aug0\n",
      "[CN] Processing subject 99/311: 014_S_0519_aug1\n",
      "[CN] Processing subject 100/311: 014_S_0520\n",
      "[CN] Processing subject 101/311: 014_S_0520_aug1\n",
      "[CN] Processing subject 102/311: 014_S_0548\n",
      "[CN] Processing subject 103/311: 014_S_0548_aug0\n",
      "[CN] Processing subject 104/311: 014_S_0548_aug1\n",
      "[CN] Processing subject 105/311: 014_S_0558\n",
      "[CN] Processing subject 106/311: 014_S_0558_aug0\n",
      "[CN] Processing subject 107/311: 014_S_0558_aug1\n",
      "[CN] Processing subject 108/311: 016_S_0359\n",
      "[CN] Processing subject 109/311: 016_S_0359_aug0\n",
      "[CN] Processing subject 110/311: 016_S_0359_aug1\n",
      "[CN] Processing subject 111/311: 016_S_0538\n",
      "[CN] Processing subject 112/311: 016_S_0538_aug0\n",
      "[CN] Processing subject 113/311: 016_S_0538_aug1\n",
      "[CN] Processing subject 114/311: 018_S_0043\n",
      "[CN] Processing subject 115/311: 018_S_0043_aug0\n",
      "[CN] Processing subject 116/311: 018_S_0043_aug1\n",
      "[CN] Processing subject 117/311: 018_S_0055\n",
      "[CN] Processing subject 118/311: 018_S_0055_aug1\n",
      "[CN] Processing subject 119/311: 018_S_0369\n",
      "[CN] Processing subject 120/311: 018_S_0369_aug0\n",
      "[CN] Processing subject 121/311: 018_S_0425\n",
      "[CN] Processing subject 122/311: 018_S_0425_aug0\n",
      "[CN] Processing subject 123/311: 018_S_0425_aug1\n",
      "[CN] Processing subject 124/311: 020_S_0097\n",
      "[CN] Processing subject 125/311: 020_S_0097_aug1\n",
      "[CN] Processing subject 126/311: 020_S_0883\n",
      "[CN] Processing subject 127/311: 020_S_0883_aug0\n",
      "[CN] Processing subject 128/311: 020_S_0883_aug1\n",
      "[CN] Processing subject 129/311: 020_S_0899\n",
      "[CN] Processing subject 130/311: 020_S_0899_aug1\n",
      "[CN] Processing subject 131/311: 020_S_1288\n",
      "[CN] Processing subject 132/311: 020_S_1288_aug0\n",
      "[CN] Processing subject 133/311: 020_S_1288_aug1\n",
      "[CN] Processing subject 134/311: 021_S_0159\n",
      "[CN] Processing subject 135/311: 021_S_0159_aug0\n",
      "[CN] Processing subject 136/311: 021_S_0159_aug1\n",
      "[CN] Processing subject 137/311: 021_S_0337\n",
      "[CN] Processing subject 138/311: 021_S_0337_aug0\n",
      "[CN] Processing subject 139/311: 021_S_0647\n",
      "[CN] Processing subject 140/311: 021_S_0647_aug0\n",
      "[CN] Processing subject 141/311: 021_S_0984\n",
      "[CN] Processing subject 142/311: 021_S_0984_aug0\n",
      "[CN] Processing subject 143/311: 021_S_0984_aug1\n",
      "[CN] Processing subject 144/311: 022_S_0014\n",
      "[CN] Processing subject 145/311: 022_S_0014_aug0\n",
      "[CN] Processing subject 146/311: 022_S_0014_aug1\n",
      "[CN] Processing subject 147/311: 022_S_0066\n",
      "[CN] Processing subject 148/311: 022_S_0066_aug0\n",
      "[CN] Processing subject 149/311: 022_S_0096\n",
      "[CN] Processing subject 150/311: 022_S_0096_aug0\n",
      "[CN] Processing subject 151/311: 022_S_0096_aug1\n",
      "[CN] Processing subject 152/311: 022_S_0130\n",
      "[CN] Processing subject 153/311: 022_S_0130_aug1\n",
      "[CN] Processing subject 154/311: 023_S_0031\n",
      "[CN] Processing subject 155/311: 023_S_0031_aug0\n",
      "[CN] Processing subject 156/311: 023_S_0031_aug1\n",
      "[CN] Processing subject 157/311: 023_S_0058\n",
      "[CN] Processing subject 158/311: 023_S_0058_aug0\n",
      "[CN] Processing subject 159/311: 023_S_0058_aug1\n",
      "[CN] Processing subject 160/311: 023_S_0061\n",
      "[CN] Processing subject 161/311: 023_S_0061_aug0\n",
      "[CN] Processing subject 162/311: 023_S_0061_aug1\n",
      "[CN] Processing subject 163/311: 023_S_0081\n",
      "[CN] Processing subject 164/311: 023_S_0081_aug0\n",
      "[CN] Processing subject 165/311: 023_S_0926\n",
      "[CN] Processing subject 166/311: 023_S_0926_aug1\n",
      "[CN] Processing subject 167/311: 023_S_0963\n",
      "[CN] Processing subject 168/311: 023_S_0963_aug1\n",
      "[CN] Processing subject 169/311: 023_S_1190\n",
      "[CN] Processing subject 170/311: 023_S_1190_aug0\n",
      "[CN] Processing subject 171/311: 023_S_1190_aug1\n",
      "[CN] Processing subject 172/311: 024_S_0985\n",
      "[CN] Processing subject 173/311: 024_S_0985_aug1\n",
      "[CN] Processing subject 174/311: 024_S_1063\n",
      "[CN] Processing subject 175/311: 024_S_1063_aug0\n",
      "[CN] Processing subject 176/311: 024_S_1063_aug1\n",
      "[CN] Processing subject 177/311: 027_S_0074\n",
      "[CN] Processing subject 178/311: 027_S_0074_aug0\n",
      "[CN] Processing subject 179/311: 027_S_0074_aug1\n",
      "[CN] Processing subject 180/311: 027_S_0118\n",
      "[CN] Processing subject 181/311: 027_S_0118_aug0\n",
      "[CN] Processing subject 182/311: 027_S_0118_aug1\n",
      "[CN] Processing subject 183/311: 027_S_0120\n",
      "[CN] Processing subject 184/311: 027_S_0120_aug0\n",
      "[CN] Processing subject 185/311: 027_S_0403\n",
      "[CN] Processing subject 186/311: 027_S_0403_aug0\n",
      "[CN] Processing subject 187/311: 029_S_0824\n",
      "[CN] Processing subject 188/311: 029_S_0843\n",
      "[CN] Processing subject 189/311: 029_S_0845\n",
      "[CN] Processing subject 190/311: 029_S_0866\n",
      "[CN] Processing subject 191/311: 031_S_0618\n",
      "[CN] Processing subject 192/311: 032_S_0095\n",
      "[CN] Processing subject 193/311: 032_S_0479\n",
      "[CN] Processing subject 194/311: 032_S_0677\n",
      "[CN] Processing subject 195/311: 032_S_1169\n",
      "[CN] Processing subject 196/311: 033_S_0516\n",
      "[CN] Processing subject 197/311: 033_S_0734\n",
      "[CN] Processing subject 198/311: 033_S_0741\n",
      "[CN] Processing subject 199/311: 033_S_0920\n",
      "[CN] Processing subject 200/311: 033_S_0923\n",
      "[CN] Processing subject 201/311: 033_S_1016\n",
      "[CN] Processing subject 202/311: 033_S_1086\n",
      "[CN] Processing subject 203/311: 033_S_1098\n",
      "[CN] Processing subject 204/311: 035_S_0048\n",
      "[CN] Processing subject 205/311: 035_S_0156\n",
      "[CN] Processing subject 206/311: 035_S_0555\n",
      "[CN] Processing subject 207/311: 036_S_0576\n",
      "[CN] Processing subject 208/311: 036_S_0672\n",
      "[CN] Processing subject 209/311: 036_S_0813\n",
      "[CN] Processing subject 210/311: 036_S_1023\n",
      "[CN] Processing subject 211/311: 037_S_0303\n",
      "[CN] Processing subject 212/311: 037_S_0327\n",
      "[CN] Processing subject 213/311: 037_S_0454\n",
      "[CN] Processing subject 214/311: 037_S_0467\n",
      "[CN] Processing subject 215/311: 041_S_0125\n",
      "[CN] Processing subject 216/311: 041_S_0262\n",
      "[CN] Processing subject 217/311: 041_S_0898\n",
      "[CN] Processing subject 218/311: 041_S_1002\n",
      "[CN] Processing subject 219/311: 051_S_1123\n",
      "[CN] Processing subject 220/311: 052_S_0951\n",
      "[CN] Processing subject 221/311: 052_S_1250\n",
      "[CN] Processing subject 222/311: 052_S_1251\n",
      "[CN] Processing subject 223/311: 057_S_0643\n",
      "[CN] Processing subject 224/311: 057_S_0779\n",
      "[CN] Processing subject 225/311: 057_S_0818\n",
      "[CN] Processing subject 226/311: 057_S_0934\n",
      "[CN] Processing subject 227/311: 062_S_0578\n",
      "[CN] Processing subject 228/311: 062_S_0768\n",
      "[CN] Processing subject 229/311: 062_S_1099\n",
      "[CN] Processing subject 230/311: 067_S_0019\n",
      "[CN] Processing subject 231/311: 067_S_0056\n",
      "[CN] Processing subject 232/311: 067_S_0059\n",
      "[CN] Processing subject 233/311: 067_S_0177\n",
      "[CN] Processing subject 234/311: 067_S_0257\n",
      "[CN] Processing subject 235/311: 068_S_0127\n",
      "[CN] Processing subject 236/311: 068_S_0210\n",
      "[CN] Processing subject 237/311: 068_S_0473\n",
      "[CN] Processing subject 238/311: 072_S_0315\n",
      "[CN] Processing subject 239/311: 073_S_0089\n",
      "[CN] Processing subject 240/311: 073_S_0311\n",
      "[CN] Processing subject 241/311: 073_S_0312\n",
      "[CN] Processing subject 242/311: 073_S_0386\n",
      "[CN] Processing subject 243/311: 082_S_1256\n",
      "[CN] Processing subject 244/311: 094_S_0526\n",
      "[CN] Processing subject 245/311: 094_S_0692\n",
      "[CN] Processing subject 246/311: 094_S_0711\n",
      "[CN] Processing subject 247/311: 094_S_1241\n",
      "[CN] Processing subject 248/311: 094_S_1267\n",
      "[CN] Processing subject 249/311: 098_S_0171\n",
      "[CN] Processing subject 250/311: 098_S_0172\n",
      "[CN] Processing subject 251/311: 098_S_0896\n",
      "[CN] Processing subject 252/311: 099_S_0040\n",
      "[CN] Processing subject 253/311: 099_S_0090\n",
      "[CN] Processing subject 254/311: 099_S_0352\n",
      "[CN] Processing subject 255/311: 099_S_0533\n",
      "[CN] Processing subject 256/311: 099_S_0534\n",
      "[CN] Processing subject 257/311: 100_S_0015\n",
      "[CN] Processing subject 258/311: 100_S_0035\n",
      "[CN] Processing subject 259/311: 100_S_0047\n",
      "[CN] Processing subject 260/311: 100_S_0069\n",
      "[CN] Processing subject 261/311: 109_S_0967\n",
      "[CN] Processing subject 262/311: 109_S_1014\n",
      "[CN] Processing subject 263/311: 114_S_0166\n",
      "[CN] Processing subject 264/311: 114_S_0173\n",
      "[CN] Processing subject 265/311: 114_S_0416\n",
      "[CN] Processing subject 266/311: 114_S_0601\n",
      "[CN] Processing subject 267/311: 116_S_0382\n",
      "[CN] Processing subject 268/311: 116_S_0648\n",
      "[CN] Processing subject 269/311: 116_S_0657\n",
      "[CN] Processing subject 270/311: 116_S_1232\n",
      "[CN] Processing subject 271/311: 116_S_1249\n",
      "[CN] Processing subject 272/311: 123_S_0072\n",
      "[CN] Processing subject 273/311: 123_S_0106\n",
      "[CN] Processing subject 274/311: 123_S_0113\n",
      "[CN] Processing subject 275/311: 123_S_0298\n",
      "[CN] Processing subject 276/311: 126_S_0605\n",
      "[CN] Processing subject 277/311: 126_S_0680\n",
      "[CN] Processing subject 278/311: 127_S_0259\n",
      "[CN] Processing subject 279/311: 127_S_0260\n",
      "[CN] Processing subject 280/311: 127_S_0622\n",
      "[CN] Processing subject 281/311: 127_S_0684\n",
      "[CN] Processing subject 282/311: 128_S_0863\n",
      "[CN] Processing subject 283/311: 128_S_1242\n",
      "[CN] Processing subject 284/311: 129_S_0778\n",
      "[CN] Processing subject 285/311: 130_S_0232\n",
      "[CN] Processing subject 286/311: 130_S_0886\n",
      "[CN] Processing subject 287/311: 130_S_0969\n",
      "[CN] Processing subject 288/311: 130_S_1200\n",
      "[CN] Processing subject 289/311: 131_S_0123\n",
      "[CN] Processing subject 290/311: 131_S_0441\n",
      "[CN] Processing subject 291/311: 131_S_1301\n",
      "[CN] Processing subject 292/311: 133_S_0433\n",
      "[CN] Processing subject 293/311: 133_S_0488\n",
      "[CN] Processing subject 294/311: 133_S_0525\n",
      "[CN] Processing subject 295/311: 136_S_0086\n",
      "[CN] Processing subject 296/311: 136_S_0184\n",
      "[CN] Processing subject 297/311: 136_S_0186\n",
      "[CN] Processing subject 298/311: 136_S_0196\n",
      "[CN] Processing subject 299/311: 137_S_0283\n",
      "[CN] Processing subject 300/311: 137_S_0301\n",
      "[CN] Processing subject 301/311: 137_S_0459\n",
      "[CN] Processing subject 302/311: 137_S_0686\n",
      "[CN] Processing subject 303/311: 137_S_0972\n",
      "[CN] Processing subject 304/311: 141_S_0717\n",
      "[CN] Processing subject 305/311: 141_S_0726\n",
      "[CN] Processing subject 306/311: 141_S_0767\n",
      "[CN] Processing subject 307/311: 141_S_0810\n",
      "[CN] Processing subject 308/311: 141_S_1094\n",
      "[CN] Processing subject 309/311: 941_S_1194\n",
      "[CN] Processing subject 310/311: 941_S_1197\n",
      "[CN] Processing subject 311/311: 941_S_1202\n",
      "[LMCI] Processing subject 1/311: 002_S_0729\n",
      "[LMCI] Processing subject 2/311: 002_S_0782\n",
      "[LMCI] Processing subject 3/311: 002_S_0954\n",
      "[LMCI] Processing subject 4/311: 002_S_1070\n",
      "[LMCI] Processing subject 5/311: 002_S_1155\n",
      "[LMCI] Processing subject 6/311: 002_S_1268\n",
      "[LMCI] Processing subject 7/311: 003_S_0908\n",
      "[LMCI] Processing subject 8/311: 003_S_1057\n",
      "[LMCI] Processing subject 9/311: 003_S_1122\n",
      "[LMCI] Processing subject 10/311: 005_S_0222\n",
      "[LMCI] Processing subject 11/311: 005_S_0324\n",
      "[LMCI] Processing subject 12/311: 005_S_0448\n",
      "[LMCI] Processing subject 13/311: 005_S_0546\n",
      "[LMCI] Processing subject 14/311: 005_S_1224\n",
      "[LMCI] Processing subject 15/311: 006_S_0675\n",
      "[LMCI] Processing subject 16/311: 006_S_1130\n",
      "[LMCI] Processing subject 17/311: 007_S_0041\n",
      "[LMCI] Processing subject 18/311: 007_S_0101\n",
      "[LMCI] Processing subject 19/311: 007_S_0128\n",
      "[LMCI] Processing subject 20/311: 007_S_0249\n",
      "[LMCI] Processing subject 21/311: 007_S_0293\n",
      "[LMCI] Processing subject 22/311: 007_S_0414\n",
      "[LMCI] Processing subject 23/311: 007_S_0698\n",
      "[LMCI] Processing subject 24/311: 009_S_1030\n",
      "[LMCI] Processing subject 25/311: 010_S_0422\n",
      "[LMCI] Processing subject 26/311: 010_S_0904\n",
      "[LMCI] Processing subject 27/311: 011_S_0168\n",
      "[LMCI] Processing subject 28/311: 011_S_0241\n",
      "[LMCI] Processing subject 29/311: 011_S_0326\n",
      "[LMCI] Processing subject 30/311: 011_S_0362\n",
      "[LMCI] Processing subject 31/311: 011_S_0856\n",
      "[LMCI] Processing subject 32/311: 011_S_0861\n",
      "[LMCI] Processing subject 33/311: 011_S_1080\n",
      "[LMCI] Processing subject 34/311: 011_S_1282\n",
      "[LMCI] Processing subject 35/311: 012_S_0634\n",
      "[LMCI] Processing subject 36/311: 012_S_0932\n",
      "[LMCI] Processing subject 37/311: 012_S_1033\n",
      "[LMCI] Processing subject 38/311: 012_S_1165\n",
      "[LMCI] Processing subject 39/311: 012_S_1292\n",
      "[LMCI] Processing subject 40/311: 012_S_1321\n",
      "[LMCI] Processing subject 41/311: 013_S_0240\n",
      "[LMCI] Processing subject 42/311: 013_S_0325\n",
      "[LMCI] Processing subject 43/311: 013_S_0860\n",
      "[LMCI] Processing subject 44/311: 013_S_1120\n",
      "[LMCI] Processing subject 45/311: 013_S_1186\n",
      "[LMCI] Processing subject 46/311: 013_S_1275\n",
      "[LMCI] Processing subject 47/311: 014_S_0169\n",
      "[LMCI] Processing subject 48/311: 014_S_0557\n",
      "[LMCI] Processing subject 49/311: 014_S_0563\n",
      "[LMCI] Processing subject 50/311: 014_S_0658\n",
      "[LMCI] Processing subject 51/311: 016_S_0354\n",
      "[LMCI] Processing subject 52/311: 016_S_0702\n",
      "[LMCI] Processing subject 53/311: 016_S_1028\n",
      "[LMCI] Processing subject 54/311: 016_S_1117\n",
      "[LMCI] Processing subject 55/311: 016_S_1121\n",
      "[LMCI] Processing subject 56/311: 016_S_1326\n",
      "[LMCI] Processing subject 57/311: 018_S_0057\n",
      "[LMCI] Processing subject 58/311: 018_S_0080\n",
      "[LMCI] Processing subject 59/311: 018_S_0087\n",
      "[LMCI] Processing subject 60/311: 018_S_0142\n",
      "[LMCI] Processing subject 61/311: 018_S_0155\n",
      "[LMCI] Processing subject 62/311: 018_S_0406\n",
      "[LMCI] Processing subject 63/311: 018_S_0450\n",
      "[LMCI] Processing subject 64/311: 021_S_0141\n",
      "[LMCI] Processing subject 65/311: 021_S_0231\n",
      "[LMCI] Processing subject 66/311: 021_S_0273\n",
      "[LMCI] Processing subject 67/311: 021_S_0276\n",
      "[LMCI] Processing subject 68/311: 021_S_0332\n",
      "[LMCI] Processing subject 69/311: 021_S_0424\n",
      "[LMCI] Processing subject 70/311: 021_S_0626\n",
      "[LMCI] Processing subject 71/311: 022_S_0004\n",
      "[LMCI] Processing subject 72/311: 022_S_0544\n",
      "[LMCI] Processing subject 73/311: 022_S_0750\n",
      "[LMCI] Processing subject 74/311: 022_S_0961\n",
      "[LMCI] Processing subject 75/311: 022_S_1351\n",
      "[LMCI] Processing subject 76/311: 022_S_1394\n",
      "[LMCI] Processing subject 77/311: 023_S_0030\n",
      "[LMCI] Processing subject 78/311: 023_S_0042\n",
      "[LMCI] Processing subject 79/311: 023_S_0078\n",
      "[LMCI] Processing subject 80/311: 023_S_0126\n",
      "[LMCI] Processing subject 81/311: 023_S_0217\n",
      "[LMCI] Processing subject 82/311: 023_S_0331\n",
      "[LMCI] Processing subject 83/311: 023_S_0376\n",
      "[LMCI] Processing subject 84/311: 023_S_0388\n",
      "[LMCI] Processing subject 85/311: 023_S_0604\n",
      "[LMCI] Processing subject 86/311: 023_S_0625\n",
      "[LMCI] Processing subject 87/311: 023_S_0855\n",
      "[LMCI] Processing subject 88/311: 023_S_0887\n",
      "[LMCI] Processing subject 89/311: 023_S_1046\n",
      "[LMCI] Processing subject 90/311: 023_S_1126\n",
      "[LMCI] Processing subject 91/311: 023_S_1247\n",
      "[LMCI] Processing subject 92/311: 024_S_1393\n",
      "[LMCI] Processing subject 93/311: 027_S_0116\n",
      "[LMCI] Processing subject 94/311: 027_S_0179\n",
      "[LMCI] Processing subject 95/311: 027_S_0256\n",
      "[LMCI] Processing subject 96/311: 027_S_0307\n",
      "[LMCI] Processing subject 97/311: 027_S_0408\n",
      "[LMCI] Processing subject 98/311: 027_S_0417\n",
      "[LMCI] Processing subject 99/311: 027_S_0461\n",
      "[LMCI] Processing subject 100/311: 027_S_0485\n",
      "[LMCI] Processing subject 101/311: 027_S_0644\n",
      "[LMCI] Processing subject 102/311: 027_S_0835\n",
      "[LMCI] Processing subject 103/311: 027_S_1045\n",
      "[LMCI] Processing subject 104/311: 027_S_1213\n",
      "[LMCI] Processing subject 105/311: 027_S_1277\n",
      "[LMCI] Processing subject 106/311: 027_S_1387\n",
      "[LMCI] Processing subject 107/311: 029_S_0878\n",
      "[LMCI] Processing subject 108/311: 029_S_0914\n",
      "[LMCI] Processing subject 109/311: 029_S_1073\n",
      "[LMCI] Processing subject 110/311: 029_S_1215\n",
      "[LMCI] Processing subject 111/311: 029_S_1318\n",
      "[LMCI] Processing subject 112/311: 029_S_1384\n",
      "[LMCI] Processing subject 113/311: 031_S_0294\n",
      "[LMCI] Processing subject 114/311: 031_S_0351\n",
      "[LMCI] Processing subject 115/311: 031_S_0568\n",
      "[LMCI] Processing subject 116/311: 031_S_0830\n",
      "[LMCI] Processing subject 117/311: 031_S_0867\n",
      "[LMCI] Processing subject 118/311: 031_S_1066\n",
      "[LMCI] Processing subject 119/311: 032_S_0187\n",
      "[LMCI] Processing subject 120/311: 032_S_0214\n",
      "[LMCI] Processing subject 121/311: 032_S_0718\n",
      "[LMCI] Processing subject 122/311: 032_S_0978\n",
      "[LMCI] Processing subject 123/311: 033_S_0511\n",
      "[LMCI] Processing subject 124/311: 033_S_0513\n",
      "[LMCI] Processing subject 125/311: 033_S_0514\n",
      "[LMCI] Processing subject 126/311: 033_S_0567\n",
      "[LMCI] Processing subject 127/311: 033_S_0723\n",
      "[LMCI] Processing subject 128/311: 033_S_0725\n",
      "[LMCI] Processing subject 129/311: 033_S_0906\n",
      "[LMCI] Processing subject 130/311: 033_S_0922\n",
      "[LMCI] Processing subject 131/311: 033_S_1116\n",
      "[LMCI] Processing subject 132/311: 033_S_1279\n",
      "[LMCI] Processing subject 133/311: 033_S_1284\n",
      "[LMCI] Processing subject 134/311: 033_S_1309\n",
      "[LMCI] Processing subject 135/311: 035_S_0033\n",
      "[LMCI] Processing subject 136/311: 035_S_0204\n",
      "[LMCI] Processing subject 137/311: 035_S_0292\n",
      "[LMCI] Processing subject 138/311: 035_S_0997\n",
      "[LMCI] Processing subject 139/311: 036_S_0656\n",
      "[LMCI] Processing subject 140/311: 036_S_0673\n",
      "[LMCI] Processing subject 141/311: 036_S_0748\n",
      "[LMCI] Processing subject 142/311: 036_S_0869\n",
      "[LMCI] Processing subject 143/311: 036_S_0945\n",
      "[LMCI] Processing subject 144/311: 036_S_0976\n",
      "[LMCI] Processing subject 145/311: 036_S_1135\n",
      "[LMCI] Processing subject 146/311: 036_S_1240\n",
      "[LMCI] Processing subject 147/311: 037_S_0150\n",
      "[LMCI] Processing subject 148/311: 037_S_0501\n",
      "[LMCI] Processing subject 149/311: 037_S_0539\n",
      "[LMCI] Processing subject 150/311: 037_S_0552\n",
      "[LMCI] Processing subject 151/311: 037_S_0566\n",
      "[LMCI] Processing subject 152/311: 037_S_0588\n",
      "[LMCI] Processing subject 153/311: 037_S_1078\n",
      "[LMCI] Processing subject 154/311: 037_S_1225\n",
      "[LMCI] Processing subject 155/311: 037_S_1421\n",
      "[LMCI] Processing subject 156/311: 041_S_0282\n",
      "[LMCI] Processing subject 157/311: 041_S_0314\n",
      "[LMCI] Processing subject 158/311: 041_S_0446\n",
      "[LMCI] Processing subject 159/311: 041_S_0549\n",
      "[LMCI] Processing subject 160/311: 041_S_0598\n",
      "[LMCI] Processing subject 161/311: 041_S_0679\n",
      "[LMCI] Processing subject 162/311: 041_S_1010\n",
      "[LMCI] Processing subject 163/311: 041_S_1260\n",
      "[LMCI] Processing subject 164/311: 041_S_1412\n",
      "[LMCI] Processing subject 165/311: 041_S_1418\n",
      "[LMCI] Processing subject 166/311: 041_S_1423\n",
      "[LMCI] Processing subject 167/311: 041_S_1425\n",
      "[LMCI] Processing subject 168/311: 051_S_1040\n",
      "[LMCI] Processing subject 169/311: 051_S_1072\n",
      "[LMCI] Processing subject 170/311: 051_S_1131\n",
      "[LMCI] Processing subject 171/311: 051_S_1331\n",
      "[LMCI] Processing subject 172/311: 052_S_0671\n",
      "[LMCI] Processing subject 173/311: 052_S_0952\n",
      "[LMCI] Processing subject 174/311: 052_S_1054\n",
      "[LMCI] Processing subject 175/311: 052_S_1168\n",
      "[LMCI] Processing subject 176/311: 052_S_1346\n",
      "[LMCI] Processing subject 177/311: 052_S_1352\n",
      "[LMCI] Processing subject 178/311: 053_S_0389\n",
      "[LMCI] Processing subject 179/311: 053_S_0507\n",
      "[LMCI] Processing subject 180/311: 053_S_0621\n",
      "[LMCI] Processing subject 181/311: 053_S_0919\n",
      "[LMCI] Processing subject 182/311: 057_S_0464\n",
      "[LMCI] Processing subject 183/311: 057_S_0839\n",
      "[LMCI] Processing subject 184/311: 057_S_0941\n",
      "[LMCI] Processing subject 185/311: 057_S_1007\n",
      "[LMCI] Processing subject 186/311: 057_S_1217\n",
      "[LMCI] Processing subject 187/311: 057_S_1265\n",
      "[LMCI] Processing subject 188/311: 057_S_1269\n",
      "[LMCI] Processing subject 189/311: 062_S_1182\n",
      "[LMCI] Processing subject 190/311: 062_S_1299\n",
      "[LMCI] Processing subject 191/311: 067_S_0038\n",
      "[LMCI] Processing subject 192/311: 067_S_0077\n",
      "[LMCI] Processing subject 193/311: 067_S_0098\n",
      "[LMCI] Processing subject 194/311: 067_S_0176\n",
      "[LMCI] Processing subject 195/311: 067_S_0284\n",
      "[LMCI] Processing subject 196/311: 067_S_0290\n",
      "[LMCI] Processing subject 197/311: 067_S_0336\n",
      "[LMCI] Processing subject 198/311: 067_S_0607\n",
      "[LMCI] Processing subject 199/311: 068_S_0442\n",
      "[LMCI] Processing subject 200/311: 068_S_0872\n",
      "[LMCI] Processing subject 201/311: 073_S_0518\n",
      "[LMCI] Processing subject 202/311: 073_S_0746\n",
      "[LMCI] Processing subject 203/311: 073_S_0909\n",
      "[LMCI] Processing subject 204/311: 082_S_0928\n",
      "[LMCI] Processing subject 205/311: 082_S_1119\n",
      "[LMCI] Processing subject 206/311: 094_S_0434\n",
      "[LMCI] Processing subject 207/311: 094_S_0531\n",
      "[LMCI] Processing subject 208/311: 094_S_0921\n",
      "[LMCI] Processing subject 209/311: 094_S_1188\n",
      "[LMCI] Processing subject 210/311: 094_S_1293\n",
      "[LMCI] Processing subject 211/311: 094_S_1398\n",
      "[LMCI] Processing subject 212/311: 094_S_1417\n",
      "[LMCI] Processing subject 213/311: 098_S_0160\n",
      "[LMCI] Processing subject 214/311: 098_S_0269\n",
      "[LMCI] Processing subject 215/311: 098_S_0667\n",
      "[LMCI] Processing subject 216/311: 099_S_0051\n",
      "[LMCI] Processing subject 217/311: 099_S_0054\n",
      "[LMCI] Processing subject 218/311: 099_S_0060\n",
      "[LMCI] Processing subject 219/311: 099_S_0111\n",
      "[LMCI] Processing subject 220/311: 099_S_0291\n",
      "[LMCI] Processing subject 221/311: 099_S_0551\n",
      "[LMCI] Processing subject 222/311: 099_S_0880\n",
      "[LMCI] Processing subject 223/311: 099_S_1034\n",
      "[LMCI] Processing subject 224/311: 100_S_0006\n",
      "[LMCI] Processing subject 225/311: 100_S_0190\n",
      "[LMCI] Processing subject 226/311: 100_S_0296\n",
      "[LMCI] Processing subject 227/311: 100_S_0995\n",
      "[LMCI] Processing subject 228/311: 109_S_0950\n",
      "[LMCI] Processing subject 229/311: 109_S_1114\n",
      "[LMCI] Processing subject 230/311: 109_S_1183\n",
      "[LMCI] Processing subject 231/311: 109_S_1343\n",
      "[LMCI] Processing subject 232/311: 114_S_0378\n",
      "[LMCI] Processing subject 233/311: 114_S_0410\n",
      "[LMCI] Processing subject 234/311: 114_S_0458\n",
      "[LMCI] Processing subject 235/311: 114_S_1103\n",
      "[LMCI] Processing subject 236/311: 114_S_1106\n",
      "[LMCI] Processing subject 237/311: 114_S_1118\n",
      "[LMCI] Processing subject 238/311: 116_S_0361\n",
      "[LMCI] Processing subject 239/311: 116_S_0649\n",
      "[LMCI] Processing subject 240/311: 116_S_0752\n",
      "[LMCI] Processing subject 241/311: 116_S_0834\n",
      "[LMCI] Processing subject 242/311: 116_S_1243\n",
      "[LMCI] Processing subject 243/311: 116_S_1271\n",
      "[LMCI] Processing subject 244/311: 116_S_1315\n",
      "[LMCI] Processing subject 245/311: 121_S_1322\n",
      "[LMCI] Processing subject 246/311: 123_S_0050\n",
      "[LMCI] Processing subject 247/311: 123_S_0108\n",
      "[LMCI] Processing subject 248/311: 123_S_0390\n",
      "[LMCI] Processing subject 249/311: 123_S_1300\n",
      "[LMCI] Processing subject 250/311: 126_S_0708\n",
      "[LMCI] Processing subject 251/311: 126_S_0709\n",
      "[LMCI] Processing subject 252/311: 126_S_0865\n",
      "[LMCI] Processing subject 253/311: 126_S_1187\n",
      "[LMCI] Processing subject 254/311: 127_S_0112\n",
      "[LMCI] Processing subject 255/311: 127_S_0393\n",
      "[LMCI] Processing subject 256/311: 127_S_0394\n",
      "[LMCI] Processing subject 257/311: 127_S_0925\n",
      "[LMCI] Processing subject 258/311: 127_S_1032\n",
      "[LMCI] Processing subject 259/311: 127_S_1140\n",
      "[LMCI] Processing subject 260/311: 127_S_1419\n",
      "[LMCI] Processing subject 261/311: 127_S_1427\n",
      "[LMCI] Processing subject 262/311: 128_S_0947\n",
      "[LMCI] Processing subject 263/311: 128_S_1043\n",
      "[LMCI] Processing subject 264/311: 128_S_1088\n",
      "[LMCI] Processing subject 265/311: 128_S_1148\n",
      "[LMCI] Processing subject 266/311: 128_S_1407\n",
      "[LMCI] Processing subject 267/311: 128_S_1408\n",
      "[LMCI] Processing subject 268/311: 129_S_1246\n",
      "[LMCI] Processing subject 269/311: 130_S_0102\n",
      "[LMCI] Processing subject 270/311: 130_S_0423\n",
      "[LMCI] Processing subject 271/311: 130_S_0505\n",
      "[LMCI] Processing subject 272/311: 130_S_0783\n",
      "[LMCI] Processing subject 273/311: 131_S_0384\n",
      "[LMCI] Processing subject 274/311: 131_S_1389\n",
      "[LMCI] Processing subject 275/311: 132_S_0987\n",
      "[LMCI] Processing subject 276/311: 133_S_0629\n",
      "[LMCI] Processing subject 277/311: 133_S_0638\n",
      "[LMCI] Processing subject 278/311: 133_S_0727\n",
      "[LMCI] Processing subject 279/311: 133_S_0771\n",
      "[LMCI] Processing subject 280/311: 133_S_0792\n",
      "[LMCI] Processing subject 281/311: 133_S_0912\n",
      "[LMCI] Processing subject 282/311: 133_S_0913\n",
      "[LMCI] Processing subject 283/311: 136_S_0107\n",
      "[LMCI] Processing subject 284/311: 136_S_0195\n",
      "[LMCI] Processing subject 285/311: 136_S_0429\n",
      "[LMCI] Processing subject 286/311: 136_S_0579\n",
      "[LMCI] Processing subject 287/311: 136_S_0695\n",
      "[LMCI] Processing subject 288/311: 136_S_0873\n",
      "[LMCI] Processing subject 289/311: 136_S_0874\n",
      "[LMCI] Processing subject 290/311: 136_S_1227\n",
      "[LMCI] Processing subject 291/311: 137_S_0158\n",
      "[LMCI] Processing subject 292/311: 137_S_0443\n",
      "[LMCI] Processing subject 293/311: 137_S_0481\n",
      "[LMCI] Processing subject 294/311: 137_S_0631\n",
      "[LMCI] Processing subject 295/311: 137_S_0668\n",
      "[LMCI] Processing subject 296/311: 137_S_0669\n",
      "[LMCI] Processing subject 297/311: 137_S_0722\n",
      "[LMCI] Processing subject 298/311: 137_S_0800\n",
      "[LMCI] Processing subject 299/311: 137_S_0825\n",
      "[LMCI] Processing subject 300/311: 137_S_0973\n",
      "[LMCI] Processing subject 301/311: 137_S_0994\n",
      "[LMCI] Processing subject 302/311: 137_S_1414\n",
      "[LMCI] Processing subject 303/311: 137_S_1426\n",
      "[LMCI] Processing subject 304/311: 141_S_0851\n",
      "[LMCI] Processing subject 305/311: 141_S_0915\n",
      "[LMCI] Processing subject 306/311: 141_S_0982\n",
      "[LMCI] Processing subject 307/311: 141_S_1004\n",
      "[LMCI] Processing subject 308/311: 141_S_1052\n",
      "[LMCI] Processing subject 309/311: 141_S_1245\n",
      "[LMCI] Processing subject 310/311: 141_S_1255\n",
      "[LMCI] Processing subject 311/311: 941_S_1311\n"
     ]
    }
   ],
   "source": [
    "feature_df_ad   = build_feature_matrix_single_class(r\"C:\\Users\\ADMIN\\Documents\\Alz_work\\DATASET\\FINAL_BALANCED_DATASET\\FINAL_BALANCED_DATASET\\AD\",   \"AD\",   vgg16, resnet50, transform, device)\n",
    "feature_df_cn   = build_feature_matrix_single_class(r\"C:\\Users\\ADMIN\\Documents\\Alz_work\\DATASET\\FINAL_BALANCED_DATASET\\FINAL_BALANCED_DATASET\\CN\",   \"CN\",   vgg16, resnet50, transform, device)\n",
    "feature_df_lmci = build_feature_matrix_single_class(r\"C:\\Users\\ADMIN\\Documents\\Alz_work\\DATASET\\FINAL_BALANCED_DATASET\\FINAL_BALANCED_DATASET\\LMCI\", \"LMCI\", vgg16, resnet50, transform, device)\n",
    "\n",
    "feature_df = pd.concat([feature_df_ad, feature_df_cn, feature_df_lmci], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25c7d782",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df_ad.to_pickle(\"features_ad.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aa6b38",
   "metadata": {},
   "source": [
    "Loading Pretrained Vision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71135fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to C:\\Users\\ADMIN/.cache\\torch\\hub\\checkpoints\\vit_b_16-c867db91.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 330M/330M [00:03<00:00, 106MB/s]  \n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "\n",
    "# Load pretrained ViT model\n",
    "vit_weights = ViT_B_16_Weights.IMAGENET1K_V1\n",
    "vit_model = vit_b_16(weights=vit_weights)\n",
    "vit_model.eval().to(device)\n",
    "\n",
    "# Remove classification head to get feature embeddings\n",
    "vit_model = torch.nn.Sequential(*list(vit_model.children())[:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c32033d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "  (1): Encoder(\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): Sequential(\n",
      "      (encoder_layer_0): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_1): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_2): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_3): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_4): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_5): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_6): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_7): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_8): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_9): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_10): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_11): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(vit_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cd1472",
   "metadata": {},
   "source": [
    "Defining preprocessing pipeline for VIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cda42226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[256]\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BILINEAR\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import ViT_B_16_Weights\n",
    "\n",
    "# Load ViT preprocessing transforms\n",
    "vit_weights = ViT_B_16_Weights.IMAGENET1K_V1\n",
    "vit_transform = vit_weights.transforms()\n",
    "\n",
    "# Optional: inspect the transform pipeline\n",
    "print(vit_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68c05017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img_path = r\"C:\\Users\\ADMIN\\Documents\\Alz_work\\DATASET\\FINAL_BALANCED_DATASET\\FINAL_BALANCED_DATASET\\AD\\002_S_0619\\sagittal_slices\\sagittal_000.png\"\n",
    "img = Image.open(img_path).convert('RGB')  # ViT expects RGB\n",
    "tensor = vit_transform(img).unsqueeze(0).to(device)\n",
    "print(tensor.shape)  # Should be [1, 3, 224, 224]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0edc9c",
   "metadata": {},
   "source": [
    "Slice-Level Feature Extraction Using ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15873225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vit_features(img_path, vit_model, vit_transform, device):\n",
    "    try:\n",
    "        # Load and preprocess image\n",
    "        img = Image.open(img_path).convert('RGB')  # ViT expects RGB\n",
    "        img = vit_transform(img).unsqueeze(0).to(device)  # Add batch dimension\n",
    "\n",
    "        # Extract features\n",
    "        with torch.no_grad():\n",
    "            vit_feat = vit_model(img).view(-1).cpu().numpy()\n",
    "\n",
    "        return vit_feat\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ViT error on {img_path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82df9a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT error on C:\\Users\\ADMIN\\Documents\\Alz_work\\DATASET\\FINAL_BALANCED_DATASET\\FINAL_BALANCED_DATASET\\AD\\002_S_0619\\sagittal_slices\\sagittal_000.png: Expected (batch_size, seq_length, hidden_dim) got torch.Size([1, 768, 14, 14])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m vit_feat \u001b[38;5;241m=\u001b[39m extract_vit_features(img_path, vit_model, vit_transform, device)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mvit_feat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)  \u001b[38;5;66;03m# Should be (768,) for ViT-B/16\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "vit_feat = extract_vit_features(img_path, vit_model, vit_transform, device)\n",
    "print(vit_feat.shape)  # Should be (768,) for ViT-B/16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad70a230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.exists(img_path))  # Should return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8dc1a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vit_features(img_path, vit_model, vit_transform, device):\n",
    "    try:\n",
    "        print(f\"Loading image: {img_path}\")\n",
    "        img = Image.open(img_path).convert('RGB')  # ViT expects RGB\n",
    "        img = vit_transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            vit_feat = vit_model(img).view(-1).cpu().numpy()\n",
    "\n",
    "        return vit_feat\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ViT error on {img_path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8344cca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image: C:\\Users\\ADMIN\\Documents\\Alz_work\\DATASET\\FINAL_BALANCED_DATASET\\FINAL_BALANCED_DATASET\\AD\\002_S_0619\\sagittal_slices\\sagittal_000.png\n",
      "ViT error on C:\\Users\\ADMIN\\Documents\\Alz_work\\DATASET\\FINAL_BALANCED_DATASET\\FINAL_BALANCED_DATASET\\AD\\002_S_0619\\sagittal_slices\\sagittal_000.png: Expected (batch_size, seq_length, hidden_dim) got torch.Size([1, 768, 14, 14])\n",
      "Feature extraction failed or returned None.\n"
     ]
    }
   ],
   "source": [
    "vit_feat = extract_vit_features(img_path, vit_model, vit_transform, device)\n",
    "\n",
    "if vit_feat is not None:\n",
    "    print(f\"Feature shape: {vit_feat.shape}\")\n",
    "else:\n",
    "    print(\"Feature extraction failed or returned None.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ee56f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): Sequential(\n",
       "      (encoder_layer_0): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_1): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_2): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_3): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_4): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_5): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_6): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_7): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_8): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_9): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_10): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_11): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (heads): Sequential(\n",
       "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "\n",
    "# Load full model with weights\n",
    "vit_weights = ViT_B_16_Weights.IMAGENET1K_V1\n",
    "vit_model = vit_b_16(weights=vit_weights)\n",
    "vit_model.eval().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a916e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vit_features(img_path, vit_model, vit_transform, device):\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = vit_transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            vit_feat = vit_model.forward_features(img).view(-1).cpu().numpy()\n",
    "            return vit_feat\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ViT error on {img_path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d8f466f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT error on C:\\Users\\ADMIN\\Documents\\Alz_work\\DATASET\\FINAL_BALANCED_DATASET\\FINAL_BALANCED_DATASET\\AD\\002_S_0619\\sagittal_slices\\sagittal_000.png: 'VisionTransformer' object has no attribute 'forward_features'\n",
      "ViT feature extraction failed.\n"
     ]
    }
   ],
   "source": [
    "vit_feat = extract_vit_features(img_path, vit_model, vit_transform, device)\n",
    "if vit_feat is not None:\n",
    "    print(f\"ViT feature shape: {vit_feat.shape}\")  # Should be (768,)\n",
    "else:\n",
    "    print(\"ViT feature extraction failed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05c9be08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vit_features(img_path, vit_model, vit_transform, device):\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = vit_transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Get patch embeddings\n",
    "            x = vit_model._process_input(img)  # [B, num_patches, hidden_dim]\n",
    "            batch_size = x.shape[0]\n",
    "\n",
    "            # Add CLS token\n",
    "            cls_token = vit_model.cls_token.expand(batch_size, -1, -1)\n",
    "            x = torch.cat((cls_token, x), dim=1)\n",
    "\n",
    "            # Add positional embeddings\n",
    "            x = x + vit_model.encoder.pos_embedding\n",
    "            x = vit_model.encoder.dropout(x)\n",
    "\n",
    "            # Pass through transformer encoder\n",
    "            x = vit_model.encoder.ln(vit_model.encoder.layers(x))\n",
    "\n",
    "            # Extract CLS token embedding\n",
    "            vit_feat = x[:, 0].view(-1).cpu().numpy()\n",
    "            return vit_feat\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ViT error on {img_path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8faadafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT error on C:\\Users\\ADMIN\\Documents\\Alz_work\\DATASET\\FINAL_BALANCED_DATASET\\FINAL_BALANCED_DATASET\\AD\\002_S_0619\\sagittal_slices\\sagittal_000.png: 'VisionTransformer' object has no attribute 'cls_token'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m vit_feat \u001b[38;5;241m=\u001b[39m extract_vit_features(img_path, vit_model, vit_transform, device)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mvit_feat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)  \u001b[38;5;66;03m# Should be (768,)\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "vit_feat = extract_vit_features(img_path, vit_model, vit_transform, device)\n",
    "print(vit_feat.shape)  # Should be (768,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4423f76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting timm\n",
      "  Downloading timm-1.0.24-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\admin\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from timm) (2.7.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\admin\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from timm) (0.22.1+cu118)\n",
      "Collecting pyyaml (from timm)\n",
      "  Downloading pyyaml-6.0.3-cp310-cp310-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting huggingface_hub (from timm)\n",
      "  Downloading huggingface_hub-1.3.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors (from timm)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from huggingface_hub->timm) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from huggingface_hub->timm) (2025.9.0)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface_hub->timm)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from huggingface_hub->timm)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\admin\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from huggingface_hub->timm) (25.0)\n",
      "Collecting shellingham (from huggingface_hub->timm)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\admin\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Collecting typer-slim (from huggingface_hub->timm)\n",
      "  Downloading typer_slim-0.21.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\admin\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from huggingface_hub->timm) (4.15.0)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->huggingface_hub->timm)\n",
      "  Downloading anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->huggingface_hub->timm)\n",
      "  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->huggingface_hub->timm)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<1,>=0.23.0->huggingface_hub->timm)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub->timm)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub->timm) (0.4.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\admin\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->huggingface_hub->timm) (1.3.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\admin\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from torch->timm) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from torch->timm) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from torch->timm) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from jinja2->torch->timm) (2.1.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from torchvision->timm) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\admin\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from torchvision->timm) (11.3.0)\n",
      "Collecting click>=8.0.0 (from typer-slim->huggingface_hub->timm)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading timm-1.0.24-py3-none-any.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.6/2.6 MB 74.1 MB/s  0:00:00\n",
      "Downloading huggingface_hub-1.3.3-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.6/536.6 kB ?  0:00:00\n",
      "Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.9/2.9 MB 85.3 MB/s  0:00:00\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading pyyaml-6.0.3-cp310-cp310-win_amd64.whl (158 kB)\n",
      "Downloading anyio-4.12.1-py3-none-any.whl (113 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading typer_slim-0.21.1-py3-none-any.whl (47 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Installing collected packages: shellingham, safetensors, pyyaml, idna, hf-xet, h11, click, certifi, typer-slim, httpcore, anyio, httpx, huggingface_hub, timm\n",
      "\n",
      "   ----- ----------------------------------  2/14 [pyyaml]\n",
      "   -------- -------------------------------  3/14 [idna]\n",
      "   ----------------- ----------------------  6/14 [click]\n",
      "   ---------------------- -----------------  8/14 [typer-slim]\n",
      "   ------------------------- --------------  9/14 [httpcore]\n",
      "   ---------------------------- ----------- 10/14 [anyio]\n",
      "   ---------------------------- ----------- 10/14 [anyio]\n",
      "   ---------------------------------- ----- 12/14 [huggingface_hub]\n",
      "   ---------------------------------- ----- 12/14 [huggingface_hub]\n",
      "   ---------------------------------- ----- 12/14 [huggingface_hub]\n",
      "   ---------------------------------- ----- 12/14 [huggingface_hub]\n",
      "   ------------------------------------- -- 13/14 [timm]\n",
      "   ------------------------------------- -- 13/14 [timm]\n",
      "   ------------------------------------- -- 13/14 [timm]\n",
      "   ------------------------------------- -- 13/14 [timm]\n",
      "   ------------------------------------- -- 13/14 [timm]\n",
      "   ------------------------------------- -- 13/14 [timm]\n",
      "   ------------------------------------- -- 13/14 [timm]\n",
      "   ------------------------------------- -- 13/14 [timm]\n",
      "   ------------------------------------- -- 13/14 [timm]\n",
      "   ------------------------------------- -- 13/14 [timm]\n",
      "   ---------------------------------------- 14/14 [timm]\n",
      "\n",
      "Successfully installed anyio-4.12.1 certifi-2026.1.4 click-8.3.1 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface_hub-1.3.3 idna-3.11 pyyaml-6.0.3 safetensors-0.7.0 shellingham-1.5.4 timm-1.0.24 typer-slim-0.21.1\n"
     ]
    }
   ],
   "source": [
    "!pip install timm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f230b42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\ADMIN\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ADMIN\\.cache\\huggingface\\hub\\models--timm--vit_base_patch16_224.augreg2_in21k_ft_in1k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (patch_drop): Identity()\n",
       "  (norm_pre): Identity()\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (fc_norm): Identity()\n",
       "  (head_drop): Dropout(p=0.0, inplace=False)\n",
       "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "# Load pretrained ViT base model\n",
    "vit_model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
    "vit_model.eval().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b7d98ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vit_features(img_path, vit_model, vit_transform, device):\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = vit_transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            vit_feat = vit_model.forward_features(img).view(-1).cpu().numpy()\n",
    "            return vit_feat\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ViT error on {img_path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eadef61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT feature shape: (151296,)\n"
     ]
    }
   ],
   "source": [
    "vit_feat = extract_vit_features(img_path, vit_model, vit_transform, device)\n",
    "if vit_feat is not None:\n",
    "    print(f\"ViT feature shape: {vit_feat.shape}\")  # Should be (768,)\n",
    "else:\n",
    "    print(\"ViT feature extraction failed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0b2a74",
   "metadata": {},
   "source": [
    "Aggregating ViT Features Across Slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d5f214e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_subject_vit(subject_path, vit_model, vit_transform, device):\n",
    "    # Check for nested 'sagittal_slices' folder\n",
    "    slice_dir = os.path.join(subject_path, 'sagittal_slices')\n",
    "    if os.path.exists(slice_dir):\n",
    "        slice_files = sorted(os.listdir(slice_dir))\n",
    "    else:\n",
    "        slice_dir = subject_path\n",
    "        slice_files = sorted([f for f in os.listdir(slice_dir) if f.endswith('.png')])\n",
    "\n",
    "    if len(slice_files) == 0:\n",
    "        print(f\"No slices found in: {slice_dir}\")\n",
    "        return None\n",
    "\n",
    "    features = []\n",
    "    for slice_file in slice_files:\n",
    "        slice_path = os.path.join(slice_dir, slice_file)\n",
    "        feat = extract_vit_features(slice_path, vit_model, vit_transform, device)\n",
    "        if feat is not None:\n",
    "            features.append(feat)\n",
    "\n",
    "    if features:\n",
    "        subject_vector = np.mean(features, axis=0)  # You can swap with max or median pooling\n",
    "        return subject_vector\n",
    "    else:\n",
    "        print(f\"All ViT slices failed for: {subject_path}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15e9315",
   "metadata": {},
   "source": [
    "Building Full ViT Feature Matrix Across All Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5017a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def build_vit_feature_matrix(base_path, vit_model, vit_transform, device):\n",
    "    classes = ['AD', 'CN', 'LMCI']\n",
    "    data = []\n",
    "\n",
    "    for label in classes:\n",
    "        class_path = os.path.join(base_path, label)\n",
    "        subjects = sorted(os.listdir(class_path))\n",
    "\n",
    "        for i, subject in enumerate(subjects):\n",
    "            subject_path = os.path.join(class_path, subject)\n",
    "            print(f\"[ViT-{label}] Processing subject {i+1}/{len(subjects)}: {subject}\")\n",
    "            feat = process_subject_vit(subject_path, vit_model, vit_transform, device)\n",
    "\n",
    "            if feat is not None:\n",
    "                data.append({'features': feat, 'label': label, 'subject_id': subject})\n",
    "            else:\n",
    "                print(f\"Skipped subject due to missing or invalid ViT data: {subject_path}\")\n",
    "\n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "adf2d5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ViT-AD] Processing subject 1/311: 002_S_0619\n",
      "[ViT-AD] Processing subject 2/311: 002_S_0619_aug1\n",
      "[ViT-AD] Processing subject 3/311: 002_S_0619_aug2\n",
      "[ViT-AD] Processing subject 4/311: 002_S_0816\n",
      "[ViT-AD] Processing subject 5/311: 002_S_0816_aug0\n",
      "[ViT-AD] Processing subject 6/311: 002_S_0816_aug1\n",
      "[ViT-AD] Processing subject 7/311: 002_S_0938\n",
      "[ViT-AD] Processing subject 8/311: 002_S_0938_aug0\n",
      "[ViT-AD] Processing subject 9/311: 002_S_0938_aug1\n",
      "[ViT-AD] Processing subject 10/311: 002_S_1018\n",
      "[ViT-AD] Processing subject 11/311: 002_S_1018_aug0\n",
      "[ViT-AD] Processing subject 12/311: 002_S_1018_aug1\n",
      "[ViT-AD] Processing subject 13/311: 005_S_0221\n",
      "[ViT-AD] Processing subject 14/311: 005_S_0221_aug0\n",
      "[ViT-AD] Processing subject 15/311: 005_S_0221_aug1\n",
      "[ViT-AD] Processing subject 16/311: 005_S_0221_aug2\n",
      "[ViT-AD] Processing subject 17/311: 005_S_0814\n",
      "[ViT-AD] Processing subject 18/311: 005_S_0814_aug0\n",
      "[ViT-AD] Processing subject 19/311: 005_S_0814_aug1\n",
      "[ViT-AD] Processing subject 20/311: 005_S_0814_aug2\n",
      "[ViT-AD] Processing subject 21/311: 005_S_1341\n",
      "[ViT-AD] Processing subject 22/311: 005_S_1341_aug0\n",
      "[ViT-AD] Processing subject 23/311: 005_S_1341_aug1\n",
      "[ViT-AD] Processing subject 24/311: 005_S_1341_aug2\n",
      "[ViT-AD] Processing subject 25/311: 006_S_0547\n",
      "[ViT-AD] Processing subject 26/311: 006_S_0547_aug0\n",
      "[ViT-AD] Processing subject 27/311: 006_S_0547_aug1\n",
      "[ViT-AD] Processing subject 28/311: 006_S_0547_aug2\n",
      "[ViT-AD] Processing subject 29/311: 007_S_0316\n",
      "[ViT-AD] Processing subject 30/311: 007_S_0316_aug0\n",
      "[ViT-AD] Processing subject 31/311: 007_S_0316_aug2\n",
      "[ViT-AD] Processing subject 32/311: 007_S_1339\n",
      "[ViT-AD] Processing subject 33/311: 007_S_1339_aug1\n",
      "[ViT-AD] Processing subject 34/311: 007_S_1339_aug2\n",
      "[ViT-AD] Processing subject 35/311: 010_S_0786\n",
      "[ViT-AD] Processing subject 36/311: 010_S_0786_aug0\n",
      "[ViT-AD] Processing subject 37/311: 010_S_0786_aug1\n",
      "[ViT-AD] Processing subject 38/311: 010_S_0786_aug2\n",
      "[ViT-AD] Processing subject 39/311: 010_S_0829\n",
      "[ViT-AD] Processing subject 40/311: 010_S_0829_aug1\n",
      "[ViT-AD] Processing subject 41/311: 011_S_0003\n",
      "[ViT-AD] Processing subject 42/311: 011_S_0003_aug1\n",
      "[ViT-AD] Processing subject 43/311: 011_S_0003_aug2\n",
      "[ViT-AD] Processing subject 44/311: 011_S_0010\n",
      "[ViT-AD] Processing subject 45/311: 011_S_0010_aug0\n",
      "[ViT-AD] Processing subject 46/311: 011_S_0010_aug1\n",
      "[ViT-AD] Processing subject 47/311: 011_S_0010_aug2\n",
      "[ViT-AD] Processing subject 48/311: 011_S_0053\n",
      "[ViT-AD] Processing subject 49/311: 011_S_0053_aug0\n",
      "[ViT-AD] Processing subject 50/311: 011_S_0053_aug1\n",
      "[ViT-AD] Processing subject 51/311: 011_S_0053_aug2\n",
      "[ViT-AD] Processing subject 52/311: 011_S_0183\n",
      "[ViT-AD] Processing subject 53/311: 011_S_0183_aug0\n",
      "[ViT-AD] Processing subject 54/311: 011_S_0183_aug1\n",
      "[ViT-AD] Processing subject 55/311: 011_S_0183_aug2\n",
      "[ViT-AD] Processing subject 56/311: 012_S_0689\n",
      "[ViT-AD] Processing subject 57/311: 012_S_0689_aug2\n",
      "[ViT-AD] Processing subject 58/311: 012_S_0712\n",
      "[ViT-AD] Processing subject 59/311: 012_S_0712_aug0\n",
      "[ViT-AD] Processing subject 60/311: 012_S_0720\n",
      "[ViT-AD] Processing subject 61/311: 012_S_0720_aug1\n",
      "[ViT-AD] Processing subject 62/311: 012_S_0803\n",
      "[ViT-AD] Processing subject 63/311: 012_S_0803_aug1\n",
      "[ViT-AD] Processing subject 64/311: 012_S_0803_aug2\n",
      "[ViT-AD] Processing subject 65/311: 013_S_1205\n",
      "[ViT-AD] Processing subject 66/311: 013_S_1205_aug1\n",
      "[ViT-AD] Processing subject 67/311: 014_S_0328\n",
      "[ViT-AD] Processing subject 68/311: 014_S_0328_aug0\n",
      "[ViT-AD] Processing subject 69/311: 014_S_0328_aug1\n",
      "[ViT-AD] Processing subject 70/311: 014_S_0328_aug2\n",
      "[ViT-AD] Processing subject 71/311: 014_S_1095\n",
      "[ViT-AD] Processing subject 72/311: 014_S_1095_aug0\n",
      "[ViT-AD] Processing subject 73/311: 014_S_1095_aug1\n",
      "[ViT-AD] Processing subject 74/311: 014_S_1095_aug2\n",
      "[ViT-AD] Processing subject 75/311: 016_S_0991\n",
      "[ViT-AD] Processing subject 76/311: 016_S_0991_aug0\n",
      "[ViT-AD] Processing subject 77/311: 016_S_0991_aug1\n",
      "[ViT-AD] Processing subject 78/311: 016_S_0991_aug2\n",
      "[ViT-AD] Processing subject 79/311: 018_S_0286\n",
      "[ViT-AD] Processing subject 80/311: 018_S_0286_aug1\n",
      "[ViT-AD] Processing subject 81/311: 018_S_0335\n",
      "[ViT-AD] Processing subject 82/311: 018_S_0335_aug0\n",
      "[ViT-AD] Processing subject 83/311: 018_S_0335_aug1\n",
      "[ViT-AD] Processing subject 84/311: 018_S_0335_aug2\n",
      "[ViT-AD] Processing subject 85/311: 018_S_0633\n",
      "[ViT-AD] Processing subject 86/311: 018_S_0633_aug0\n",
      "[ViT-AD] Processing subject 87/311: 018_S_0633_aug1\n",
      "[ViT-AD] Processing subject 88/311: 018_S_0682\n",
      "[ViT-AD] Processing subject 89/311: 018_S_0682_aug0\n",
      "[ViT-AD] Processing subject 90/311: 018_S_0682_aug1\n",
      "[ViT-AD] Processing subject 91/311: 018_S_0682_aug2\n",
      "[ViT-AD] Processing subject 92/311: 020_S_0213\n",
      "[ViT-AD] Processing subject 93/311: 020_S_0213_aug0\n",
      "[ViT-AD] Processing subject 94/311: 020_S_0213_aug2\n",
      "[ViT-AD] Processing subject 95/311: 021_S_0343\n",
      "[ViT-AD] Processing subject 96/311: 021_S_0343_aug1\n",
      "[ViT-AD] Processing subject 97/311: 021_S_0343_aug2\n",
      "[ViT-AD] Processing subject 98/311: 021_S_0642\n",
      "[ViT-AD] Processing subject 99/311: 021_S_0642_aug0\n",
      "[ViT-AD] Processing subject 100/311: 021_S_0642_aug1\n",
      "[ViT-AD] Processing subject 101/311: 021_S_0642_aug2\n",
      "[ViT-AD] Processing subject 102/311: 021_S_0753\n",
      "[ViT-AD] Processing subject 103/311: 021_S_0753_aug0\n",
      "[ViT-AD] Processing subject 104/311: 021_S_0753_aug1\n",
      "[ViT-AD] Processing subject 105/311: 021_S_0753_aug2\n",
      "[ViT-AD] Processing subject 106/311: 021_S_1109\n",
      "[ViT-AD] Processing subject 107/311: 021_S_1109_aug1\n",
      "[ViT-AD] Processing subject 108/311: 021_S_1109_aug2\n",
      "[ViT-AD] Processing subject 109/311: 022_S_0129\n",
      "[ViT-AD] Processing subject 110/311: 022_S_0129_aug1\n",
      "[ViT-AD] Processing subject 111/311: 022_S_0129_aug2\n",
      "[ViT-AD] Processing subject 112/311: 023_S_0083\n",
      "[ViT-AD] Processing subject 113/311: 023_S_0083_aug0\n",
      "[ViT-AD] Processing subject 114/311: 023_S_0083_aug2\n",
      "[ViT-AD] Processing subject 115/311: 023_S_0084\n",
      "[ViT-AD] Processing subject 116/311: 023_S_0084_aug0\n",
      "[ViT-AD] Processing subject 117/311: 023_S_0084_aug1\n",
      "[ViT-AD] Processing subject 118/311: 023_S_0139\n",
      "[ViT-AD] Processing subject 119/311: 023_S_0139_aug1\n",
      "[ViT-AD] Processing subject 120/311: 023_S_0916\n",
      "[ViT-AD] Processing subject 121/311: 023_S_0916_aug0\n",
      "[ViT-AD] Processing subject 122/311: 023_S_0916_aug1\n",
      "[ViT-AD] Processing subject 123/311: 023_S_0916_aug2\n",
      "[ViT-AD] Processing subject 124/311: 023_S_1262\n",
      "[ViT-AD] Processing subject 125/311: 024_S_1171\n",
      "[ViT-AD] Processing subject 126/311: 024_S_1171_aug0\n",
      "[ViT-AD] Processing subject 127/311: 024_S_1171_aug2\n",
      "[ViT-AD] Processing subject 128/311: 024_S_1307\n",
      "[ViT-AD] Processing subject 129/311: 027_S_0404\n",
      "[ViT-AD] Processing subject 130/311: 027_S_0404_aug1\n",
      "[ViT-AD] Processing subject 131/311: 027_S_0404_aug2\n",
      "[ViT-AD] Processing subject 132/311: 027_S_0850\n",
      "[ViT-AD] Processing subject 133/311: 027_S_0850_aug0\n",
      "[ViT-AD] Processing subject 134/311: 027_S_0850_aug1\n",
      "[ViT-AD] Processing subject 135/311: 027_S_0850_aug2\n",
      "[ViT-AD] Processing subject 136/311: 027_S_1081\n",
      "[ViT-AD] Processing subject 137/311: 027_S_1081_aug0\n",
      "[ViT-AD] Processing subject 138/311: 027_S_1082\n",
      "[ViT-AD] Processing subject 139/311: 027_S_1082_aug0\n",
      "[ViT-AD] Processing subject 140/311: 027_S_1082_aug2\n",
      "[ViT-AD] Processing subject 141/311: 027_S_1254\n",
      "[ViT-AD] Processing subject 142/311: 027_S_1254_aug0\n",
      "[ViT-AD] Processing subject 143/311: 027_S_1254_aug1\n",
      "[ViT-AD] Processing subject 144/311: 027_S_1254_aug2\n",
      "[ViT-AD] Processing subject 145/311: 027_S_1385\n",
      "[ViT-AD] Processing subject 146/311: 027_S_1385_aug0\n",
      "[ViT-AD] Processing subject 147/311: 027_S_1385_aug1\n",
      "[ViT-AD] Processing subject 148/311: 027_S_1385_aug2\n",
      "[ViT-AD] Processing subject 149/311: 029_S_0836\n",
      "[ViT-AD] Processing subject 150/311: 029_S_0836_aug0\n",
      "[ViT-AD] Processing subject 151/311: 029_S_0836_aug1\n",
      "[ViT-AD] Processing subject 152/311: 029_S_0836_aug2\n",
      "[ViT-AD] Processing subject 153/311: 029_S_0999\n",
      "[ViT-AD] Processing subject 154/311: 029_S_0999_aug0\n",
      "[ViT-AD] Processing subject 155/311: 029_S_0999_aug1\n",
      "[ViT-AD] Processing subject 156/311: 029_S_0999_aug2\n",
      "[ViT-AD] Processing subject 157/311: 029_S_1056\n",
      "[ViT-AD] Processing subject 158/311: 029_S_1056_aug0\n",
      "[ViT-AD] Processing subject 159/311: 031_S_0321\n",
      "[ViT-AD] Processing subject 160/311: 031_S_0321_aug0\n",
      "[ViT-AD] Processing subject 161/311: 031_S_0321_aug2\n",
      "[ViT-AD] Processing subject 162/311: 031_S_0554\n",
      "[ViT-AD] Processing subject 163/311: 031_S_0554_aug1\n",
      "[ViT-AD] Processing subject 164/311: 031_S_0554_aug2\n",
      "[ViT-AD] Processing subject 165/311: 031_S_1209\n",
      "[ViT-AD] Processing subject 166/311: 031_S_1209_aug0\n",
      "[ViT-AD] Processing subject 167/311: 031_S_1209_aug1\n",
      "[ViT-AD] Processing subject 168/311: 031_S_1209_aug2\n",
      "[ViT-AD] Processing subject 169/311: 032_S_0147\n",
      "[ViT-AD] Processing subject 170/311: 032_S_0147_aug0\n",
      "[ViT-AD] Processing subject 171/311: 032_S_0147_aug1\n",
      "[ViT-AD] Processing subject 172/311: 032_S_0147_aug2\n",
      "[ViT-AD] Processing subject 173/311: 032_S_0400\n",
      "[ViT-AD] Processing subject 174/311: 032_S_0400_aug0\n",
      "[ViT-AD] Processing subject 175/311: 032_S_0400_aug1\n",
      "[ViT-AD] Processing subject 176/311: 032_S_0400_aug2\n",
      "[ViT-AD] Processing subject 177/311: 032_S_1101\n",
      "[ViT-AD] Processing subject 178/311: 032_S_1101_aug0\n",
      "[ViT-AD] Processing subject 179/311: 032_S_1101_aug1\n",
      "[ViT-AD] Processing subject 180/311: 032_S_1101_aug2\n",
      "[ViT-AD] Processing subject 181/311: 033_S_0724\n",
      "[ViT-AD] Processing subject 182/311: 033_S_0724_aug0\n",
      "[ViT-AD] Processing subject 183/311: 033_S_0724_aug1\n",
      "[ViT-AD] Processing subject 184/311: 033_S_0724_aug2\n",
      "[ViT-AD] Processing subject 185/311: 033_S_0733\n",
      "[ViT-AD] Processing subject 186/311: 033_S_0733_aug0\n",
      "[ViT-AD] Processing subject 187/311: 033_S_0733_aug1\n",
      "[ViT-AD] Processing subject 188/311: 033_S_0739\n",
      "[ViT-AD] Processing subject 189/311: 033_S_0739_aug0\n",
      "[ViT-AD] Processing subject 190/311: 033_S_0739_aug1\n",
      "[ViT-AD] Processing subject 191/311: 033_S_0739_aug2\n",
      "[ViT-AD] Processing subject 192/311: 033_S_0889\n",
      "[ViT-AD] Processing subject 193/311: 033_S_0889_aug0\n",
      "[ViT-AD] Processing subject 194/311: 033_S_0889_aug2\n",
      "[ViT-AD] Processing subject 195/311: 033_S_1281\n",
      "[ViT-AD] Processing subject 196/311: 033_S_1281_aug1\n",
      "[ViT-AD] Processing subject 197/311: 033_S_1281_aug2\n",
      "[ViT-AD] Processing subject 198/311: 033_S_1283\n",
      "[ViT-AD] Processing subject 199/311: 033_S_1283_aug1\n",
      "[ViT-AD] Processing subject 200/311: 033_S_1283_aug2\n",
      "[ViT-AD] Processing subject 201/311: 033_S_1285\n",
      "[ViT-AD] Processing subject 202/311: 033_S_1285_aug0\n",
      "[ViT-AD] Processing subject 203/311: 033_S_1285_aug1\n",
      "[ViT-AD] Processing subject 204/311: 033_S_1285_aug2\n",
      "[ViT-AD] Processing subject 205/311: 033_S_1308\n",
      "[ViT-AD] Processing subject 206/311: 033_S_1308_aug1\n",
      "[ViT-AD] Processing subject 207/311: 033_S_1308_aug2\n",
      "[ViT-AD] Processing subject 208/311: 035_S_0341\n",
      "[ViT-AD] Processing subject 209/311: 035_S_0341_aug0\n",
      "[ViT-AD] Processing subject 210/311: 035_S_0341_aug1\n",
      "[ViT-AD] Processing subject 211/311: 035_S_0341_aug2\n",
      "[ViT-AD] Processing subject 212/311: 036_S_0577\n",
      "[ViT-AD] Processing subject 213/311: 036_S_0577_aug0\n",
      "[ViT-AD] Processing subject 214/311: 036_S_0577_aug2\n",
      "[ViT-AD] Processing subject 215/311: 036_S_0759\n",
      "[ViT-AD] Processing subject 216/311: 036_S_0759_aug0\n",
      "[ViT-AD] Processing subject 217/311: 036_S_0759_aug1\n",
      "[ViT-AD] Processing subject 218/311: 036_S_0760\n",
      "[ViT-AD] Processing subject 219/311: 036_S_0760_aug0\n",
      "[ViT-AD] Processing subject 220/311: 036_S_0760_aug2\n",
      "[ViT-AD] Processing subject 221/311: 036_S_1001\n",
      "[ViT-AD] Processing subject 222/311: 036_S_1001_aug2\n",
      "[ViT-AD] Processing subject 223/311: 037_S_0627\n",
      "[ViT-AD] Processing subject 224/311: 037_S_0627_aug0\n",
      "[ViT-AD] Processing subject 225/311: 037_S_0627_aug1\n",
      "[ViT-AD] Processing subject 226/311: 037_S_0627_aug2\n",
      "[ViT-AD] Processing subject 227/311: 041_S_1368\n",
      "[ViT-AD] Processing subject 228/311: 041_S_1368_aug0\n",
      "[ViT-AD] Processing subject 229/311: 041_S_1368_aug1\n",
      "[ViT-AD] Processing subject 230/311: 051_S_1296\n",
      "[ViT-AD] Processing subject 231/311: 051_S_1296_aug0\n",
      "[ViT-AD] Processing subject 232/311: 051_S_1296_aug1\n",
      "[ViT-AD] Processing subject 233/311: 051_S_1296_aug2\n",
      "[ViT-AD] Processing subject 234/311: 053_S_1044\n",
      "[ViT-AD] Processing subject 235/311: 053_S_1044_aug0\n",
      "[ViT-AD] Processing subject 236/311: 053_S_1044_aug1\n",
      "[ViT-AD] Processing subject 237/311: 053_S_1044_aug2\n",
      "[ViT-AD] Processing subject 238/311: 057_S_0474\n",
      "[ViT-AD] Processing subject 239/311: 057_S_0474_aug0\n",
      "[ViT-AD] Processing subject 240/311: 057_S_0474_aug1\n",
      "[ViT-AD] Processing subject 241/311: 057_S_1371\n",
      "[ViT-AD] Processing subject 242/311: 057_S_1371_aug0\n",
      "[ViT-AD] Processing subject 243/311: 057_S_1371_aug1\n",
      "[ViT-AD] Processing subject 244/311: 057_S_1371_aug2\n",
      "[ViT-AD] Processing subject 245/311: 057_S_1373\n",
      "[ViT-AD] Processing subject 246/311: 057_S_1373_aug0\n",
      "[ViT-AD] Processing subject 247/311: 057_S_1373_aug1\n",
      "[ViT-AD] Processing subject 248/311: 057_S_1373_aug2\n",
      "[ViT-AD] Processing subject 249/311: 057_S_1379\n",
      "[ViT-AD] Processing subject 250/311: 057_S_1379_aug0\n",
      "[ViT-AD] Processing subject 251/311: 057_S_1379_aug1\n",
      "[ViT-AD] Processing subject 252/311: 057_S_1379_aug2\n",
      "[ViT-AD] Processing subject 253/311: 062_S_0535\n",
      "[ViT-AD] Processing subject 254/311: 062_S_0535_aug0\n",
      "[ViT-AD] Processing subject 255/311: 062_S_0535_aug1\n",
      "[ViT-AD] Processing subject 256/311: 062_S_0535_aug2\n",
      "[ViT-AD] Processing subject 257/311: 062_S_0690\n",
      "[ViT-AD] Processing subject 258/311: 062_S_0730\n",
      "[ViT-AD] Processing subject 259/311: 062_S_0793\n",
      "[ViT-AD] Processing subject 260/311: 067_S_0029\n",
      "[ViT-AD] Processing subject 261/311: 067_S_0076\n",
      "[ViT-AD] Processing subject 262/311: 068_S_0109\n",
      "[ViT-AD] Processing subject 263/311: 073_S_0565\n",
      "[ViT-AD] Processing subject 264/311: 082_S_1377\n",
      "[ViT-AD] Processing subject 265/311: 094_S_1027\n",
      "[ViT-AD] Processing subject 266/311: 094_S_1090\n",
      "[ViT-AD] Processing subject 267/311: 094_S_1164\n",
      "[ViT-AD] Processing subject 268/311: 094_S_1397\n",
      "[ViT-AD] Processing subject 269/311: 094_S_1402\n",
      "[ViT-AD] Processing subject 270/311: 098_S_0149\n",
      "[ViT-AD] Processing subject 271/311: 099_S_0372\n",
      "[ViT-AD] Processing subject 272/311: 099_S_0470\n",
      "[ViT-AD] Processing subject 273/311: 099_S_1144\n",
      "[ViT-AD] Processing subject 274/311: 109_S_1157\n",
      "[ViT-AD] Processing subject 275/311: 114_S_0374\n",
      "[ViT-AD] Processing subject 276/311: 114_S_0979\n",
      "[ViT-AD] Processing subject 277/311: 116_S_0370\n",
      "[ViT-AD] Processing subject 278/311: 116_S_0392\n",
      "[ViT-AD] Processing subject 279/311: 116_S_0487\n",
      "[ViT-AD] Processing subject 280/311: 123_S_0088\n",
      "[ViT-AD] Processing subject 281/311: 123_S_0091\n",
      "[ViT-AD] Processing subject 282/311: 123_S_0094\n",
      "[ViT-AD] Processing subject 283/311: 123_S_0162\n",
      "[ViT-AD] Processing subject 284/311: 126_S_0606\n",
      "[ViT-AD] Processing subject 285/311: 126_S_0784\n",
      "[ViT-AD] Processing subject 286/311: 126_S_0891\n",
      "[ViT-AD] Processing subject 287/311: 126_S_1221\n",
      "[ViT-AD] Processing subject 288/311: 127_S_0431\n",
      "[ViT-AD] Processing subject 289/311: 127_S_0754\n",
      "[ViT-AD] Processing subject 290/311: 127_S_0844\n",
      "[ViT-AD] Processing subject 291/311: 127_S_1382\n",
      "[ViT-AD] Processing subject 292/311: 130_S_0956\n",
      "[ViT-AD] Processing subject 293/311: 130_S_1201\n",
      "[ViT-AD] Processing subject 294/311: 130_S_1290\n",
      "[ViT-AD] Processing subject 295/311: 130_S_1337\n",
      "[ViT-AD] Processing subject 296/311: 131_S_0457\n",
      "[ViT-AD] Processing subject 297/311: 131_S_0497\n",
      "[ViT-AD] Processing subject 298/311: 133_S_1170\n",
      "[ViT-AD] Processing subject 299/311: 136_S_0194\n",
      "[ViT-AD] Processing subject 300/311: 136_S_0299\n",
      "[ViT-AD] Processing subject 301/311: 136_S_0300\n",
      "[ViT-AD] Processing subject 302/311: 136_S_0426\n",
      "[ViT-AD] Processing subject 303/311: 137_S_0366\n",
      "[ViT-AD] Processing subject 304/311: 137_S_0796\n",
      "[ViT-AD] Processing subject 305/311: 137_S_1041\n",
      "[ViT-AD] Processing subject 306/311: 141_S_0696\n",
      "[ViT-AD] Processing subject 307/311: 141_S_0790\n",
      "[ViT-AD] Processing subject 308/311: 141_S_0852\n",
      "[ViT-AD] Processing subject 309/311: 141_S_0853\n",
      "[ViT-AD] Processing subject 310/311: 141_S_1137\n",
      "[ViT-AD] Processing subject 311/311: 141_S_1152\n",
      "[ViT-CN] Processing subject 1/311: 002_S_0295\n",
      "[ViT-CN] Processing subject 2/311: 002_S_0295_aug0\n",
      "[ViT-CN] Processing subject 3/311: 002_S_0295_aug1\n",
      "[ViT-CN] Processing subject 4/311: 002_S_0413\n",
      "[ViT-CN] Processing subject 5/311: 002_S_0413_aug1\n",
      "[ViT-CN] Processing subject 6/311: 002_S_0685\n",
      "[ViT-CN] Processing subject 7/311: 002_S_0685_aug0\n",
      "[ViT-CN] Processing subject 8/311: 002_S_0685_aug1\n",
      "[ViT-CN] Processing subject 9/311: 002_S_1261\n",
      "[ViT-CN] Processing subject 10/311: 002_S_1261_aug0\n",
      "[ViT-CN] Processing subject 11/311: 002_S_1261_aug1\n",
      "[ViT-CN] Processing subject 12/311: 002_S_1280\n",
      "[ViT-CN] Processing subject 13/311: 002_S_1280_aug0\n",
      "[ViT-CN] Processing subject 14/311: 002_S_1280_aug1\n",
      "[ViT-CN] Processing subject 15/311: 003_S_0907\n",
      "[ViT-CN] Processing subject 16/311: 003_S_0907_aug0\n",
      "[ViT-CN] Processing subject 17/311: 003_S_0907_aug1\n",
      "[ViT-CN] Processing subject 18/311: 003_S_0981\n",
      "[ViT-CN] Processing subject 19/311: 003_S_0981_aug1\n",
      "[ViT-CN] Processing subject 20/311: 005_S_0223\n",
      "[ViT-CN] Processing subject 21/311: 005_S_0223_aug0\n",
      "[ViT-CN] Processing subject 22/311: 005_S_0223_aug1\n",
      "[ViT-CN] Processing subject 23/311: 005_S_0553\n",
      "[ViT-CN] Processing subject 24/311: 005_S_0553_aug0\n",
      "[ViT-CN] Processing subject 25/311: 005_S_0602\n",
      "[ViT-CN] Processing subject 26/311: 005_S_0602_aug1\n",
      "[ViT-CN] Processing subject 27/311: 005_S_0610\n",
      "[ViT-CN] Processing subject 28/311: 005_S_0610_aug0\n",
      "[ViT-CN] Processing subject 29/311: 005_S_0610_aug1\n",
      "[ViT-CN] Processing subject 30/311: 006_S_0498\n",
      "[ViT-CN] Processing subject 31/311: 006_S_0498_aug0\n",
      "[ViT-CN] Processing subject 32/311: 006_S_0498_aug1\n",
      "[ViT-CN] Processing subject 33/311: 006_S_0681\n",
      "[ViT-CN] Processing subject 34/311: 006_S_0681_aug0\n",
      "[ViT-CN] Processing subject 35/311: 006_S_0681_aug1\n",
      "[ViT-CN] Processing subject 36/311: 006_S_0731\n",
      "[ViT-CN] Processing subject 37/311: 006_S_0731_aug0\n",
      "[ViT-CN] Processing subject 38/311: 006_S_0731_aug1\n",
      "[ViT-CN] Processing subject 39/311: 007_S_0068\n",
      "[ViT-CN] Processing subject 40/311: 007_S_0068_aug0\n",
      "[ViT-CN] Processing subject 41/311: 007_S_0068_aug1\n",
      "[ViT-CN] Processing subject 42/311: 007_S_0070\n",
      "[ViT-CN] Processing subject 43/311: 007_S_0070_aug0\n",
      "[ViT-CN] Processing subject 44/311: 007_S_0070_aug1\n",
      "[ViT-CN] Processing subject 45/311: 007_S_1206\n",
      "[ViT-CN] Processing subject 46/311: 007_S_1206_aug0\n",
      "[ViT-CN] Processing subject 47/311: 007_S_1206_aug1\n",
      "[ViT-CN] Processing subject 48/311: 007_S_1222\n",
      "[ViT-CN] Processing subject 49/311: 007_S_1222_aug0\n",
      "[ViT-CN] Processing subject 50/311: 007_S_1222_aug1\n",
      "[ViT-CN] Processing subject 51/311: 009_S_0751\n",
      "[ViT-CN] Processing subject 52/311: 009_S_0751_aug0\n",
      "[ViT-CN] Processing subject 53/311: 009_S_0842\n",
      "[ViT-CN] Processing subject 54/311: 009_S_0842_aug0\n",
      "[ViT-CN] Processing subject 55/311: 009_S_0862\n",
      "[ViT-CN] Processing subject 56/311: 009_S_0862_aug0\n",
      "[ViT-CN] Processing subject 57/311: 009_S_0862_aug1\n",
      "[ViT-CN] Processing subject 58/311: 010_S_0067\n",
      "[ViT-CN] Processing subject 59/311: 010_S_0067_aug0\n",
      "[ViT-CN] Processing subject 60/311: 010_S_0067_aug1\n",
      "[ViT-CN] Processing subject 61/311: 010_S_0419\n",
      "[ViT-CN] Processing subject 62/311: 010_S_0419_aug0\n",
      "[ViT-CN] Processing subject 63/311: 010_S_0419_aug1\n",
      "[ViT-CN] Processing subject 64/311: 010_S_0472\n",
      "[ViT-CN] Processing subject 65/311: 010_S_0472_aug0\n",
      "[ViT-CN] Processing subject 66/311: 010_S_0472_aug1\n",
      "[ViT-CN] Processing subject 67/311: 011_S_0005\n",
      "[ViT-CN] Processing subject 68/311: 011_S_0005_aug0\n",
      "[ViT-CN] Processing subject 69/311: 011_S_0005_aug1\n",
      "[ViT-CN] Processing subject 70/311: 011_S_0016\n",
      "[ViT-CN] Processing subject 71/311: 011_S_0016_aug0\n",
      "[ViT-CN] Processing subject 72/311: 011_S_0021\n",
      "[ViT-CN] Processing subject 73/311: 011_S_0021_aug0\n",
      "[ViT-CN] Processing subject 74/311: 011_S_0022\n",
      "[ViT-CN] Processing subject 75/311: 011_S_0022_aug0\n",
      "[ViT-CN] Processing subject 76/311: 011_S_0023\n",
      "[ViT-CN] Processing subject 77/311: 011_S_0023_aug0\n",
      "[ViT-CN] Processing subject 78/311: 011_S_0023_aug1\n",
      "[ViT-CN] Processing subject 79/311: 012_S_0637\n",
      "[ViT-CN] Processing subject 80/311: 012_S_0637_aug0\n",
      "[ViT-CN] Processing subject 81/311: 012_S_0637_aug1\n",
      "[ViT-CN] Processing subject 82/311: 012_S_1009\n",
      "[ViT-CN] Processing subject 83/311: 012_S_1009_aug0\n",
      "[ViT-CN] Processing subject 84/311: 012_S_1009_aug1\n",
      "[ViT-CN] Processing subject 85/311: 012_S_1133\n",
      "[ViT-CN] Processing subject 86/311: 012_S_1133_aug0\n",
      "[ViT-CN] Processing subject 87/311: 012_S_1133_aug1\n",
      "[ViT-CN] Processing subject 88/311: 013_S_0502\n",
      "[ViT-CN] Processing subject 89/311: 013_S_0502_aug0\n",
      "[ViT-CN] Processing subject 90/311: 013_S_0502_aug1\n",
      "[ViT-CN] Processing subject 91/311: 013_S_0575\n",
      "[ViT-CN] Processing subject 92/311: 013_S_0575_aug0\n",
      "[ViT-CN] Processing subject 93/311: 013_S_0575_aug1\n",
      "[ViT-CN] Processing subject 94/311: 013_S_1035\n",
      "[ViT-CN] Processing subject 95/311: 013_S_1035_aug0\n",
      "[ViT-CN] Processing subject 96/311: 013_S_1035_aug1\n",
      "[ViT-CN] Processing subject 97/311: 014_S_0519\n",
      "[ViT-CN] Processing subject 98/311: 014_S_0519_aug0\n",
      "[ViT-CN] Processing subject 99/311: 014_S_0519_aug1\n",
      "[ViT-CN] Processing subject 100/311: 014_S_0520\n",
      "[ViT-CN] Processing subject 101/311: 014_S_0520_aug1\n",
      "[ViT-CN] Processing subject 102/311: 014_S_0548\n",
      "[ViT-CN] Processing subject 103/311: 014_S_0548_aug0\n",
      "[ViT-CN] Processing subject 104/311: 014_S_0548_aug1\n",
      "[ViT-CN] Processing subject 105/311: 014_S_0558\n",
      "[ViT-CN] Processing subject 106/311: 014_S_0558_aug0\n",
      "[ViT-CN] Processing subject 107/311: 014_S_0558_aug1\n",
      "[ViT-CN] Processing subject 108/311: 016_S_0359\n",
      "[ViT-CN] Processing subject 109/311: 016_S_0359_aug0\n",
      "[ViT-CN] Processing subject 110/311: 016_S_0359_aug1\n",
      "[ViT-CN] Processing subject 111/311: 016_S_0538\n",
      "[ViT-CN] Processing subject 112/311: 016_S_0538_aug0\n",
      "[ViT-CN] Processing subject 113/311: 016_S_0538_aug1\n",
      "[ViT-CN] Processing subject 114/311: 018_S_0043\n",
      "[ViT-CN] Processing subject 115/311: 018_S_0043_aug0\n",
      "[ViT-CN] Processing subject 116/311: 018_S_0043_aug1\n",
      "[ViT-CN] Processing subject 117/311: 018_S_0055\n",
      "[ViT-CN] Processing subject 118/311: 018_S_0055_aug1\n",
      "[ViT-CN] Processing subject 119/311: 018_S_0369\n",
      "[ViT-CN] Processing subject 120/311: 018_S_0369_aug0\n",
      "[ViT-CN] Processing subject 121/311: 018_S_0425\n",
      "[ViT-CN] Processing subject 122/311: 018_S_0425_aug0\n",
      "[ViT-CN] Processing subject 123/311: 018_S_0425_aug1\n",
      "[ViT-CN] Processing subject 124/311: 020_S_0097\n",
      "[ViT-CN] Processing subject 125/311: 020_S_0097_aug1\n",
      "[ViT-CN] Processing subject 126/311: 020_S_0883\n",
      "[ViT-CN] Processing subject 127/311: 020_S_0883_aug0\n",
      "[ViT-CN] Processing subject 128/311: 020_S_0883_aug1\n",
      "[ViT-CN] Processing subject 129/311: 020_S_0899\n",
      "[ViT-CN] Processing subject 130/311: 020_S_0899_aug1\n",
      "[ViT-CN] Processing subject 131/311: 020_S_1288\n",
      "[ViT-CN] Processing subject 132/311: 020_S_1288_aug0\n",
      "[ViT-CN] Processing subject 133/311: 020_S_1288_aug1\n",
      "[ViT-CN] Processing subject 134/311: 021_S_0159\n",
      "[ViT-CN] Processing subject 135/311: 021_S_0159_aug0\n",
      "[ViT-CN] Processing subject 136/311: 021_S_0159_aug1\n",
      "[ViT-CN] Processing subject 137/311: 021_S_0337\n",
      "[ViT-CN] Processing subject 138/311: 021_S_0337_aug0\n",
      "[ViT-CN] Processing subject 139/311: 021_S_0647\n",
      "[ViT-CN] Processing subject 140/311: 021_S_0647_aug0\n",
      "[ViT-CN] Processing subject 141/311: 021_S_0984\n",
      "[ViT-CN] Processing subject 142/311: 021_S_0984_aug0\n",
      "[ViT-CN] Processing subject 143/311: 021_S_0984_aug1\n",
      "[ViT-CN] Processing subject 144/311: 022_S_0014\n",
      "[ViT-CN] Processing subject 145/311: 022_S_0014_aug0\n",
      "[ViT-CN] Processing subject 146/311: 022_S_0014_aug1\n",
      "[ViT-CN] Processing subject 147/311: 022_S_0066\n",
      "[ViT-CN] Processing subject 148/311: 022_S_0066_aug0\n",
      "[ViT-CN] Processing subject 149/311: 022_S_0096\n",
      "[ViT-CN] Processing subject 150/311: 022_S_0096_aug0\n",
      "[ViT-CN] Processing subject 151/311: 022_S_0096_aug1\n",
      "[ViT-CN] Processing subject 152/311: 022_S_0130\n",
      "[ViT-CN] Processing subject 153/311: 022_S_0130_aug1\n",
      "[ViT-CN] Processing subject 154/311: 023_S_0031\n",
      "[ViT-CN] Processing subject 155/311: 023_S_0031_aug0\n",
      "[ViT-CN] Processing subject 156/311: 023_S_0031_aug1\n",
      "[ViT-CN] Processing subject 157/311: 023_S_0058\n",
      "[ViT-CN] Processing subject 158/311: 023_S_0058_aug0\n",
      "[ViT-CN] Processing subject 159/311: 023_S_0058_aug1\n",
      "[ViT-CN] Processing subject 160/311: 023_S_0061\n",
      "[ViT-CN] Processing subject 161/311: 023_S_0061_aug0\n",
      "[ViT-CN] Processing subject 162/311: 023_S_0061_aug1\n",
      "[ViT-CN] Processing subject 163/311: 023_S_0081\n",
      "[ViT-CN] Processing subject 164/311: 023_S_0081_aug0\n",
      "[ViT-CN] Processing subject 165/311: 023_S_0926\n",
      "[ViT-CN] Processing subject 166/311: 023_S_0926_aug1\n",
      "[ViT-CN] Processing subject 167/311: 023_S_0963\n",
      "[ViT-CN] Processing subject 168/311: 023_S_0963_aug1\n",
      "[ViT-CN] Processing subject 169/311: 023_S_1190\n",
      "[ViT-CN] Processing subject 170/311: 023_S_1190_aug0\n",
      "[ViT-CN] Processing subject 171/311: 023_S_1190_aug1\n",
      "[ViT-CN] Processing subject 172/311: 024_S_0985\n",
      "[ViT-CN] Processing subject 173/311: 024_S_0985_aug1\n",
      "[ViT-CN] Processing subject 174/311: 024_S_1063\n",
      "[ViT-CN] Processing subject 175/311: 024_S_1063_aug0\n",
      "[ViT-CN] Processing subject 176/311: 024_S_1063_aug1\n",
      "[ViT-CN] Processing subject 177/311: 027_S_0074\n",
      "[ViT-CN] Processing subject 178/311: 027_S_0074_aug0\n",
      "[ViT-CN] Processing subject 179/311: 027_S_0074_aug1\n",
      "[ViT-CN] Processing subject 180/311: 027_S_0118\n",
      "[ViT-CN] Processing subject 181/311: 027_S_0118_aug0\n",
      "[ViT-CN] Processing subject 182/311: 027_S_0118_aug1\n",
      "[ViT-CN] Processing subject 183/311: 027_S_0120\n",
      "[ViT-CN] Processing subject 184/311: 027_S_0120_aug0\n",
      "[ViT-CN] Processing subject 185/311: 027_S_0403\n",
      "[ViT-CN] Processing subject 186/311: 027_S_0403_aug0\n",
      "[ViT-CN] Processing subject 187/311: 029_S_0824\n",
      "[ViT-CN] Processing subject 188/311: 029_S_0843\n",
      "[ViT-CN] Processing subject 189/311: 029_S_0845\n",
      "[ViT-CN] Processing subject 190/311: 029_S_0866\n",
      "[ViT-CN] Processing subject 191/311: 031_S_0618\n",
      "[ViT-CN] Processing subject 192/311: 032_S_0095\n",
      "[ViT-CN] Processing subject 193/311: 032_S_0479\n",
      "[ViT-CN] Processing subject 194/311: 032_S_0677\n",
      "[ViT-CN] Processing subject 195/311: 032_S_1169\n",
      "[ViT-CN] Processing subject 196/311: 033_S_0516\n",
      "[ViT-CN] Processing subject 197/311: 033_S_0734\n",
      "[ViT-CN] Processing subject 198/311: 033_S_0741\n",
      "[ViT-CN] Processing subject 199/311: 033_S_0920\n",
      "[ViT-CN] Processing subject 200/311: 033_S_0923\n",
      "[ViT-CN] Processing subject 201/311: 033_S_1016\n",
      "[ViT-CN] Processing subject 202/311: 033_S_1086\n",
      "[ViT-CN] Processing subject 203/311: 033_S_1098\n",
      "[ViT-CN] Processing subject 204/311: 035_S_0048\n",
      "[ViT-CN] Processing subject 205/311: 035_S_0156\n",
      "[ViT-CN] Processing subject 206/311: 035_S_0555\n",
      "[ViT-CN] Processing subject 207/311: 036_S_0576\n",
      "[ViT-CN] Processing subject 208/311: 036_S_0672\n",
      "[ViT-CN] Processing subject 209/311: 036_S_0813\n",
      "[ViT-CN] Processing subject 210/311: 036_S_1023\n",
      "[ViT-CN] Processing subject 211/311: 037_S_0303\n",
      "[ViT-CN] Processing subject 212/311: 037_S_0327\n",
      "[ViT-CN] Processing subject 213/311: 037_S_0454\n",
      "[ViT-CN] Processing subject 214/311: 037_S_0467\n",
      "[ViT-CN] Processing subject 215/311: 041_S_0125\n",
      "[ViT-CN] Processing subject 216/311: 041_S_0262\n",
      "[ViT-CN] Processing subject 217/311: 041_S_0898\n",
      "[ViT-CN] Processing subject 218/311: 041_S_1002\n",
      "[ViT-CN] Processing subject 219/311: 051_S_1123\n",
      "[ViT-CN] Processing subject 220/311: 052_S_0951\n",
      "[ViT-CN] Processing subject 221/311: 052_S_1250\n",
      "[ViT-CN] Processing subject 222/311: 052_S_1251\n",
      "[ViT-CN] Processing subject 223/311: 057_S_0643\n",
      "[ViT-CN] Processing subject 224/311: 057_S_0779\n",
      "[ViT-CN] Processing subject 225/311: 057_S_0818\n",
      "[ViT-CN] Processing subject 226/311: 057_S_0934\n",
      "[ViT-CN] Processing subject 227/311: 062_S_0578\n",
      "[ViT-CN] Processing subject 228/311: 062_S_0768\n",
      "[ViT-CN] Processing subject 229/311: 062_S_1099\n",
      "[ViT-CN] Processing subject 230/311: 067_S_0019\n",
      "[ViT-CN] Processing subject 231/311: 067_S_0056\n",
      "[ViT-CN] Processing subject 232/311: 067_S_0059\n",
      "[ViT-CN] Processing subject 233/311: 067_S_0177\n",
      "[ViT-CN] Processing subject 234/311: 067_S_0257\n",
      "[ViT-CN] Processing subject 235/311: 068_S_0127\n",
      "[ViT-CN] Processing subject 236/311: 068_S_0210\n",
      "[ViT-CN] Processing subject 237/311: 068_S_0473\n",
      "[ViT-CN] Processing subject 238/311: 072_S_0315\n",
      "[ViT-CN] Processing subject 239/311: 073_S_0089\n",
      "[ViT-CN] Processing subject 240/311: 073_S_0311\n",
      "[ViT-CN] Processing subject 241/311: 073_S_0312\n",
      "[ViT-CN] Processing subject 242/311: 073_S_0386\n",
      "[ViT-CN] Processing subject 243/311: 082_S_1256\n",
      "[ViT-CN] Processing subject 244/311: 094_S_0526\n",
      "[ViT-CN] Processing subject 245/311: 094_S_0692\n",
      "[ViT-CN] Processing subject 246/311: 094_S_0711\n",
      "[ViT-CN] Processing subject 247/311: 094_S_1241\n",
      "[ViT-CN] Processing subject 248/311: 094_S_1267\n",
      "[ViT-CN] Processing subject 249/311: 098_S_0171\n",
      "[ViT-CN] Processing subject 250/311: 098_S_0172\n",
      "[ViT-CN] Processing subject 251/311: 098_S_0896\n",
      "[ViT-CN] Processing subject 252/311: 099_S_0040\n",
      "[ViT-CN] Processing subject 253/311: 099_S_0090\n",
      "[ViT-CN] Processing subject 254/311: 099_S_0352\n",
      "[ViT-CN] Processing subject 255/311: 099_S_0533\n",
      "[ViT-CN] Processing subject 256/311: 099_S_0534\n",
      "[ViT-CN] Processing subject 257/311: 100_S_0015\n",
      "[ViT-CN] Processing subject 258/311: 100_S_0035\n",
      "[ViT-CN] Processing subject 259/311: 100_S_0047\n",
      "[ViT-CN] Processing subject 260/311: 100_S_0069\n",
      "[ViT-CN] Processing subject 261/311: 109_S_0967\n",
      "[ViT-CN] Processing subject 262/311: 109_S_1014\n",
      "[ViT-CN] Processing subject 263/311: 114_S_0166\n",
      "[ViT-CN] Processing subject 264/311: 114_S_0173\n",
      "[ViT-CN] Processing subject 265/311: 114_S_0416\n",
      "[ViT-CN] Processing subject 266/311: 114_S_0601\n",
      "[ViT-CN] Processing subject 267/311: 116_S_0382\n",
      "[ViT-CN] Processing subject 268/311: 116_S_0648\n",
      "[ViT-CN] Processing subject 269/311: 116_S_0657\n",
      "[ViT-CN] Processing subject 270/311: 116_S_1232\n",
      "[ViT-CN] Processing subject 271/311: 116_S_1249\n",
      "[ViT-CN] Processing subject 272/311: 123_S_0072\n",
      "[ViT-CN] Processing subject 273/311: 123_S_0106\n",
      "[ViT-CN] Processing subject 274/311: 123_S_0113\n",
      "[ViT-CN] Processing subject 275/311: 123_S_0298\n",
      "[ViT-CN] Processing subject 276/311: 126_S_0605\n",
      "[ViT-CN] Processing subject 277/311: 126_S_0680\n",
      "[ViT-CN] Processing subject 278/311: 127_S_0259\n",
      "[ViT-CN] Processing subject 279/311: 127_S_0260\n",
      "[ViT-CN] Processing subject 280/311: 127_S_0622\n",
      "[ViT-CN] Processing subject 281/311: 127_S_0684\n",
      "[ViT-CN] Processing subject 282/311: 128_S_0863\n",
      "[ViT-CN] Processing subject 283/311: 128_S_1242\n",
      "[ViT-CN] Processing subject 284/311: 129_S_0778\n",
      "[ViT-CN] Processing subject 285/311: 130_S_0232\n",
      "[ViT-CN] Processing subject 286/311: 130_S_0886\n",
      "[ViT-CN] Processing subject 287/311: 130_S_0969\n",
      "[ViT-CN] Processing subject 288/311: 130_S_1200\n",
      "[ViT-CN] Processing subject 289/311: 131_S_0123\n",
      "[ViT-CN] Processing subject 290/311: 131_S_0441\n",
      "[ViT-CN] Processing subject 291/311: 131_S_1301\n",
      "[ViT-CN] Processing subject 292/311: 133_S_0433\n",
      "[ViT-CN] Processing subject 293/311: 133_S_0488\n",
      "[ViT-CN] Processing subject 294/311: 133_S_0525\n",
      "[ViT-CN] Processing subject 295/311: 136_S_0086\n",
      "[ViT-CN] Processing subject 296/311: 136_S_0184\n",
      "[ViT-CN] Processing subject 297/311: 136_S_0186\n",
      "[ViT-CN] Processing subject 298/311: 136_S_0196\n",
      "[ViT-CN] Processing subject 299/311: 137_S_0283\n",
      "[ViT-CN] Processing subject 300/311: 137_S_0301\n",
      "[ViT-CN] Processing subject 301/311: 137_S_0459\n",
      "[ViT-CN] Processing subject 302/311: 137_S_0686\n",
      "[ViT-CN] Processing subject 303/311: 137_S_0972\n",
      "[ViT-CN] Processing subject 304/311: 141_S_0717\n",
      "[ViT-CN] Processing subject 305/311: 141_S_0726\n",
      "[ViT-CN] Processing subject 306/311: 141_S_0767\n",
      "[ViT-CN] Processing subject 307/311: 141_S_0810\n",
      "[ViT-CN] Processing subject 308/311: 141_S_1094\n",
      "[ViT-CN] Processing subject 309/311: 941_S_1194\n",
      "[ViT-CN] Processing subject 310/311: 941_S_1197\n",
      "[ViT-CN] Processing subject 311/311: 941_S_1202\n",
      "[ViT-LMCI] Processing subject 1/311: 002_S_0729\n",
      "[ViT-LMCI] Processing subject 2/311: 002_S_0782\n",
      "[ViT-LMCI] Processing subject 3/311: 002_S_0954\n",
      "[ViT-LMCI] Processing subject 4/311: 002_S_1070\n",
      "[ViT-LMCI] Processing subject 5/311: 002_S_1155\n",
      "[ViT-LMCI] Processing subject 6/311: 002_S_1268\n",
      "[ViT-LMCI] Processing subject 7/311: 003_S_0908\n",
      "[ViT-LMCI] Processing subject 8/311: 003_S_1057\n",
      "[ViT-LMCI] Processing subject 9/311: 003_S_1122\n",
      "[ViT-LMCI] Processing subject 10/311: 005_S_0222\n",
      "[ViT-LMCI] Processing subject 11/311: 005_S_0324\n",
      "[ViT-LMCI] Processing subject 12/311: 005_S_0448\n",
      "[ViT-LMCI] Processing subject 13/311: 005_S_0546\n",
      "[ViT-LMCI] Processing subject 14/311: 005_S_1224\n",
      "[ViT-LMCI] Processing subject 15/311: 006_S_0675\n",
      "[ViT-LMCI] Processing subject 16/311: 006_S_1130\n",
      "[ViT-LMCI] Processing subject 17/311: 007_S_0041\n",
      "[ViT-LMCI] Processing subject 18/311: 007_S_0101\n",
      "[ViT-LMCI] Processing subject 19/311: 007_S_0128\n",
      "[ViT-LMCI] Processing subject 20/311: 007_S_0249\n",
      "[ViT-LMCI] Processing subject 21/311: 007_S_0293\n",
      "[ViT-LMCI] Processing subject 22/311: 007_S_0414\n",
      "[ViT-LMCI] Processing subject 23/311: 007_S_0698\n",
      "[ViT-LMCI] Processing subject 24/311: 009_S_1030\n",
      "[ViT-LMCI] Processing subject 25/311: 010_S_0422\n",
      "[ViT-LMCI] Processing subject 26/311: 010_S_0904\n",
      "[ViT-LMCI] Processing subject 27/311: 011_S_0168\n",
      "[ViT-LMCI] Processing subject 28/311: 011_S_0241\n",
      "[ViT-LMCI] Processing subject 29/311: 011_S_0326\n",
      "[ViT-LMCI] Processing subject 30/311: 011_S_0362\n",
      "[ViT-LMCI] Processing subject 31/311: 011_S_0856\n",
      "[ViT-LMCI] Processing subject 32/311: 011_S_0861\n",
      "[ViT-LMCI] Processing subject 33/311: 011_S_1080\n",
      "[ViT-LMCI] Processing subject 34/311: 011_S_1282\n",
      "[ViT-LMCI] Processing subject 35/311: 012_S_0634\n",
      "[ViT-LMCI] Processing subject 36/311: 012_S_0932\n",
      "[ViT-LMCI] Processing subject 37/311: 012_S_1033\n",
      "[ViT-LMCI] Processing subject 38/311: 012_S_1165\n",
      "[ViT-LMCI] Processing subject 39/311: 012_S_1292\n",
      "[ViT-LMCI] Processing subject 40/311: 012_S_1321\n",
      "[ViT-LMCI] Processing subject 41/311: 013_S_0240\n",
      "[ViT-LMCI] Processing subject 42/311: 013_S_0325\n",
      "[ViT-LMCI] Processing subject 43/311: 013_S_0860\n",
      "[ViT-LMCI] Processing subject 44/311: 013_S_1120\n",
      "[ViT-LMCI] Processing subject 45/311: 013_S_1186\n",
      "[ViT-LMCI] Processing subject 46/311: 013_S_1275\n",
      "[ViT-LMCI] Processing subject 47/311: 014_S_0169\n",
      "[ViT-LMCI] Processing subject 48/311: 014_S_0557\n",
      "[ViT-LMCI] Processing subject 49/311: 014_S_0563\n",
      "[ViT-LMCI] Processing subject 50/311: 014_S_0658\n",
      "[ViT-LMCI] Processing subject 51/311: 016_S_0354\n",
      "[ViT-LMCI] Processing subject 52/311: 016_S_0702\n",
      "[ViT-LMCI] Processing subject 53/311: 016_S_1028\n",
      "[ViT-LMCI] Processing subject 54/311: 016_S_1117\n",
      "[ViT-LMCI] Processing subject 55/311: 016_S_1121\n",
      "[ViT-LMCI] Processing subject 56/311: 016_S_1326\n",
      "[ViT-LMCI] Processing subject 57/311: 018_S_0057\n",
      "[ViT-LMCI] Processing subject 58/311: 018_S_0080\n",
      "[ViT-LMCI] Processing subject 59/311: 018_S_0087\n",
      "[ViT-LMCI] Processing subject 60/311: 018_S_0142\n",
      "[ViT-LMCI] Processing subject 61/311: 018_S_0155\n",
      "[ViT-LMCI] Processing subject 62/311: 018_S_0406\n",
      "[ViT-LMCI] Processing subject 63/311: 018_S_0450\n",
      "[ViT-LMCI] Processing subject 64/311: 021_S_0141\n",
      "[ViT-LMCI] Processing subject 65/311: 021_S_0231\n",
      "[ViT-LMCI] Processing subject 66/311: 021_S_0273\n",
      "[ViT-LMCI] Processing subject 67/311: 021_S_0276\n",
      "[ViT-LMCI] Processing subject 68/311: 021_S_0332\n",
      "[ViT-LMCI] Processing subject 69/311: 021_S_0424\n",
      "[ViT-LMCI] Processing subject 70/311: 021_S_0626\n",
      "[ViT-LMCI] Processing subject 71/311: 022_S_0004\n",
      "[ViT-LMCI] Processing subject 72/311: 022_S_0544\n",
      "[ViT-LMCI] Processing subject 73/311: 022_S_0750\n",
      "[ViT-LMCI] Processing subject 74/311: 022_S_0961\n",
      "[ViT-LMCI] Processing subject 75/311: 022_S_1351\n",
      "[ViT-LMCI] Processing subject 76/311: 022_S_1394\n",
      "[ViT-LMCI] Processing subject 77/311: 023_S_0030\n",
      "[ViT-LMCI] Processing subject 78/311: 023_S_0042\n",
      "[ViT-LMCI] Processing subject 79/311: 023_S_0078\n",
      "[ViT-LMCI] Processing subject 80/311: 023_S_0126\n",
      "[ViT-LMCI] Processing subject 81/311: 023_S_0217\n",
      "[ViT-LMCI] Processing subject 82/311: 023_S_0331\n",
      "[ViT-LMCI] Processing subject 83/311: 023_S_0376\n",
      "[ViT-LMCI] Processing subject 84/311: 023_S_0388\n",
      "[ViT-LMCI] Processing subject 85/311: 023_S_0604\n",
      "[ViT-LMCI] Processing subject 86/311: 023_S_0625\n",
      "[ViT-LMCI] Processing subject 87/311: 023_S_0855\n",
      "[ViT-LMCI] Processing subject 88/311: 023_S_0887\n",
      "[ViT-LMCI] Processing subject 89/311: 023_S_1046\n",
      "[ViT-LMCI] Processing subject 90/311: 023_S_1126\n",
      "[ViT-LMCI] Processing subject 91/311: 023_S_1247\n",
      "[ViT-LMCI] Processing subject 92/311: 024_S_1393\n",
      "[ViT-LMCI] Processing subject 93/311: 027_S_0116\n",
      "[ViT-LMCI] Processing subject 94/311: 027_S_0179\n",
      "[ViT-LMCI] Processing subject 95/311: 027_S_0256\n",
      "[ViT-LMCI] Processing subject 96/311: 027_S_0307\n",
      "[ViT-LMCI] Processing subject 97/311: 027_S_0408\n",
      "[ViT-LMCI] Processing subject 98/311: 027_S_0417\n",
      "[ViT-LMCI] Processing subject 99/311: 027_S_0461\n",
      "[ViT-LMCI] Processing subject 100/311: 027_S_0485\n",
      "[ViT-LMCI] Processing subject 101/311: 027_S_0644\n",
      "[ViT-LMCI] Processing subject 102/311: 027_S_0835\n",
      "[ViT-LMCI] Processing subject 103/311: 027_S_1045\n",
      "[ViT-LMCI] Processing subject 104/311: 027_S_1213\n",
      "[ViT-LMCI] Processing subject 105/311: 027_S_1277\n",
      "[ViT-LMCI] Processing subject 106/311: 027_S_1387\n",
      "[ViT-LMCI] Processing subject 107/311: 029_S_0878\n",
      "[ViT-LMCI] Processing subject 108/311: 029_S_0914\n",
      "[ViT-LMCI] Processing subject 109/311: 029_S_1073\n",
      "[ViT-LMCI] Processing subject 110/311: 029_S_1215\n",
      "[ViT-LMCI] Processing subject 111/311: 029_S_1318\n",
      "[ViT-LMCI] Processing subject 112/311: 029_S_1384\n",
      "[ViT-LMCI] Processing subject 113/311: 031_S_0294\n",
      "[ViT-LMCI] Processing subject 114/311: 031_S_0351\n",
      "[ViT-LMCI] Processing subject 115/311: 031_S_0568\n",
      "[ViT-LMCI] Processing subject 116/311: 031_S_0830\n",
      "[ViT-LMCI] Processing subject 117/311: 031_S_0867\n",
      "[ViT-LMCI] Processing subject 118/311: 031_S_1066\n",
      "[ViT-LMCI] Processing subject 119/311: 032_S_0187\n",
      "[ViT-LMCI] Processing subject 120/311: 032_S_0214\n",
      "[ViT-LMCI] Processing subject 121/311: 032_S_0718\n",
      "[ViT-LMCI] Processing subject 122/311: 032_S_0978\n",
      "[ViT-LMCI] Processing subject 123/311: 033_S_0511\n",
      "[ViT-LMCI] Processing subject 124/311: 033_S_0513\n",
      "[ViT-LMCI] Processing subject 125/311: 033_S_0514\n",
      "[ViT-LMCI] Processing subject 126/311: 033_S_0567\n",
      "[ViT-LMCI] Processing subject 127/311: 033_S_0723\n",
      "[ViT-LMCI] Processing subject 128/311: 033_S_0725\n",
      "[ViT-LMCI] Processing subject 129/311: 033_S_0906\n",
      "[ViT-LMCI] Processing subject 130/311: 033_S_0922\n",
      "[ViT-LMCI] Processing subject 131/311: 033_S_1116\n",
      "[ViT-LMCI] Processing subject 132/311: 033_S_1279\n",
      "[ViT-LMCI] Processing subject 133/311: 033_S_1284\n",
      "[ViT-LMCI] Processing subject 134/311: 033_S_1309\n",
      "[ViT-LMCI] Processing subject 135/311: 035_S_0033\n",
      "[ViT-LMCI] Processing subject 136/311: 035_S_0204\n",
      "[ViT-LMCI] Processing subject 137/311: 035_S_0292\n",
      "[ViT-LMCI] Processing subject 138/311: 035_S_0997\n",
      "[ViT-LMCI] Processing subject 139/311: 036_S_0656\n",
      "[ViT-LMCI] Processing subject 140/311: 036_S_0673\n",
      "[ViT-LMCI] Processing subject 141/311: 036_S_0748\n",
      "[ViT-LMCI] Processing subject 142/311: 036_S_0869\n",
      "[ViT-LMCI] Processing subject 143/311: 036_S_0945\n",
      "[ViT-LMCI] Processing subject 144/311: 036_S_0976\n",
      "[ViT-LMCI] Processing subject 145/311: 036_S_1135\n",
      "[ViT-LMCI] Processing subject 146/311: 036_S_1240\n",
      "[ViT-LMCI] Processing subject 147/311: 037_S_0150\n",
      "[ViT-LMCI] Processing subject 148/311: 037_S_0501\n",
      "[ViT-LMCI] Processing subject 149/311: 037_S_0539\n",
      "[ViT-LMCI] Processing subject 150/311: 037_S_0552\n",
      "[ViT-LMCI] Processing subject 151/311: 037_S_0566\n",
      "[ViT-LMCI] Processing subject 152/311: 037_S_0588\n",
      "[ViT-LMCI] Processing subject 153/311: 037_S_1078\n",
      "[ViT-LMCI] Processing subject 154/311: 037_S_1225\n",
      "[ViT-LMCI] Processing subject 155/311: 037_S_1421\n",
      "[ViT-LMCI] Processing subject 156/311: 041_S_0282\n",
      "[ViT-LMCI] Processing subject 157/311: 041_S_0314\n",
      "[ViT-LMCI] Processing subject 158/311: 041_S_0446\n",
      "[ViT-LMCI] Processing subject 159/311: 041_S_0549\n",
      "[ViT-LMCI] Processing subject 160/311: 041_S_0598\n",
      "[ViT-LMCI] Processing subject 161/311: 041_S_0679\n",
      "[ViT-LMCI] Processing subject 162/311: 041_S_1010\n",
      "[ViT-LMCI] Processing subject 163/311: 041_S_1260\n",
      "[ViT-LMCI] Processing subject 164/311: 041_S_1412\n",
      "[ViT-LMCI] Processing subject 165/311: 041_S_1418\n",
      "[ViT-LMCI] Processing subject 166/311: 041_S_1423\n",
      "[ViT-LMCI] Processing subject 167/311: 041_S_1425\n",
      "[ViT-LMCI] Processing subject 168/311: 051_S_1040\n",
      "[ViT-LMCI] Processing subject 169/311: 051_S_1072\n",
      "[ViT-LMCI] Processing subject 170/311: 051_S_1131\n",
      "[ViT-LMCI] Processing subject 171/311: 051_S_1331\n",
      "[ViT-LMCI] Processing subject 172/311: 052_S_0671\n",
      "[ViT-LMCI] Processing subject 173/311: 052_S_0952\n",
      "[ViT-LMCI] Processing subject 174/311: 052_S_1054\n",
      "[ViT-LMCI] Processing subject 175/311: 052_S_1168\n",
      "[ViT-LMCI] Processing subject 176/311: 052_S_1346\n",
      "[ViT-LMCI] Processing subject 177/311: 052_S_1352\n",
      "[ViT-LMCI] Processing subject 178/311: 053_S_0389\n",
      "[ViT-LMCI] Processing subject 179/311: 053_S_0507\n",
      "[ViT-LMCI] Processing subject 180/311: 053_S_0621\n",
      "[ViT-LMCI] Processing subject 181/311: 053_S_0919\n",
      "[ViT-LMCI] Processing subject 182/311: 057_S_0464\n",
      "[ViT-LMCI] Processing subject 183/311: 057_S_0839\n",
      "[ViT-LMCI] Processing subject 184/311: 057_S_0941\n",
      "[ViT-LMCI] Processing subject 185/311: 057_S_1007\n",
      "[ViT-LMCI] Processing subject 186/311: 057_S_1217\n",
      "[ViT-LMCI] Processing subject 187/311: 057_S_1265\n",
      "[ViT-LMCI] Processing subject 188/311: 057_S_1269\n",
      "[ViT-LMCI] Processing subject 189/311: 062_S_1182\n",
      "[ViT-LMCI] Processing subject 190/311: 062_S_1299\n",
      "[ViT-LMCI] Processing subject 191/311: 067_S_0038\n",
      "[ViT-LMCI] Processing subject 192/311: 067_S_0077\n",
      "[ViT-LMCI] Processing subject 193/311: 067_S_0098\n",
      "[ViT-LMCI] Processing subject 194/311: 067_S_0176\n",
      "[ViT-LMCI] Processing subject 195/311: 067_S_0284\n",
      "[ViT-LMCI] Processing subject 196/311: 067_S_0290\n",
      "[ViT-LMCI] Processing subject 197/311: 067_S_0336\n",
      "[ViT-LMCI] Processing subject 198/311: 067_S_0607\n",
      "[ViT-LMCI] Processing subject 199/311: 068_S_0442\n",
      "[ViT-LMCI] Processing subject 200/311: 068_S_0872\n",
      "[ViT-LMCI] Processing subject 201/311: 073_S_0518\n",
      "[ViT-LMCI] Processing subject 202/311: 073_S_0746\n",
      "[ViT-LMCI] Processing subject 203/311: 073_S_0909\n",
      "[ViT-LMCI] Processing subject 204/311: 082_S_0928\n",
      "[ViT-LMCI] Processing subject 205/311: 082_S_1119\n",
      "[ViT-LMCI] Processing subject 206/311: 094_S_0434\n",
      "[ViT-LMCI] Processing subject 207/311: 094_S_0531\n",
      "[ViT-LMCI] Processing subject 208/311: 094_S_0921\n",
      "[ViT-LMCI] Processing subject 209/311: 094_S_1188\n",
      "[ViT-LMCI] Processing subject 210/311: 094_S_1293\n",
      "[ViT-LMCI] Processing subject 211/311: 094_S_1398\n",
      "[ViT-LMCI] Processing subject 212/311: 094_S_1417\n",
      "[ViT-LMCI] Processing subject 213/311: 098_S_0160\n",
      "[ViT-LMCI] Processing subject 214/311: 098_S_0269\n",
      "[ViT-LMCI] Processing subject 215/311: 098_S_0667\n",
      "[ViT-LMCI] Processing subject 216/311: 099_S_0051\n",
      "[ViT-LMCI] Processing subject 217/311: 099_S_0054\n",
      "[ViT-LMCI] Processing subject 218/311: 099_S_0060\n",
      "[ViT-LMCI] Processing subject 219/311: 099_S_0111\n",
      "[ViT-LMCI] Processing subject 220/311: 099_S_0291\n",
      "[ViT-LMCI] Processing subject 221/311: 099_S_0551\n",
      "[ViT-LMCI] Processing subject 222/311: 099_S_0880\n",
      "[ViT-LMCI] Processing subject 223/311: 099_S_1034\n",
      "[ViT-LMCI] Processing subject 224/311: 100_S_0006\n",
      "[ViT-LMCI] Processing subject 225/311: 100_S_0190\n",
      "[ViT-LMCI] Processing subject 226/311: 100_S_0296\n",
      "[ViT-LMCI] Processing subject 227/311: 100_S_0995\n",
      "[ViT-LMCI] Processing subject 228/311: 109_S_0950\n",
      "[ViT-LMCI] Processing subject 229/311: 109_S_1114\n",
      "[ViT-LMCI] Processing subject 230/311: 109_S_1183\n",
      "[ViT-LMCI] Processing subject 231/311: 109_S_1343\n",
      "[ViT-LMCI] Processing subject 232/311: 114_S_0378\n",
      "[ViT-LMCI] Processing subject 233/311: 114_S_0410\n",
      "[ViT-LMCI] Processing subject 234/311: 114_S_0458\n",
      "[ViT-LMCI] Processing subject 235/311: 114_S_1103\n",
      "[ViT-LMCI] Processing subject 236/311: 114_S_1106\n",
      "[ViT-LMCI] Processing subject 237/311: 114_S_1118\n",
      "[ViT-LMCI] Processing subject 238/311: 116_S_0361\n",
      "[ViT-LMCI] Processing subject 239/311: 116_S_0649\n",
      "[ViT-LMCI] Processing subject 240/311: 116_S_0752\n",
      "[ViT-LMCI] Processing subject 241/311: 116_S_0834\n",
      "[ViT-LMCI] Processing subject 242/311: 116_S_1243\n",
      "[ViT-LMCI] Processing subject 243/311: 116_S_1271\n",
      "[ViT-LMCI] Processing subject 244/311: 116_S_1315\n",
      "[ViT-LMCI] Processing subject 245/311: 121_S_1322\n",
      "[ViT-LMCI] Processing subject 246/311: 123_S_0050\n",
      "[ViT-LMCI] Processing subject 247/311: 123_S_0108\n",
      "[ViT-LMCI] Processing subject 248/311: 123_S_0390\n",
      "[ViT-LMCI] Processing subject 249/311: 123_S_1300\n",
      "[ViT-LMCI] Processing subject 250/311: 126_S_0708\n",
      "[ViT-LMCI] Processing subject 251/311: 126_S_0709\n",
      "[ViT-LMCI] Processing subject 252/311: 126_S_0865\n",
      "[ViT-LMCI] Processing subject 253/311: 126_S_1187\n",
      "[ViT-LMCI] Processing subject 254/311: 127_S_0112\n",
      "[ViT-LMCI] Processing subject 255/311: 127_S_0393\n",
      "[ViT-LMCI] Processing subject 256/311: 127_S_0394\n",
      "[ViT-LMCI] Processing subject 257/311: 127_S_0925\n",
      "[ViT-LMCI] Processing subject 258/311: 127_S_1032\n",
      "[ViT-LMCI] Processing subject 259/311: 127_S_1140\n",
      "[ViT-LMCI] Processing subject 260/311: 127_S_1419\n",
      "[ViT-LMCI] Processing subject 261/311: 127_S_1427\n",
      "[ViT-LMCI] Processing subject 262/311: 128_S_0947\n",
      "[ViT-LMCI] Processing subject 263/311: 128_S_1043\n",
      "[ViT-LMCI] Processing subject 264/311: 128_S_1088\n",
      "[ViT-LMCI] Processing subject 265/311: 128_S_1148\n",
      "[ViT-LMCI] Processing subject 266/311: 128_S_1407\n",
      "[ViT-LMCI] Processing subject 267/311: 128_S_1408\n",
      "[ViT-LMCI] Processing subject 268/311: 129_S_1246\n",
      "[ViT-LMCI] Processing subject 269/311: 130_S_0102\n",
      "[ViT-LMCI] Processing subject 270/311: 130_S_0423\n",
      "[ViT-LMCI] Processing subject 271/311: 130_S_0505\n",
      "[ViT-LMCI] Processing subject 272/311: 130_S_0783\n",
      "[ViT-LMCI] Processing subject 273/311: 131_S_0384\n",
      "[ViT-LMCI] Processing subject 274/311: 131_S_1389\n",
      "[ViT-LMCI] Processing subject 275/311: 132_S_0987\n",
      "[ViT-LMCI] Processing subject 276/311: 133_S_0629\n",
      "[ViT-LMCI] Processing subject 277/311: 133_S_0638\n",
      "[ViT-LMCI] Processing subject 278/311: 133_S_0727\n",
      "[ViT-LMCI] Processing subject 279/311: 133_S_0771\n",
      "[ViT-LMCI] Processing subject 280/311: 133_S_0792\n",
      "[ViT-LMCI] Processing subject 281/311: 133_S_0912\n",
      "[ViT-LMCI] Processing subject 282/311: 133_S_0913\n",
      "[ViT-LMCI] Processing subject 283/311: 136_S_0107\n",
      "[ViT-LMCI] Processing subject 284/311: 136_S_0195\n",
      "[ViT-LMCI] Processing subject 285/311: 136_S_0429\n",
      "[ViT-LMCI] Processing subject 286/311: 136_S_0579\n",
      "[ViT-LMCI] Processing subject 287/311: 136_S_0695\n",
      "[ViT-LMCI] Processing subject 288/311: 136_S_0873\n",
      "[ViT-LMCI] Processing subject 289/311: 136_S_0874\n",
      "[ViT-LMCI] Processing subject 290/311: 136_S_1227\n",
      "[ViT-LMCI] Processing subject 291/311: 137_S_0158\n",
      "[ViT-LMCI] Processing subject 292/311: 137_S_0443\n",
      "[ViT-LMCI] Processing subject 293/311: 137_S_0481\n",
      "[ViT-LMCI] Processing subject 294/311: 137_S_0631\n",
      "[ViT-LMCI] Processing subject 295/311: 137_S_0668\n",
      "[ViT-LMCI] Processing subject 296/311: 137_S_0669\n",
      "[ViT-LMCI] Processing subject 297/311: 137_S_0722\n",
      "[ViT-LMCI] Processing subject 298/311: 137_S_0800\n",
      "[ViT-LMCI] Processing subject 299/311: 137_S_0825\n",
      "[ViT-LMCI] Processing subject 300/311: 137_S_0973\n",
      "[ViT-LMCI] Processing subject 301/311: 137_S_0994\n",
      "[ViT-LMCI] Processing subject 302/311: 137_S_1414\n",
      "[ViT-LMCI] Processing subject 303/311: 137_S_1426\n",
      "[ViT-LMCI] Processing subject 304/311: 141_S_0851\n",
      "[ViT-LMCI] Processing subject 305/311: 141_S_0915\n",
      "[ViT-LMCI] Processing subject 306/311: 141_S_0982\n",
      "[ViT-LMCI] Processing subject 307/311: 141_S_1004\n",
      "[ViT-LMCI] Processing subject 308/311: 141_S_1052\n",
      "[ViT-LMCI] Processing subject 309/311: 141_S_1245\n",
      "[ViT-LMCI] Processing subject 310/311: 141_S_1255\n",
      "[ViT-LMCI] Processing subject 311/311: 941_S_1311\n",
      "Total subjects processed with ViT: 933\n",
      "                                            features label       subject_id\n",
      "0  [1.2259265, -1.5940833, -0.8396731, 1.5705092,...    AD       002_S_0619\n",
      "1  [0.9756227, -1.0976689, -0.80414844, 1.4985571...    AD  002_S_0619_aug1\n",
      "2  [1.4952822, -0.3410925, -0.34367055, 1.967998,...    AD  002_S_0619_aug2\n",
      "3  [1.6166612, -1.4291191, -1.5476533, 1.4495406,...    AD       002_S_0816\n",
      "4  [2.0281694, -1.4437882, -1.1708605, 1.7067395,...    AD  002_S_0816_aug0\n"
     ]
    }
   ],
   "source": [
    "base_path = r\"C:\\Users\\ADMIN\\Documents\\Alz_work\\DATASET\\FINAL_BALANCED_DATASET\\FINAL_BALANCED_DATASET\"\n",
    "vit_feature_df = build_vit_feature_matrix(base_path, vit_model, vit_transform, device)\n",
    "print(f\"Total subjects processed with ViT: {len(vit_feature_df)}\")\n",
    "print(vit_feature_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5682adc",
   "metadata": {},
   "source": [
    "Feature Confusion and Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707d7b97",
   "metadata": {},
   "source": [
    "Concatenate CNN + ViT Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca8445aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_features(cnn_df, vit_df):\n",
    "    # Inner join on subject_id to ensure alignment\n",
    "    merged_df = pd.merge(cnn_df, vit_df, on='subject_id', suffixes=('_cnn', '_vit'))\n",
    "\n",
    "    fused_data = []\n",
    "    for _, row in merged_df.iterrows():\n",
    "        cnn_feat = row['features_cnn']\n",
    "        vit_feat = row['features_vit']\n",
    "        fused_feat = np.concatenate([cnn_feat, vit_feat])\n",
    "        fused_data.append({\n",
    "            'features': fused_feat,\n",
    "            'label': row['label_cnn'],  # same label in both\n",
    "            'subject_id': row['subject_id']\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(fused_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f14af08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fused feature shape: (178432,)\n",
      "Total subjects fused: 933\n"
     ]
    }
   ],
   "source": [
    "fused_df = fuse_features(feature_df, vit_feature_df)\n",
    "print(f\"Fused feature shape: {fused_df.iloc[0]['features'].shape}\")\n",
    "print(f\"Total subjects fused: {len(fused_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96f12b9",
   "metadata": {},
   "source": [
    "Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2355a3",
   "metadata": {},
   "source": [
    "Applying PCA to fused features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "942e398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def apply_pca(fused_df, n_components=512):\n",
    "    # Extract feature matrix\n",
    "    X = np.stack(fused_df['features'].values)\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    # Build reduced DataFrame\n",
    "    reduced_df = pd.DataFrame({\n",
    "        'features': list(X_pca),\n",
    "        'label': fused_df['label'].values,\n",
    "        'subject_id': fused_df['subject_id'].values\n",
    "    })\n",
    "\n",
    "    print(f\"PCA explained variance ratio (top {n_components}): {np.sum(pca.explained_variance_ratio_):.4f}\")\n",
    "    return reduced_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6208159a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA explained variance ratio (top 512): 0.9649\n",
      "Reduced feature shape: (512,)\n"
     ]
    }
   ],
   "source": [
    "reduced_df = apply_pca(fused_df, n_components=512)\n",
    "print(f\"Reduced feature shape: {reduced_df.iloc[0]['features'].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2d5b60",
   "metadata": {},
   "source": [
    "Train-Test Split + Stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5af2514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def stratified_split(df, test_size=0.2, random_state=42):\n",
    "    X = np.stack(df['features'].values)\n",
    "    y = df['label'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "\n",
    "    print(f\"Train size: {len(X_train)}, Test size: {len(X_test)}\")\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "465294eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 746, Test size: 187\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = stratified_split(reduced_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f154736e",
   "metadata": {},
   "source": [
    "Training on SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e970745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def train_evaluate_svm(X_train, X_test, y_train, y_test):\n",
    "    # Initialize SVM with RBF kernel\n",
    "    svm = SVC(kernel='rbf', C=1.0, gamma='scale', probability=True)\n",
    "    svm.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    y_pred = svm.predict(X_test)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "97dc6eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[35  1 26]\n",
      " [16 27 19]\n",
      " [ 0 12 51]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.69      0.56      0.62        62\n",
      "          CN       0.68      0.44      0.53        62\n",
      "        LMCI       0.53      0.81      0.64        63\n",
      "\n",
      "    accuracy                           0.60       187\n",
      "   macro avg       0.63      0.60      0.60       187\n",
      "weighted avg       0.63      0.60      0.60       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model = train_evaluate_svm(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f068142a",
   "metadata": {},
   "source": [
    "Permutation Feature Importance (SVM-Compatible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cc15b408",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bf246586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def interpret_svm_features(model, X_test, y_test, top_k=20, save_path=None):\n",
    "    try:\n",
    "        result = permutation_importance(\n",
    "            model, X_test, y_test, n_repeats=10, random_state=42, scoring='accuracy'\n",
    "        )\n",
    "        importances = result.importances_mean\n",
    "\n",
    "        if importances is None or len(importances) == 0:\n",
    "            print(\"No importances returned. Check model or input data.\")\n",
    "            return None, None\n",
    "\n",
    "        indices = np.argsort(importances)[::-1][:top_k]\n",
    "\n",
    "        # Plot top-k important features\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(range(top_k), importances[indices], align='center', color='skyblue')\n",
    "        plt.xticks(range(top_k), [f'F{i}' for i in indices], rotation=45)\n",
    "        plt.title(\"Top Feature Importances (Permutation)\")\n",
    "        plt.xlabel(\"Feature Index\")\n",
    "        plt.ylabel(\"Importance\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "            print(f\"Plot saved to: {save_path}\")\n",
    "        else:\n",
    "            plt.show(block=True)\n",
    "\n",
    "        return indices, importances[indices]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during feature interpretation: {e}\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "35e743ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to: svm_feature_importance.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUyBJREFUeJzt3Qm8VHX9P/4PO6KhJm4ohgupCCrihhtlpn7dK5WsBM0sNdPSNPc1NTfSxDQrKzXSrMTqa5iplLkRirmlmZngimSCYoDC/B7vz/8/9zv3ctnvuTNz5/l8PEa5Z87MfOZsc17ns5xOpVKplAAAAIA217nt3xIAAAAIQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwDQcKZOnZp69uyZ7r///moXpW79+Mc/Tp06dUr/+te/CvuMp59+OnXt2jU9+eSThX0GQNGEboA6ECe2S/KYMGFCoeWIk+uFffb2229fyGe+8sor6ZxzzkmPPfZYqjXl5XHZZZelenXHHXfk5dtozjvvvLTddtulHXfcsWnaYYcd1myb7t27d9piiy3S5ZdfnubMmZMadf1eeOGFady4cakaBg4cmPbee+901llnVeXzAdpC1zZ5FwAKdeONNzb7+4Ybbkh33XXXAtM33XTTdinPIYcckvbaa69m01ZfffXCQve5556b+vfvn7bccstCPqORRSi7+uqrGyp4v/HGG+knP/lJfrTUo0eP9IMf/CD/+6233kq//OUv09e//vX0l7/8Jd18882pEddvhO4DDzwwHXDAAc2mH3rooenTn/50XmZFOuqoo/Lx5vnnn08bbrhhoZ8FUAShG6AOfO5zn2v290MPPZRDd8vp7WWrrbaq2me3ldmzZ6fu3bunzp0bs9HXrFmz0oorrpga0U033ZSbLO+7774LPBfTK7ftY445JteI33LLLWn06NGpb9++y/y58+fPT3Pnzs3N2juCLl265EfRdtttt7TqqqvmiyTRQgGg3jTmmQZABw1RJ554YurXr1+uedp4441zs+dSqdRsvmg2e+yxx6af/vSneZ4IAEOHDk1/+tOf2qwszzzzTK4Z++AHP5jff+utt06//vWvm83z5ptv5hrEwYMHp5VWWik35f2f//mf9Ne//rVpnmguv8022+R/H3744U3NfqMvaYja72gS3NJHPvKR/Kh8n3hd1FSeccYZaZ111km9evVKM2fOzM8//PDDac8990wrr7xynj58+PBl7utb7uf65z//OR133HG5BcAqq6ySvvSlL+XAFbWnI0eOzCEiHieffHKzdVTZZP3b3/52+tCHPpRWWGGFXKbW+rXec889aeedd84BOj5n//33T3/729+azRO1nPGe0T/2M5/5TP7cnXbaKS+7qAUNlc2qy6IMO+ywQ1pttdVyGWI7+cUvfrFAGcrbVDRBHjRoUN7+NttsszR+/PgF5n355ZfTEUcckcNrzLf++uuno48+Oi+bslhGX/3qV5u25Y022ihdfPHFObRWivUZZfrABz6Qt5/Ylq688srFrqMoZwTp2O4WJy7KlLelct/laGp+9tln53JF+aKcsR5bNkGv3NdiecS8sUyWdxspb88tu5OUt53y/tEW6zfmj2NLBN7y68v73ML6dH/3u99t+r6xnr/85S/n71QplmlsK7FNfvSjH837XeyXl1xyyQLroFu3bnn+22+/fbHrC6AWqekG6ADihHy//fZL9957bw400Qz7zjvvTCeddFIOORHeKv3xj3/MNXdxwh8nxnGSHKFz4sSJ+UR4cd599900ffr0ZtMisMbJ8VNPPZX7ycYJ9CmnnJLD4M9//vPcNDWa6n7iE5/I8//zn//M4eeggw7Kwev1119P3/ve93K4jBPxOFmP5vJRsxX9Ob/4xS/mcBkiKCyL888/P9duR9iPgBT/jtAaYT8CRwSpCFk/+tGP0q677pruu+++tO222y7TZ33lK19Ja621Vm4aHy0TrrvuuhysHnjggbTeeuvlJrvR9PfSSy/NyzxCVssuBG+//XYOLFErH2EyyvTEE0+kNddcM8/zhz/8IZd9gw02yMH6v//9b7rqqqvy8n/00UfzRYlKsawHDBiQPzu2mSFDhuTm+611VQjxmbFdffazn81hMEJuvMdvf/vb3M+2UgTIX/3qV7lmOELwd77znfSpT30qTZkyJYe6EJ8VyzMCWKzPTTbZJG+fEfRim4r1Ef+PbSCmRwiNZRXL7NRTT02vvvpquuKKK/J7RZmjm8PHPvaxHMhDXGyIiyXHH3/8QtfLe++9l5uKR9BfUtGsOcT3iOAfyyS+b3yH2EZjncQ+9ve//32Bvs+xfcX2H+G7T58+eZ2UxydY3m1kcWL5Le/6jdd94QtfyOstvm9YVBPv2A7j+0TtdCzjZ599Nl1zzTV5mce6iWNE2X/+85983PnkJz+ZDj744LwdfOMb38gXT2K7rhT7Z4TuuFAWF1gA6koJgLrz5S9/Oaq9mv4eN25c/vub3/xms/kOPPDAUqdOnUr/+Mc/mqbFfPGYNGlS07QXX3yx1LNnz9InPvGJRX7uCy+80PT6lo977703z/Oxj32sNHjw4NLs2bObXjd//vzSDjvsUBowYEDTtHh+3rx5C7x/jx49Suedd17TtL/85S/5/X/0ox8tUJ4PfehDpVGjRi0wffjw4flRFmWL99hggw1K7777brNyRZn22GOP/O+ymGf99dcvffzjH1+i5XHppZc2TYtyxrSW7zls2LC8Lo466qimae+//35p3XXXbVbW8nuusMIKpZdeeqlp+sMPP5ynf+1rX2uatuWWW5bWWGON0r///e+maX/9619LnTt3Lo0cObJp2tlnn51fe8ghhyx2W6pUuazC3LlzS4MGDSrtuuuuzabH67t3795sO4tyxPSrrrqqaVqUKcoW67Sl8rI6//zzSyuuuGLp73//e7PnTznllFKXLl1KU6ZMyX8ff/zxpd69e+dluDSijC3LVRbbUnz2G2+8kR8x74UXXpjX2+abb57nufHGG/N3uO+++5q99tprr83ve//99zdbLjHvU0891Wze5d1GyttzeZ9rue1U7ittsX5jmbS2n5W/R3xumDZtWt4Odt9992b79pgxY/J8119/fdO0+D4x7YYbbmiaNmfOnNJaa61V+tSnPrXAZ40dOzbPH/sBQL3RvBygA4jasOhbGTXXlaK5eZz7/+53v2s2fdiwYbnmqCxq1aJZctSOz5s3b7GfFzVeUXtW+YhRnqPJeNTsRa1V1NJGbXg8/v3vf6c99tgjPffcc7kGM0QNe7k/dXxmzBPNfaPJe9TSFmHUqFG5GW1Z1DhGmaLJdXx+ubzRnDZqUKPJfcsmzUsqWhxUNuWN5syxLmJ6WayzaHoftf4tRcuAaC1QFjWN8R6xrkPU+kb5o6lvNOMv23zzzdPHP/7xpvlaDki1NCqXVdRKzpgxI7c2aG39RM1mZQ1olCNqJMvfLZZj1AJHP+r4zi2Vl9Wtt96aPyOaVZfXRzzi/WM7KXeDiBrhWE+x7S2NWM8h3r818Z7R3Dse0Xz8tNNOy/vLbbfd1lS+qN2OWvrK8kUrhBCtTSpFrX2MwF3ENrK8lmb9LoloeRE15tE1oHKshCOPPDJvC//7v//bbP7Y3yv7z0dLh9jOW/uu5fXVsoUNQD3QvBygA3jxxRdzc+xo1tvaaObxfKVoYtzShz/84dy0N0Z2jiavixKvjxDUUjRPj9Bw5pln5kdrpk2blsNkhLBo3hpN21944YVmYb/cHLmtRTP2ShG4y2F8YSKILCygLUpcyGjZ/D5E/9+W0yPwtLSwdRRNlSvXaVykaCnWe1xAaTlYWsvvvzjRzPib3/xmDveV/ZUrg+LCvm+I5Vb+brFdRdPgxXVfiHXy+OOPL3Q0/Nh+QjRjj2URzZBje9p9993zxZ5orrwkWo51UBZjEPzmN7/J/y73OV933XWblS+asS+ufEuyzJd3G1leS7N+l8TCtskI09EFouVxKJZry8+KbSbW/8LW17KWDaCahG4A2ky5Vjj6TEfNdmui9jBEf9UI5p///OdzX+uorY3asaglW9La5YWdgEeAb21U5cqavcryRp/Zhd2ObEkG22rNwkZ1bm36wgJgW2v5/Rcl+rNHf99ddtklXxhZe+21c3/c6O8+duzYJf6+S/vdYp1ETX0MHtaauPAQ1lhjjRwW4+JCtOSIR5Qt+j23diuwlhd0FhZi43u0dkGpsnzR5zhGMm9Ny8C8qGW+rNvIorb7otZvEZZmmymvr+gXD1BvhG6ADiBGuI6mndGku7K2O0YRLz/fWg1vpRgEKkYQXp77bUdtVoiT90UFlxCDJsWoxT/84Q+bTY9BtipPrBdVsxW1Yi1HRQ5Ro1Yuy6KUm0NH09fFlbe9LWwdlQdHK6/TGKiqpVjvsQyX5JZgC1u+Mehd1PpGqK28D3OEsmUR21Us59ZGYG+5Tt55550lWh9RgxrN1eMRYThqv2MwvriYU76401rtcgThaF2xLKJ8McJ+dD+oVq1rueVFy22/ZU1yW63fJf2eldtk5f4XTc5jeS/PPhavj4ty5YsuAPVEn26ADmCvvfbKtVxjxoxpNj1GVI4T5pYjAT/44IPN+m1OnTo1jwwcTXSX5767UfsYt/aJ4BN9jluKJsZl8Tkta7Siv2y5z3dZOTi2Fq4jAMWoz5W3m4oms/F9lkT0a4/3iFsnRdBbVHnbW/R/rlwW0XQ/bm1WXpdRMxm181GrW7lsItT+/ve/z9vEkljY8o31E9tOZe1p3Bqq5ejcSyoCU/RTj6bbkyZNWuD58rYQTcRj+4ww2FKU8f3332/WN7vy/aMfeWh5665KcUEo+ki3VoYlEeWL9fL9739/gedi9Pho0l+0CLexflre5i9qrItYv/Eere1/LUWojgshMXJ95b4dF9aim0bLEe+XxiOPPJJvQ1Zugg9QT9R0A3QAUdMXtcann356PnGOQc0ieEWQjubaLW/xE/1qo/l35S3DQtzqZ3nFfYHjHtDRBDcGUIoar7gdWASpl156qek+3Pvss0++HVjcfztuARa3XYr7GbesoY6yx6BZ1157ba7FjwAQA05FX9m4lVHUmEc/3ghDcWunm266aZG3NGoZ1H7wgx/kIBsn9FGW6B8coSoGxIqa2XL/3vYWNbWxHOO2SxEi41ZZ0TS6stl1NIuPssdAXzH4VvmWYRFM4tZNS6I8oF5sC7FNRBj79Kc/nQNSNKGOZRsDzUVf5Vi3Ua7W+twuiehSENtlDC5Wvt1WXJyJiy1xC65Yz3Gbu7ine2wfMUhclC+CbGwfsa5j+45a/Fj3MXBfDGAWfYOjlje+e1yIKI9lsDAxaGDsK8ty+6lDDz009yWPQeliG4nbs0VwjdYFMT0uFrQ2UFxbivUbt/aK7xvBObb3uNjUsj95W63feI9oSRPzx9gRse/FPthaa4a4tVscR+J9o/l61HrH8WWbbbZpNmja0ojbvMVtDqMlA0Bdqvbw6QAsvdZuA/T222/n20n17du31K1bt3wrrLiVVeUtiUK8Ll5/00035XniFl1DhgxZ4PZDS3qLrNY8//zz+fZQcfufKMs666xT2meffUq/+MUvmt0y7MQTTyytvfba+fZYO+64Y+nBBx9c4HZf4fbbby8NHDiw1LVr1wVuiXT55Zfn94/vEe8Rt0Jb2C3Dbr311lbLO3ny5NInP/nJ0mqrrZbfJ25FdvDBB5fuvvvupV4e5dsotbwtVvm2XXErqtZuU9Xae8Z369evXy7TzjvvnG/D1dIf/vCH/L1jGcYttPbdd9/S008/vUSfXb4l1Ve+8pXS6quvnm9XVbld/fCHP2zaRjbZZJP83crv1do2tSS3dIvb08W2EZ8X7xu3cYvXxu2iKrflU089tbTRRhvlW1D16dMn33Lusssuy7e1CrEtxa2p4pZpMc96661X+tKXvlR69dVXS4vz+uuv520pbv+1qHWxMFGGiy++uLTZZpvl77DqqquWhg4dWjr33HNLM2bMWOxyWd5tJMQ8cWutXr165c+P7/7kk08usH+0xfp95plnSrvsskvexuK58jptecuwyluExfvFvr/mmmuWjj766NJ//vOfZvPE/hnLr6V479huKv3ud7/Ln/Pcc88tMD9APegU/6l28Aeg/UTN2Je//OUFmqJTG6ImN2oSoxY7BqSjGNEyIPrIx4Bi1LbolhDHrfJt2wDqjeblAEDDOfvss/OgXPfff39uIk5tituzRdP5GKkeoF4J3QBAw4lRzGfPnl3tYrAY0T+/PHgeQL0yejkAAAAURJ9uAAAAKIiabgAAACiI0A0AAAAFMZBaK+bPn59eeeWV9IEPfCDfogIAAAAqRU/tt99+O/Xt2zd17rzw+myhuxURuPv161ftYgAAAFDjpk6dmtZdd92FPi90tyJquMsLr3fv3tUuDgAAADVm5syZubK2nB8XRuhuRblJeQRuoRsAAICFWVyXZAOpAQAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABSka1FvTPG+NXl6qgWnDOlT7SIAAADUJDXdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAB05dF999dWpf//+qWfPnmm77bZLEydOXOT8t956a9pkk03y/IMHD0533HHHQuc96qijUqdOndIVV1xRQMkBAACghkP3Lbfckk444YR09tlnp0cffTRtscUWaY899kjTpk1rdf4HHnggHXLIIemII45IkydPTgcccEB+PPnkkwvMe9ttt6WHHnoo9e3btx2+CQAAANRY6B49enQ68sgj0+GHH54GDhyYrr322tSrV690/fXXtzr/lVdemfbcc8900kknpU033TSdf/75aauttkpjxoxpNt/LL7+cvvKVr6Sf/vSnqVu3bu30bQAAAOD/dE1VNHfu3PTII4+kU089tWla586d02677ZYefPDBVl8T06NmvFLUjI8bN67p7/nz56dDDz00B/PNNttsseWYM2dOfpTNnDlzGb8RrfnW5OmpFpwypE+1iwAAADSYqtZ0T58+Pc2bNy+tueaazabH36+99lqrr4npi5v/4osvTl27dk3HHXfcEpXjoosuSiuvvHLTo1+/fsv0fQAAAKCmmpe3tag5jyboP/7xj/MAaksiatpnzJjR9Jg6dWrh5QQAAKDjq2ro7tOnT+rSpUt6/fXXm02Pv9daa61WXxPTFzX/fffdlwdhW2+99XJtdzxefPHFdOKJJ+YR0lvTo0eP1Lt372YPAAAAqOvQ3b179zR06NB09913N+uPHX8PGzas1dfE9Mr5w1133dU0f/Tlfvzxx9Njjz3W9IjRy6N/95133lnwNwIAAIAaGUgtxKBoo0aNSltvvXXadttt8/20Z82alUczDyNHjkzrrLNO7ncdjj/++DR8+PB0+eWXp7333jvdfPPNadKkSem6667Lz6+22mr5USlGL4+a8I033rgK3xAAAIBGVfXQPWLEiPTGG2+ks846Kw+GtuWWW6bx48c3DZY2ZcqUPKJ52Q477JDGjh2bzjjjjHTaaaelAQMG5JHLBw0aVMVvAQAAAAvqVCqVSq1Mb2hxy7AYxTwGVavl/t31ciuueiknAABAW+fGDjd6OQAAANQKoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoSNei3hjqzbcmT692EdIpQ/pUuwgAAEAbUtMNAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAgnQt6o2BYnxr8vRqFyGdMqRPtYsAAAB1QU03AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABARx69/Oqrr06XXnppeu2119IWW2yRrrrqqrTtttsudP5bb701nXnmmelf//pXGjBgQLr44ovTXnvt1fT8Oeeck26++eY0derU1L179zR06NB0wQUXpO22266dvhFglHUAAKiBmu5bbrklnXDCCenss89Ojz76aA7de+yxR5o2bVqr8z/wwAPpkEMOSUcccUSaPHlyOuCAA/LjySefbJrnwx/+cBozZkx64okn0p///OfUv3//tPvuu6c33nijHb8ZAAAAja7qoXv06NHpyCOPTIcffngaOHBguvbaa1OvXr3S9ddf3+r8V155Zdpzzz3TSSedlDbddNN0/vnnp6222iqH7LLPfOYzabfddksbbLBB2myzzfJnzJw5Mz3++OPt+M0AAABodFUN3XPnzk2PPPJIDshNBercOf/94IMPtvqamF45f4ia8YXNH59x3XXXpZVXXjnXordmzpw5OZRXPgAAAKCuQ/f06dPTvHnz0pprrtlsevwd/btbE9OXZP7f/va3aaWVVko9e/ZM3/72t9Ndd92V+vRpvX/nRRddlEN5+dGvX7/l/m4AAABQ9eblRfnoRz+aHnvssdwHPJqjH3zwwQvtJ37qqaemGTNmND1iADYAAACo69AdNc9dunRJr7/+erPp8fdaa63V6mti+pLMv+KKK6aNNtoobb/99umHP/xh6tq1a/5/a3r06JF69+7d7AEAAAB1HbrLt/O6++67m6bNnz8//z1s2LBWXxPTK+cP0XR8YfNXvm/03QYAAICGuU933C5s1KhRaeutt8735r7iiivSrFmz8mjmYeTIkWmdddbJ/a7D8ccfn4YPH54uv/zytPfee+f7cU+aNCkPlhbitXFP7v322y+tvfbaud943Af85ZdfTgcddFBVvysAAACNpeqhe8SIEfn+2WeddVYeDG3LLbdM48ePbxosbcqUKXlE87IddtghjR07Np1xxhnptNNOSwMGDEjjxo1LgwYNys9Hc/Vnnnkm/eQnP8mBe7XVVkvbbLNNuu+++/LtwwAAAKBhQnc49thj86M1EyZMWGBa1FgvrNY6Riv/1a9+1eZlBAAAgKXVYUcvBwAAgGoTugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAGotdN94441pxx13TH379k0vvvhinnbFFVek22+/vS3LBwAAAI0Vuq+55pp0wgknpL322iu99dZbad68eXn6KquskoM3AAAAsIyh+6qrrkrf//730+mnn566dOnSNH3rrbdOTzzxRFuWDwAAABordL/wwgtpyJAhC0zv0aNHmjVrVluUCwAAABozdK+//vrpscceW2D6+PHj06abbtoW5QIAAIC613VZXhT9ub/85S+n2bNnp1KplCZOnJh+9rOfpYsuuij94Ac/aPtSAgAAQKOE7i984QtphRVWSGeccUZ6991302c+85k8ivmVV16ZPv3pT7d9KQEAAKBRQnf47Gc/mx8Rut955520xhprtG3JAAAAoBFDdwyk9v7776cBAwakXr165Ud47rnnUrdu3VL//v3bupwAAADQGAOpHXbYYemBBx5YYPrDDz+cnwMAAACWMXRPnjw57bjjjgtM33777Vsd1RwAAAAa0TKF7k6dOqW33357gekzZsxI8+bNa4tyAQAAQGOG7l122SXfHqwyYMe/Y9pOO+3UluUDAACAxhpI7eKLL87Be+ONN04777xznnbfffelmTNnpnvuuaetywgAAACNU9M9cODA9Pjjj6eDDz44TZs2LTc1HzlyZHrmmWfSoEGD2r6UAAAA0Ej36e7bt2+68MIL27Y0AAAA0IEsc+h+66230sSJE3NN9/z585s9F7XeAAAA0OiWKXT/5je/SZ/97GfTO++8k3r37p1HMy+LfwvdAAAAsIx9uk888cT0+c9/PofuqPH+z3/+0/R48803276UAAAA0Cih++WXX07HHXdc6tWrV9uXCAAAABo5dO+xxx5p0qRJbV8aAAAAaPQ+3XvvvXc66aST0tNPP50GDx6cunXr1uz5/fbbr63KBwAAAI0Vuo888sj8//POO2+B52IgtXnz5i1/yQAAAKARQ3fLW4QBAAAAbdSnGwAAACiopjvMmjUr/fGPf0xTpkxJc+fObfZcjGwOAAAAjW6ZQvfkyZPTXnvtld59990cvj/4wQ+m6dOn51uIrbHGGkI3AAAALGvz8q997Wtp3333Tf/5z3/SCiuskB566KH04osvpqFDh6bLLrus7UsJAAAAjRK6H3vssXTiiSemzp07py5duqQ5c+akfv36pUsuuSSddtppbV9KAAAAaJTQHffljsAdojl59OsOK6+8cpo6dWrblhAAAAAaqU/3kCFD0l/+8pc0YMCANHz48HTWWWflPt033nhjGjRoUNuXEgAAABqlpvvCCy9Ma6+9dv73BRdckFZdddV09NFHpzfeeCN973vfa+syAgAAQOPUdG+99dZN/47m5ePHj2/LMgEAAEDj1nTvuuuu6a233lpg+syZM/NzAAAAwDKG7gkTJqS5c+cuMH327Nnpvvvua4tyAQAAQGM1L3/88ceb/v3000+n1157renvefPm5Wbm66yzTtuWEAAAABohdG+55ZapU6dO+dFaM/IVVlghXXXVVW1ZPgAAAGiM0P3CCy+kUqmUNthggzRx4sS0+uqrNz3XvXv3PKhaly5diignAAAAdOzQ/aEPfSi99957adSoUWm11VbLfwMAAABtNJBat27d0m233ba0LwMAAICGs0yjl++///5p3LhxbV8aAAAAaNTm5WUDBgxI5513Xrr//vvT0KFD04orrtjs+eOOO66tygcAAACNFbp/+MMfplVWWSU98sgj+VEpRjYXugEAAGAZQ3eMYg4AAAAU0Ke7UtxCLB4AAABAG4XuG264IQ0ePDitsMIK+bH55punG2+8cVnfDgAAADqcZWpePnr06HTmmWemY489Nu2444552p///Od01FFHpenTp6evfe1rbV1OgDb3rcnTUy04ZUifahcBAIBaCt1XXXVVuuaaa9LIkSObpu23335ps802S+ecc47QDQAAAMvavPzVV19NO+ywwwLTY1o8BwAAACxj6N5oo43Sz3/+8wWm33LLLfke3gAAAMAyNi8/99xz04gRI9Kf/vSnpj7d999/f7r77rtbDeMAAADQiJappvtTn/pUevjhh1OfPn3SuHHj8iP+PXHixPSJT3yi7UsJAAAAjVLTHYYOHZpuuummti0NAAAAdCDLHLrnzZuXbrvttvS3v/0t/z1w4MC0//77p65dl/ktAQAAoENZpoT81FNP5VuEvfbaa2njjTfO0y6++OK0+uqrp9/85jdp0KBBbV1OAAAAaIw+3V/4whfyPblfeuml9Oijj+bH1KlT0+abb56++MUvtn0pAQAAoFFquh977LE0adKktOqqqzZNi39fcMEFaZtttmnL8gEAAEBj1XR/+MMfTq+//voC06dNm5bv4Q0AAAAsY+i+6KKL0nHHHZd+8Ytf5Cbm8Yh/f/WrX819u2fOnNn0AAAAgEa1TM3L99lnn/z/gw8+OHXq1Cn/u1Qq5f/vu+++TX/HczHKOQAAADSiZQrd9957b9uXBAAAADqYZQrdw4cPb/uSAAAAQAezTKE7zJ49Oz3++ON58LT58+c3ey7u4Q0AAACNbplC9/jx49PIkSPT9OnTF3hOP24AAABYjtHLv/KVr6SDDjoovfrqq7mWu/IhcAMAAMByhO64R/cJJ5yQ1lxzzWV5OQAAADSEZQrdBx54YJowYULblwYAAAAavU/3mDFjcvPy++67Lw0ePDh169at2fPHHXdcW5UPAAAAGit0/+xnP0u///3vU8+ePXONdwyeVhb/FroBAABgGUP36aefns4999x0yimnpM6dl6mFOgAAAHR4y5SY586dm0aMGCFwAwAAwCIsU2oeNWpUuuWWW5blpQAAANAwlql5edyL+5JLLkl33nln2nzzzRcYSG306NFtVT4AAABorND9xBNPpCFDhuR/P/nkk21dJgAAAGjc0H3vvfe2fUkAAACgkUP3Jz/5ycXOE7cM++Uvf7k8ZQIAAIDGC90rr7xycSUBAACARg7dP/rRj4orCQAAAHQwbrQNAAAABRG6AQAAoCBCNwAAAHTk0H311Ven/v37p549e6btttsuTZw4cZHz33rrrWmTTTbJ8w8ePDjdcccdTc+999576Rvf+EaevuKKK6a+ffumkSNHpldeeaUdvgkAAADUUOi+5ZZb0gknnJDOPvvs9Oijj6Ytttgi7bHHHmnatGmtzv/AAw+kQw45JB1xxBFp8uTJ6YADDsiPJ598Mj//7rvv5vc588wz8/9/9atfpWeffTbtt99+7fzNAAAAaHRVD92jR49ORx55ZDr88MPTwIED07XXXpt69eqVrr/++lbnv/LKK9Oee+6ZTjrppLTpppum888/P2211VZpzJgxTbc1u+uuu9LBBx+cNt5447T99tvn5x555JE0ZcqUdv52AAAANLKqhu65c+fmMLzbbrv9X4E6d85/P/jgg62+JqZXzh+iZnxh84cZM2akTp06pVVWWaXV5+fMmZNmzpzZ7AEAAAB1HbqnT5+e5s2bl9Zcc81m0+Pv1157rdXXxPSlmX/27Nm5j3c0Se/du3er81x00UW5hrz86Nev3zJ/JwAAAKiZ5uVFikHVopl5qVRK11xzzULnO/XUU3NtePkxderUdi0nAAAAHVPXan54nz59UpcuXdLrr7/ebHr8vdZaa7X6mpi+JPOXA/eLL76Y7rnnnoXWcocePXrkBwAAAHSYmu7u3bunoUOHprvvvrtp2vz58/Pfw4YNa/U1Mb1y/hADp1XOXw7czz33XPrDH/6QVltttQK/BQAAANRgTXeI24WNGjUqbb311mnbbbdNV1xxRZo1a1YezTzEPbbXWWed3O86HH/88Wn48OHp8ssvT3vvvXe6+eab06RJk9J1113XFLgPPPDAfLuw3/72t7nPeLm/9wc/+MEc9AEAAKAhQveIESPSG2+8kc4666wcjrfccss0fvz4psHS4jZfMaJ52Q477JDGjh2bzjjjjHTaaaelAQMGpHHjxqVBgwbl519++eX061//Ov873qvSvffemz7ykY+06/cDAACgcVU9dIdjjz02P1ozYcKEBaYddNBB+dGa/v3754HTAAAAoNo69OjlAAAAUE1CNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAF6VrUGwPQNr41eXq1i5BOGdKn2kUAAKhLaroBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQkK5FvTEAjeVbk6dXuwjplCF9ql0EAIBm1HQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQkK5FvTEA1KJvTZ5e7SKkU4b0qXYRAIB2oqYbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAgnQt6o0BgGXzrcnTUy04ZUifahcBAOqemm4AAADoqKH76quvTv379089e/ZM2223XZo4ceIi57/11lvTJptskucfPHhwuuOOO5o9/6tf/SrtvvvuabXVVkudOnVKjz32WMHfAAAAAGowdN9yyy3phBNOSGeffXZ69NFH0xZbbJH22GOPNG3atFbnf+CBB9IhhxySjjjiiDR58uR0wAEH5MeTTz7ZNM+sWbPSTjvtlC6++OJ2/CYAAABQY6F79OjR6cgjj0yHH354GjhwYLr22mtTr1690vXXX9/q/FdeeWXac88900knnZQ23XTTdP7556etttoqjRkzpmmeQw89NJ111llpt912a8dvAgAAADU0kNrcuXPTI488kk499dSmaZ07d85h+cEHH2z1NTE9asYrRc34uHHjCi8vAFCfA77VQjkNSgfQuKoWuqdPn57mzZuX1lxzzWbT4+9nnnmm1de89tprrc4f05fHnDlz8qNs5syZy/V+AAAAUBMDqdWCiy66KK288spNj379+lW7SAAAAHQAVQvdffr0SV26dEmvv/56s+nx91prrdXqa2L60sy/pKKJ+4wZM5oeU6dOXa73AwAAgKqG7u7du6ehQ4emu+++u2na/Pnz89/Dhg1r9TUxvXL+cNdddy10/iXVo0eP1Lt372YPAAAAqNs+3SEGRRs1alTaeuut07bbbpuuuOKKfMuvGM08jBw5Mq2zzjq5+Xc4/vjj0/Dhw9Pll1+e9t5773TzzTenSZMmpeuuu67pPd988800ZcqU9Morr+S/n3322fz/qA1f3hpxAICiGPANoGOqaugeMWJEeuONN/ItvmIwtC233DKNHz++abC0CM8xonnZDjvskMaOHZvOOOOMdNppp6UBAwbkkcsHDRrUNM+vf/3rptAePv3pT+f/x73AzznnnHb9fgAAADS2qobucOyxx+ZHayZMmLDAtIMOOig/Fuawww7LDwAAAKg2o5cDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAArStag3BgCg4/nW5OnVLkI6ZUifmi/jkpQTaAxqugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBdi3pjAABg4b41eXqqBacM6VPz5VxcGaGWqekGAACAggjdAAAAUBChGwAAAAoidAMAAEBBDKQGAADUvXoY8K0WyhgMTNe+1HQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoSNei3hgAAID6863J01MtOGVIn9QRqOkGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBHDt1XX3116t+/f+rZs2fabrvt0sSJExc5/6233po22WSTPP/gwYPTHXfc0ez5UqmUzjrrrLT22munFVZYIe22227pueeeK/hbAAAAQI2F7ltuuSWdcMIJ6eyzz06PPvpo2mKLLdIee+yRpk2b1ur8DzzwQDrkkEPSEUcckSZPnpwOOOCA/HjyySeb5rnkkkvSd77znXTttdemhx9+OK244or5PWfPnt2O3wwAAIBGV/XQPXr06HTkkUemww8/PA0cODAH5V69eqXrr7++1fmvvPLKtOeee6aTTjopbbrppun8889PW221VRozZkxTLfcVV1yRzjjjjLT//vunzTffPN1www3plVdeSePGjWvnbwcAAEAjq2ronjt3bnrkkUdy8++mAnXunP9+8MEHW31NTK+cP0Qtdnn+F154Ib322mvN5ll55ZVzs/WFvScAAAAUoWuqounTp6d58+alNddcs9n0+PuZZ55p9TURqFubP6aXny9PW9g8Lc2ZMyc/ymbMmJH/P3PmzFTLZr/zdqoFM2d2X+Tzytl2ZQzK2bHWeb2Us6Os83opZy2UMShn2+ko22a9lLMWyhiUs+3YNttWRylntZXzYrS2rtnQXSsuuuiidO655y4wvV+/flUpT71ZcMnVpnooZz2UMShn45WzHsoYlLNtKWdjlTEoZ9tSzsYqY1DOxizn22+/nVtX12To7tOnT+rSpUt6/fXXm02Pv9daa61WXxPTFzV/+f8xLUYvr5xnyy23bPU9Tz311DyYW9n8+fPTm2++mVZbbbXUqVOn1FHFlZm4sDB16tTUu3fvVKuUs7HKGJSzbSlnY5UxKGfjlbMeyhiUs20pZ2OVMShnbYka7gjcffv2XeR8VQ3d3bt3T0OHDk133313HoG8HHjj72OPPbbV1wwbNiw//9WvfrVp2l133ZWnh/XXXz8H75inHLJjpcco5kcffXSr79mjR4/8qLTKKqukRhE7Qj3sDMrZWGUMytm2lLOxyhiUs/HKWQ9lDMrZtpSzscoYlLN2LKqGu2aal0cN86hRo9LWW2+dtt122zzy+KxZs/Jo5mHkyJFpnXXWyU3Aw/HHH5+GDx+eLr/88rT33nunm2++OU2aNCldd911+fmomY5A/s1vfjMNGDAgh/AzzzwzX30oB3sAAABoD1UP3SNGjEhvvPFGOuuss/JAZ1E7PX78+KaB0KZMmZJHNC/bYYcd0tixY/MtwU477bQcrONWYIMGDWqa5+STT87B/Ytf/GJ666230k477ZTfs2fPnlX5jgAAADSmqofuEE3JF9acfMKECQtMO+igg/JjYaK2+7zzzssPFi6a1J999tkLNK2vNcrZWGUMytm2lLOxyhiUs/HKWQ9lDMrZtpSzscoYlLM+dSotbnxzAAAAYJn8X7ttAAAAoE0J3QAAAFAQoRsAAAAKInQDAABAQYRugAZj/EyAjqtejvH1Uk5oC0J3A3vllVfS3//+91Qv6uXgPH/+/FQParmc//3vf9P777+f6kUtL8uW/vWvf6WxY8fm/amW96l58+ZVuwhUUS1vmzS2Wt4233zzzaZb59aDcjlrdZn6HSpGqUbXd9GE7gb11FNPpZ133jndfPPNNX1geeyxx9LnPve5XL5a/hF5/vnn0w033JCDYufOnWs2hEWYjcfcuXNzOWt12zzssMPSo48+mt57771Uq95+++18gvPuu+/W7LJs6YknnkgDBw5MF154Yd6f4lGLP35xMfDiiy9OL730UqpVL7/8cnrggQfS7bffnmbPnt10DK2FfT8uqP72t79Nv//979M//vGPVA/eeOON9OSTT6Z77703/12rx/s4dtaqWtj2lnYfevDBB9MvfvGLfDwtL9ta+x6vv/563jbvv//+mg6KUcZddtkln4vUsjhfit+g4447Lt12223pnXfeqcn9vR5+h1544YV03XXXpXPPPTdNnjy5Zs+ZYh966qmn0oQJE2p6Hypc3KebxvLYY4+VevXqVVpjjTVKG264Yendd98t1Wo5V1hhhdI3vvGNZtPnz59fqiVvvfVWad111y1tuummpTFjxpTee++9mizn008/Xdpnn31K22yzTWnjjTcu/e///m/NlfPJJ58srbLKKqUjjzyy9OKLL5Zq1eOPP14aOnRoafDgwaW11lqrdPrpp5ceeeSRUi2L/WnFFVcsHXjggXl7vfrqq0u16O233y5tttlmpU6dOpVOOeWU0uuvv970XK1sq3/9619L66yzTi5njx49SgMHDixdccUVpTfffDM/P2/evKpum3Fc32KLLUprrrlm6aCDDiq99NJLpVr2xBNPlLbaaqt8DI1j/h577FGqRXF82n333UuTJ08u1ZrnnnuudO2115amT59eqgexD8VxaKeddip98IMfLA0aNKh0/vnn18Q+1LKcsT8NGDCg9IEPfKC0/fbbl37961+X3nnnnZo6JsXve/x2fu1rXys9//zzCzxfK+WM49Pqq69e+uQnP5n39y233LJ0zz33lGpNPfwOxbKM84+Pf/zjpT59+uTfoX/84x+lWhP70EYbbVTaeuutS6uttlr+bRo7dmxexrW0PNuD0N1gykH2jDPOKE2ZMiXvCHGyWGsbfjkgfP3rX282vZbKWPbKK6+U+vfvX9phhx3yCUQE7//+97/5uXIAr7annnoqH+yOPfbY0nXXXVc69NBDS7179y7985//LNWKmTNnlj7ykY/kMpZF+Z599tnSa6+9VqoVcTEgfuCinHfeeWfpnHPOKQ0bNiyv+7vuuqtUyxfa4uLA+++/X9p3331Ln/rUp2p2n/rKV75SOvjgg/MJTyznl19+udnz1Twhj1ATASEuBk6dOrU0Y8aM0uGHH17adtttS8ccc0xT6KnGco39Ze21184niRFebr755vx3hNpaFft3nISfdtpp+cLVX/7yl3wi+dWvfrVUS1544YX8exnb5CabbFJTy/Tvf/97aeWVV85lu+SSS/KF4FoW+3Mswzh2/vvf/87TPvvZz5a6d+9eGjVqVFPAqfaxKX53InDHthnrO7bV3XbbrbT55puXLr300vybVQvimP65z32udMQRRzQtt9iPbr311nzBrVyxUu0LGbE849h55plnNk2L0H3llVc2m6/a5ayH36Eoy4c//OG8D82ZMydP69u3b+mGG26oqWUZOWODDTbI5XzhhRfyPhPnSnGBKLaD//znP6VGInQ3YOCOH5AQwTCukMWjlsTBJALiJz7xiabgevLJJ+cro3Fie/3115f+9a9/lWrJ0UcfXZowYULp85//fC5jBNtQC7Wfb7zxRumjH/1o6bjjjms2PWpqy9tCtU9uQlz13HHHHfMV+1jn5Vr5VVddtbTLLruUbrvttlItiCATIbvygkqE7ahBjhOI2A5qSZwoxklDXGgrGzduXJ5Wa2UtnyBES4dbbrklly/KGQEslndc0IrtuZqeeeaZ0oc+9KHSww8/3DQt9p8LL7ywtN122+ULheUr+O3t29/+9gK1xPH3TTfdVPrlL3+ZT8RrSdQWHnLIIfn4WXlyGCdoEW5q5dgUJ7UXXHBB6YADDig9+uij+XgaF1qjpqnaYluLwBq/Peedd17eX2JbrOXg/Yc//CH//sQF6/JxNEJttB6J6bE9lGuSqyn2l/XXXz/v85W+9KUv5WN9tBYqB55qmjt3bq6BL/9GxsXrWI7lVjgnnHBCTbSAeOihh/LFlr/97W9N00aOHFn68pe/nI8DccEotolq7/f18DsUF/zj4k9c+C2Lc5A4BsTyjHLXwjqP352okIqL03Pnzs3T7r333nyRMGq+Y52XpzeC+uiIyHKbM2dOGj9+fPra176WLrjggtxnqmfPnun888/P/ZR+9rOfpVoQ/Y1fffXVtNVWW6Vp06alP/3pT2nfffdNEydOTGussUbacMMNc5lHjx6d+4hUS/TjreyP8uKLL+b+P1deeWXaeOON04033pi23HLLtNtuu+VlX60+arE8p06dmvtMRd/4UO57usEGG6S33nor/7ua/anKyzLW99NPP53L+tWvfjX37xszZkz63ve+lzbddNN0zDHHpLvvvrvq5Yx++7Guoz9iWazn448/Pq2//vp5G6ilPmD9+vXLyzH2mxDb4u67757LfP311+dtpFaU+8bvuuuu+bg0fPjw9Jvf/CYv00GDBqVLLrmkaT1US7du3fKjvI5je4j959RTT83L9c4770wPP/xwfq699vtZs2Y1lSUGynvuuefy33Gsj37d3/3ud/P632efffLyrBVdu3bNyy7278pxEQYPHpz++c9/5nVdC+ONxPrefPPN8zF0yJAhub98//7903777ZfHSWhNe/RVjOUTfTijTHvuuWc688wz875y+umn53U+Y8aMVIviNz4eK620Ut4GQpR1o402SsOGDUt33XVXevbZZ6ve5zO2vfgdit+kEGM3hGuvvTZvo7GMp0yZUvVyxvbZu3fv9O9//zudfPLJqUePHumnP/1p/k0dMWJEHnvixz/+cdXLGcsyzofi+BjL8lvf+lYe1HPFFVfMz8WxKc5Rq93Hux5+h2bOnJnHwYjjZLj00kvTuHHj8u/SX//61/z3ZZddVvUxKOLcOMYYie2zW7dueVpsAx/5yEfSeuutl/uj1+pxqhDVTv20z9Xa6DvTsoluXEmcNm1argmJZknxdzWbokyaNCk3l4ly/vnPf87NX6O5WfShq7yqeNVVV+U+YPfff3/VyhlNzqKZcXl5XX755aUTTzyxaZ5oThPN40866aSmae195ba8PKP5Xlz1LCtfVTz++ONLRx11VLPXtHf//vKyjGZH0URu//33z8txr732yldDy6KfUrR0iFrEWI7VWJaxTmOdP/jgg7lP/I033pjLXOnnP/95bhr7pz/9qVQLFnUFOWruoqzlmoVqN0Or/Pxf/epXud9X2a677pprGkaMGNHU57NaYp3vvPPOubZz9uzZeVplq4eo7Y5ttb23zajxuP322/PnR1/ET3/603mZRauG2A5i241m8LFvRa1DtWuQy+u7cn2Wp0Wf2fgOlSr7VLan8nJqubyimWTLGu/YDmLfb49a2ljv0dw9Woa9+uqrzZ6L5rrlGu9Y1+XttmXz2GqJGrg49kST6Ggx8sc//rG00kor5WNSiPOVlmO5VEPs39GXO8ZFqJxWFs9Fl5JqKu8zn/nMZ0rDhw/PXcfit6nSF77whVwTXm3RKiBaMMZv/sc+9rFcE/+b3/ym6fkYkyBaFkRrt2qpl9+haKk6ZMiQ0nrrrZdbBcW58vjx45ueP/XUU3OrgmodNytb2sVYCHHu9sorr+Q8El3dyl0Kokl8y+4FHZnQ3QBNymODj74pZS1DSzSF7tq1a1UPdK2VM0JXNOcpN4GtPBhGP8Vzzz23auVs2d8wmtCUm0PGiW0MYBQnt9Es+rLLLmv3vt3lclb2jw6V5YhlXRkOoo/a9773vQWCZHsuyzjpigNyly5d8olYpbgwVI0BlsrljIsUZYcddli+8PPAAw8sMH+EhcqLLdWwqABd3vfjRztOblteeGlPcZEnHi2baMZFmLgAE6KPZwy4FE2n48Qi9q+4WFiNZVneN2KgouiHHE0iWy7XGAwqTijbI9SWt83KriMRvH/4wx/mk5xoulkpupNE95f22scXtzwrl1Hl9BjkMU4Yy2J/2m+//ZrGyqhmOSv/HYG2HLyjK1G52XHRTU9bW+8tL7LFWC3l4B37S2wPEXLbcxkuah+67777cjeN+C2PMTIqj5l77713s3OBah6P4jyk5bIu/47G+o4+v+0tBvKLLgWxLMvbY1x4ie0w1vlFF13UbP4IjxHQ2rvbS+V6Ly+zWLbRReN3v/td/q2srAyKQBYXENu720Zc1P/JT37SVMZyuWvpd6hlGUPsy9FVIy6yxEWVyibc0eWtXKHRnqKPdvw+xgW+cll+/OMf526Cffv2zWMJVZ7zRRPzb37zm6VGIXR3YDFiYASYcr/dsvIPSvnAElflo89F/IBUo2/FwsoZ4uSl8spylDl+XKKvb3v38V3U8oyBbGJwiKhdipOIOEDOmjUrnyhGTX17XhVd0vUeJxFR3hADWsSPdXv92C1qnZ911lm5LBFoKn8wokYhTsTaMzC0LGd52cWJTlztjnV99913N6vxjJPw73znO6VaH8U4lmOMlRA/etXo+7Ww0fTLx6SosY0TsLiAFbV6IQYGiosd7TWwXmvLsrwNRK1CnEjEhauoZS6fDEVNU7TSKfpCW8tts3zyXf7cuNgX5ag88Y19PkJCte5YsaTb5u9///tcgxPi+0WNWPQHrcWRwCPIxEWWOGbF+ii63/ziju+Vx8eoQerWrVu+EBAXMqsx6vqilmWEhvjNiVHhy+Ic5H/+539y67HQXi0yFnY8imNRXIyOmviWFyhjX4q+9LGPtVc5W7urS3mfjwAWFzLirhpxUaN8PhchJ85D2vOCS2vrvfKYGC3GWl6giu8UdzFoz9+jhd19ppZ+hxZVxnKlT2y3laIff5zXt+fYDjEuQ1zUjcHyYqC0yhrsWFYTJkwoTZw4sdnyjdYDMU5TqHbrq/YgdHdQMWJgXD1ueRU2rtLFFe+WwSUOdnEVqtwUrdrljB/cCASt1dhFKItakHhtLSzPKGeErvgBiRPFuIpbFsuzPZv0Lcl6Lx+woxl3HJijhrtnz57tNujbwsoY5SgP9hW1yhFoo7lclDuuKsfAG5UnZ9UqZ4SZaLoVPxhxFTzmifLGD0z8P35soklVPYxiHAMSxrzf/e53S7U0mn4EiFiWMbBeebss/yC3V23NkizL6OIS+3wMaBODF8W2Et1Kir54tbBtc/To0Xm/jmUVtd1xW8gIDHGBMkY0j22zWqNuL822GbVgcRIZ+1nUKrXngJRLuw/Fso5WOHESHtt1LfyuV568RmiIfa0ag74talm2dlEqLk7HuUi0ImnPWx+1djyK2u3yrbfidzxqE+O7xPKMWuaYJ/b19vxNWpK7usQxKWq8o2tZ1H7GhbfY7+NiTS3tQ/H7GV0MYlDSuBhY3ofa+8LQou4+ExUnUbYoY7V+hxZXxhAj1Md2EecjF198cR6IMJZlbC/tJfaD2IfinDKWVezHcXFoYa0BZs2alX+T4jyvvWvjq0no7qBiI46Tlqhpjf7RIZocxYltZV/Z8gEkfszj6m57BtnFlbPlvRvj6mKMyhg/IO19YF5UOaOmM8QVvMoThWo04VzS9R7igBc/ivFce45qvKgyRg1XWYy4HCdBEbyiaVd7nzQurJxxMlZe56E8qnGMErvnnntW7R6+SzuKcXn7jBqzytFka2E0/fLyrxyZdWF9a6u9LOPkMbaLaIkRTWTbo5vOkhyPQtTMxUWBaGYY+1F7noQtz7YZfbpjnjiJK9cu1WI5Y1u85ppr8nztcWFgaY7vUcsZx8/2bMG0PMsyyhgXjOLif+WF61o5HpXDTbQIjFZYERLbM3Av7q4ucZEtxm0oH5Oi4iJquM8+++wFRl+v9novX3CJMBm/mdFSJLo+FH3RamnvPhPLLcJhtX6HlqSM5Zrj6OoWXQii5VocH9pz24x+43FhorLZeCy3WLexL0erh8pWARMnTsy/TdF6oD339VogdHdgcbUxNvrYAePWB1HrEbcZWNgJeLXuObmk5Yzbc8TtzapZU7Oky7OalrScERbjB7EaffkXVcaWFyvi5LFafVCXtJxRMxsnG/FDUw3xuVFLFLXwMZhbiCbuS3L7oPa85U00a44f2QgO5ZOF8nKMwYqqPSjR0i7L8sljNU7EFrVtVtYixslXtGgo3w+5HrbNCBhRo9ietXPLug9FM972rJVd0uN77GvR8qEaJ7XLsizjOBAtHMrBsdaORy1b3bXnb1KUMy4+xflPXDyL8U5iG4jWNRFe4iJADEAWFw4qA2Itr/fy8ovlGo/2/B0q/06Xj9cx/k6E2PgNjxYMMVBmNNGPCp44/6hGs+clKWMM8hZlLHdvi2VaHpegvcRnxcWSGGOp3DKkfNvHGCsqKiOilj5q4R/7/y/6xu9TtBypnL9RCN0dXDRzjQN1NPOIA2E9lrPygFetCwOLK2et9UVZ0uVZzdFsl7SM1Vbr5ayXUYzrZTT9pV2WUftVre1hUdtmNQdLW57lWW5tVTmWR62v91r9Xa/GHQmWZVlWIyguy/GoclT69trXl/WuLu19IXB59vX2VA93n6mHMpbLGSP4x/quXJcxcFqs77Fjx+bnYnDPqIUfPXp0qdEJ3Q0grsLHAToGJ4mr8rUUGJa0nLVU1o6wPGvhhLyjLMtqqpdRjOtpNP1aX5YdfduMpqmxPNtzYKrlWe/VWs61uN7rZVkuz/GoPS9k1NtdXWr92FkPd5+phzIuap3H9hitJ+NWgJWiZn7EiBGlRid0N4hyk7S45VK5L1gtUs7GK2c9lLEWy1kvoxjX82j6tbYsF8a22bHLWQ/rvV6WZT0cjxZVznq6q0u9rPdauftMPZRxceVsKbbNKGe00Pj2t79danRCdwOJnTZuiREjWsbtGmqVcjZeOeuhjLVUznoZxbieR9OvtWW5OLbNjlnOeljv9bIs6+F41FHu6lIv671W7j5TD2VcXDljn6m8d3xZXLSKft3/aMexL2qV0N1gYpTiAw88sF0HK1kWytl45ayHMtZKOetlFON6H02/lpblkrBtdrxy1sN6r5dlWQ/Ho45yV5d6We+1cveZeijj0q7zaBIfYyPEWAONNkr5wgjdDag9R4lcHsrZeOWshzLWSjnrYRTjjjCafi0tyyVh2+x45ayH9V4vy7Iejkcd8a4u9bLeq6keyrg05YzR1uN2qtW6FVwtEroB6lQtj2LckUbTr6VlWS/qZXnWSznrQb0sy3o4HnWEu7rUy3qv9qCT9VbGpdk24xZn/J9O8Z8EQF16/vnn0zHHHJO6dOmSTjvttLTTTjvl6XFo79SpU6qHcs6fPz9Pr7Z6WZb1ol6WZ72Usx7Uy7Ksh+PR4soZamWZdoT1XivlrIcy1tO2WUs6V7sAACy7DTfcMI0ZMyb/0H3zm99M999/f03+4C2qnLVyglsvy7Je1MvyrJdy1oN6WZb1cDxaXDlraZl2hPVeK+qhjPW0bdYSoRugzg0YMCB95zvfSd26dUtf//rX00MPPZRqUT2Usx7KWE/qZXnWSznrQb0sS+VsW8rZWGWsp3LWCqEboAOIH79LL700rbvuuqlv376pVtVDOeuhjPWkXpZnvZSzHtTLslTOtqWcjVXGeipnLdCnG6ADmTt3burevXuqdfVQznooYz2pl+VZL+WsB/WyLJWzbSlnY5WxnspZTUI3AAAAFETzcgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAqEmdOnVK48aNq3YxAGC5CN0A0I4OO+ywHCZbPv7xj3+0yfv/+Mc/Tqusskqq9nc84IADqloGAKgVXatdAABoNHvuuWf60Y9+1Gza6quvnmrNe++9l7p161btYgBAXVPTDQDtrEePHmmttdZq9ujSpUt+7vbbb09bbbVV6tmzZ9pggw3Sueeem95///2m144ePToNHjw4rbjiiqlfv37pmGOOSe+8805+bsKECenwww9PM2bMaKpBP+eccxbaVDtqxKNmPPzrX//K89xyyy1p+PDh+fN/+tOf5ud+8IMfpE033TRP22STTdJ3v/vdpfq+H/nIR9Jxxx2XTj755PTBD34wf99yucqee+65tMsuu+TPGDhwYLrrrrsWeJ+pU6emgw8+OJc73mf//ffP5Q7PPPNM6tWrVxo7dmzT/D//+c/TCiuskJ5++umlKi8AtCWhGwBqxH333ZdGjhyZjj/++BwUv/e97+VQfMEFFzTN07lz5/Sd73wnPfXUU+knP/lJuueee3KYDTvssEO64oorUu/evdOrr76aH1//+teXqgynnHJK/vy//e1vaY899sjB+6yzzspliGkXXnhhOvPMM/NnL42YPy4UPPzww+mSSy5J5513XlOwnj9/fvrkJz+Zunfvnp+/9tpr0ze+8Y0Fat2jPB/4wAfycrr//vvTSiutlFsNzJ07N18MuOyyy/JFiClTpqSXXnopHXXUUeniiy/OIR4AqqYEALSbUaNGlbp06VJaccUVmx4HHnhgfu5jH/tY6cILL2w2/4033lhae+21F/p+t956a2m11VZr+vtHP/pRaeWVV15gvvjJv+2225pNi/li/vDCCy/kea644opm82y44YalsWPHNpt2/vnnl4YNG7bI77j//vs3/T18+PDSTjvt1GyebbbZpvSNb3wj//vOO+8sde3atfTyyy83Pf+73/2uWZljOWy88cal+fPnN80zZ86c0gorrJBfX7b33nuXdt5557wsd99992bzA0A16NMNAO3sox/9aLrmmmua/o4a4PDXv/411+BW1mzPmzcvzZ49O7377ru5+fQf/vCHdNFFF+Xm1DNnzsxNzyufX15bb711079nzZqVnn/++XTEEUekI488sml6fObKK6+8VO+7+eabN/t77bXXTtOmTcv/jhr0aCrft2/fpueHDRvWbP5YNjHYXNR0V4rvHmUsu/7669OHP/zh3CIgWgNEk3kAqCahGwDaWYTsjTbaaIHp0Tc7+nBHU+uWoq9z9F/eZ5990tFHH52DefRr/vOf/5xDcTSxXlTojvD5/1V4N2+y3VrZKssTvv/976ftttuu2XzlPuhLquWAbFGeaFa+pKIsQ4cObepnvrBB6CKcx8WCCN3RvD7CPQBUk9ANADUiBlB79tlnWw3k4ZFHHslB9fLLL8+hsjxYWKXoFx21460F0wihlQOXRe34oqy55pq59vmf//xn+uxnP5uKEoO0xSBplSH5oYceWmDZxCBva6yxRu6z3po333wz367s9NNPz+8VZX700UfzYGoAUC0GUgOAGhEDlt1www25tjuaRkez65tvvjmdccYZ+fkI41E7fdVVV+UgfOONN+ZBxyr1798/1wrffffdafr06U3Betddd01jxoxJkydPTpMmTcqDjC3J7cCiLNGcPQZv+/vf/56eeOKJfLuzGEW9rey22265SfioUaNyTXUMlBbBuVIE6D59+uQRy+P5F154IY/WHqOix6BpIb5TNFOP5RXli4sPSzuQHAC0NaEbAGpEjM7929/+Nv3+979P22yzTdp+++3Tt7/97fShD30oP7/FFlvkMBkjcg8aNCg3tY5AXClGMI/wOWLEiFy7HSOFh6gdj0C68847p8985jM5jC5JH/AvfOEL+ZZhEbTjVmVxO7EYUX399ddvs+8dtfa33XZb+u9//5u23Xbb/JmV/dpDlPVPf/pTWm+99XLz+6gdj2b10ac7ar7jYsUdd9yRL0R07do1N5O/6aabctP43/3ud21WVgBYWp1iNLWlfhUAAACwWGq6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAJCK8f8AzdRVkFA2CBgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_indices, top_importances = interpret_svm_features(\n",
    "    svm_model, X_test, y_test, top_k=20, save_path=\"svm_feature_importance.png\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4d80abe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-Only Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.62      0.55      0.58        62\n",
      "          CN       0.61      0.18      0.28        62\n",
      "        LMCI       0.50      0.90      0.64        63\n",
      "\n",
      "    accuracy                           0.55       187\n",
      "   macro avg       0.58      0.54      0.50       187\n",
      "weighted avg       0.58      0.55      0.50       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Step 1: Extract CNN features and labels\n",
    "X_cnn = np.stack(feature_df['features'].values)\n",
    "y_cnn = feature_df['label'].values\n",
    "\n",
    "# Step 2: Train-test split\n",
    "X_train_cnn, X_test_cnn, y_train_cnn, y_test_cnn = train_test_split(\n",
    "    X_cnn, y_cnn, test_size=0.2, stratify=y_cnn, random_state=42\n",
    ")\n",
    "\n",
    "# Step 3: Train SVM\n",
    "svm_cnn = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "svm_cnn.fit(X_train_cnn, y_train_cnn)\n",
    "\n",
    "# Step 4: Predict and evaluate\n",
    "y_pred_cnn = svm_cnn.predict(X_test_cnn)\n",
    "print(\"CNN-Only Classification Report:\")\n",
    "print(classification_report(y_test_cnn, y_pred_cnn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c0549130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-Only Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.62      0.55      0.58        62\n",
      "          CN       0.61      0.18      0.28        62\n",
      "        LMCI       0.50      0.90      0.64        63\n",
      "\n",
      "    accuracy                           0.55       187\n",
      "   macro avg       0.58      0.54      0.50       187\n",
      "weighted avg       0.58      0.55      0.50       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"CNN-Only Classification Report:\")\n",
    "print(classification_report(y_test_cnn, y_pred_cnn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "07418a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT-Only Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.59      0.53      0.56        62\n",
      "          CN       0.80      0.13      0.22        62\n",
      "        LMCI       0.51      0.98      0.67        63\n",
      "\n",
      "    accuracy                           0.55       187\n",
      "   macro avg       0.63      0.55      0.49       187\n",
      "weighted avg       0.63      0.55      0.49       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Step 1: Extract ViT features and labels\n",
    "X_vit = np.stack(vit_feature_df['features'].values)\n",
    "y_vit = vit_feature_df['label'].values\n",
    "\n",
    "# Step 2: Train-test split\n",
    "X_train_vit, X_test_vit, y_train_vit, y_test_vit = train_test_split(\n",
    "    X_vit, y_vit, test_size=0.2, stratify=y_vit, random_state=42\n",
    ")\n",
    "\n",
    "# Step 3: Train SVM\n",
    "svm_vit = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "svm_vit.fit(X_train_vit, y_train_vit)\n",
    "\n",
    "# Step 4: Predict and evaluate\n",
    "y_pred_vit = svm_vit.predict(X_test_vit)\n",
    "print(\"ViT-Only Classification Report:\")\n",
    "print(classification_report(y_test_vit, y_pred_vit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2ac8a02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT-Only Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.59      0.53      0.56        62\n",
      "          CN       0.80      0.13      0.22        62\n",
      "        LMCI       0.51      0.98      0.67        63\n",
      "\n",
      "    accuracy                           0.55       187\n",
      "   macro avg       0.63      0.55      0.49       187\n",
      "weighted avg       0.63      0.55      0.49       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ViT-Only Classification Report:\")\n",
    "print(classification_report(y_test_vit, y_pred_vit))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba15191",
   "metadata": {},
   "source": [
    "Weighted Fusion Based on Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0c65a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_importance(importances, total_dims=512):\n",
    "    weights = np.zeros(total_dims)\n",
    "    for idx, score in zip(top_indices, top_importances):\n",
    "        weights[idx] = score\n",
    "    weights /= np.sum(weights)  # Normalize to sum = 1\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b2f5a6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_weighted_fusion(fused_df, weights):\n",
    "    X = np.stack(fused_df['features'].values)\n",
    "    X_weighted = X * weights  # Element-wise weighting\n",
    "\n",
    "    weighted_df = pd.DataFrame({\n",
    "        'features': list(X_weighted),\n",
    "        'label': fused_df['label'].values,\n",
    "        'subject_id': fused_df['subject_id'].values\n",
    "    })\n",
    "\n",
    "    return weighted_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "64a075c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA explained variance ratio (top 512): 0.9649\n"
     ]
    }
   ],
   "source": [
    "reduced_df = apply_pca(fused_df, n_components=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "95e9a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_weighted_fusion(reduced_df, weights):\n",
    "    X = np.stack(reduced_df['features'].values)\n",
    "    X_weighted = X * weights  # Now shapes match: (933, 512) × (512,)\n",
    "\n",
    "    weighted_df = pd.DataFrame({\n",
    "        'features': list(X_weighted),\n",
    "        'label': reduced_df['label'].values,\n",
    "        'subject_id': reduced_df['subject_id'].values\n",
    "    })\n",
    "\n",
    "    return weighted_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bb9170dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Fusion Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.63      0.50      0.56        62\n",
      "          CN       0.54      0.31      0.39        62\n",
      "        LMCI       0.50      0.83      0.63        63\n",
      "\n",
      "    accuracy                           0.55       187\n",
      "   macro avg       0.56      0.54      0.53       187\n",
      "weighted avg       0.56      0.55      0.53       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights = normalize_importance(top_importances, total_dims=512)\n",
    "weighted_df = apply_weighted_fusion(reduced_df, weights)\n",
    "\n",
    "\n",
    "X = np.stack(weighted_df['features'].values)\n",
    "y = weighted_df['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "svm_weighted = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "svm_weighted.fit(X_train, y_train)\n",
    "y_pred = svm_weighted.predict(X_test)\n",
    "\n",
    "print(\"Weighted Fusion Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645a5c09",
   "metadata": {},
   "source": [
    "Contrastive Alignment of CNN and ViT Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c048741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.1: Split fused features back into CNN and ViT\n",
    "cnn_features = np.stack(fused_df['features'].apply(lambda x: x[:len(x)//2]))\n",
    "vit_features = np.stack(fused_df['features'].apply(lambda x: x[len(x)//2:]))\n",
    "labels = fused_df['label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ec4b6f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.2: Infer dimensions from a sample\n",
    "sample_vector = fused_df['features'].iloc[0]\n",
    "D_total = len(sample_vector)\n",
    "\n",
    "# If CNN and ViT were equal-length:\n",
    "cnn_dim = vit_dim = D_total // 2\n",
    "\n",
    "# Split features\n",
    "cnn_features = np.stack(fused_df['features'].apply(lambda x: x[:cnn_dim]))\n",
    "vit_features = np.stack(fused_df['features'].apply(lambda x: x[cnn_dim:]))\n",
    "labels = fused_df['label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d800acdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN shape: (933, 89216)\n",
      "ViT shape: (933, 89216)\n",
      "Labels shape: (933,)\n"
     ]
    }
   ],
   "source": [
    "print(\"CNN shape:\", cnn_features.shape)\n",
    "print(\"ViT shape:\", vit_features.shape)\n",
    "print(\"Labels shape:\", labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139f71c0",
   "metadata": {},
   "source": [
    "Defining Contrastive Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e4a12269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def contrastive_loss(cnn_embed, vit_embed, labels, margin=0.5):\n",
    "    batch_size = cnn_embed.size(0)\n",
    "    loss = 0.0\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        for j in range(batch_size):\n",
    "            if i == j:\n",
    "                continue\n",
    "            sim = F.cosine_similarity(cnn_embed[i], vit_embed[j], dim=0)\n",
    "            if labels[i] == labels[j]:\n",
    "                loss += (1 - sim)  # pull together\n",
    "            else:\n",
    "                loss += F.relu(sim - margin)  # push apart\n",
    "\n",
    "    return loss / (batch_size * (batch_size - 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2fda1633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.1: Create label mapping\n",
    "label_map = {'AD': 0, 'CN': 1, 'LMCI': 2}\n",
    "labels_encoded = np.array([label_map[label] for label in labels])\n",
    "\n",
    "# Step 2.2: Convert to PyTorch tensor\n",
    "label_tensor = torch.tensor(labels_encoded, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0f0ba6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded labels: [0 1 2]\n",
      "Tensor shape: torch.Size([933])\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoded labels:\", np.unique(labels_encoded))\n",
    "print(\"Tensor shape:\", label_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44145c0b",
   "metadata": {},
   "source": [
    "Building Alignment Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "df8b44a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class AlignmentNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=128):\n",
    "        super().__init__()\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.project(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "67fc01ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_net = AlignmentNet(input_dim=89216, output_dim=128)\n",
    "vit_net = AlignmentNet(input_dim=89216, output_dim=128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d693a9d7",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1d4efe1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch in c:\\users\\admin\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (2.7.1+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\admin\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from jinja2->torch) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d788f144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "cnn_tensor = torch.tensor(cnn_features, dtype=torch.float32)\n",
    "vit_tensor = torch.tensor(vit_features, dtype=torch.float32)\n",
    "\n",
    "# If not already done:\n",
    "label_map = {'AD': 0, 'CN': 1, 'LMCI': 2}\n",
    "labels_encoded = np.array([label_map[label] for label in labels])\n",
    "label_tensor = torch.tensor(labels_encoded, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2597270c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Contrastive Loss: 0.3695\n",
      "Epoch 2/10 - Contrastive Loss: 0.1675\n",
      "Epoch 3/10 - Contrastive Loss: 0.2513\n",
      "Epoch 4/10 - Contrastive Loss: 0.2355\n",
      "Epoch 5/10 - Contrastive Loss: 0.1917\n",
      "Epoch 6/10 - Contrastive Loss: 0.2062\n",
      "Epoch 7/10 - Contrastive Loss: 0.2224\n",
      "Epoch 8/10 - Contrastive Loss: 0.2110\n",
      "Epoch 9/10 - Contrastive Loss: 0.1842\n",
      "Epoch 10/10 - Contrastive Loss: 0.1816\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Step 4.1: Move networks to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cnn_net = cnn_net.to(device)\n",
    "vit_net = vit_net.to(device)\n",
    "\n",
    "# Step 4.2: Prepare data\n",
    "cnn_tensor = cnn_tensor.to(device)\n",
    "vit_tensor = vit_tensor.to(device)\n",
    "label_tensor = label_tensor.to(device)\n",
    "\n",
    "# Step 4.3: Optimizer\n",
    "optimizer = optim.Adam(list(cnn_net.parameters()) + list(vit_net.parameters()), lr=1e-3)\n",
    "\n",
    "# Step 4.4: Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    cnn_embed = cnn_net(cnn_tensor)\n",
    "    vit_embed = vit_net(vit_tensor)\n",
    "\n",
    "    loss = contrastive_loss(cnn_embed, vit_embed, label_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Contrastive Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0c85ecbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: True\n",
      "Device: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"GPU: {torch.cuda.is_available()}\")\n",
    "print(f\"Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
