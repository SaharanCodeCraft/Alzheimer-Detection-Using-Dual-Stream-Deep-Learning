{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d90f4179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\ADMIN\\Documents\\Alz_work\n",
      "Device: cuda\n",
      "K slices per subject: 16\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 1: Imports & Config\n",
    "# =========================\n",
    "\n",
    "import torch\n",
    "import timm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------------------------\n",
    "# Global configuration\n",
    "# -------------------------\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Resolve project root (assuming notebooks/ is one level down)\n",
    "PROJECT_ROOT = Path.cwd().parents[0]\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "\n",
    "K_SLICES = 16  # fixed slices per subject (LOCKED)\n",
    "\n",
    "FEATURES_DIR = Path(\"features/vit\")\n",
    "FEATURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Device:\", DEVICE)\n",
    "print(\"K slices per subject:\", K_SLICES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6bd68ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\ADMIN\\Documents\\Alz_work\n"
     ]
    }
   ],
   "source": [
    "# Resolve project root (assuming notebooks/ is one level down)\n",
    "PROJECT_ROOT = Path.cwd().parents[0]\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99540cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d98b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "list(Path(\".\").glob(\"**/labels.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7c7e53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\Documents\\Alz_work\\Notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1bb7c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "list(Path(\".\").glob(\"**/*.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a20e5f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['subject_id', 'label']\n",
      "Total subjects: 639\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 2: Load labels & subjects\n",
    "# =========================\n",
    "\n",
    "LABELS_PATH = PROJECT_ROOT / \"features\" / \"labels.csv\"\n",
    "\n",
    "\n",
    "labels_df = pd.read_csv(LABELS_PATH)\n",
    "\n",
    "# Expect at least: subject_id, label\n",
    "print(\"Columns:\", labels_df.columns.tolist())\n",
    "\n",
    "subjects = labels_df[\"subject_id\"].astype(str).tolist()\n",
    "\n",
    "print(\"Total subjects:\", len(subjects))\n",
    "\n",
    "# Sanity check\n",
    "assert len(subjects) == 639, \"Subject count mismatch!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89b041a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('c:/Users/ADMIN/Documents/Alz_work/features/labels.csv')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list((PROJECT_ROOT).glob(\"**/labels.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12a61678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Robust deterministic slice sampling\n",
    "# =========================\n",
    "\n",
    "def sample_slices(image_paths, num_slices=16):\n",
    "    \"\"\"\n",
    "    Deterministically sample num_slices images from a list of image paths.\n",
    "    If fewer images are available, repeat the last image.\n",
    "    If no images are available, return an empty list.\n",
    "    \"\"\"\n",
    "    image_paths = sorted(image_paths)\n",
    "\n",
    "    if len(image_paths) == 0:\n",
    "        return []\n",
    "\n",
    "    if len(image_paths) >= num_slices:\n",
    "        indices = np.linspace(\n",
    "            0, len(image_paths) - 1, num_slices\n",
    "        ).astype(int)\n",
    "        return [image_paths[i] for i in indices]\n",
    "    else:\n",
    "        return image_paths + [image_paths[-1]] * (num_slices - len(image_paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b92197cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Cell 4: Image Loading & Preprocessing\n",
    "# =========================\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# ImageNet normalization (LOCKED)\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "preprocess = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),  # converts to [0,1] and (C,H,W)\n",
    "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])\n",
    "\n",
    "def load_and_preprocess_image(img_path):\n",
    "    \"\"\"\n",
    "    Load a single MRI slice and return a ViT-ready tensor (3, 224, 224).\n",
    "    \"\"\"\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img = preprocess(img)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96d2142a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "example_img = load_and_preprocess_image(\n",
    "    sample_slices([p for p in Path(\".\").glob(\"**/*.png\")], num_slices=1)[0]\n",
    ")\n",
    "\n",
    "print(example_img.shape, example_img.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "037c4b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT loaded.\n",
      "ViT output dim: 768\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 5: Load ViT Model\n",
    "# =========================\n",
    "\n",
    "vit = timm.create_model(\n",
    "    \"vit_base_patch16_224\",\n",
    "    pretrained=True,\n",
    "    num_classes=0  # returns CLS embedding\n",
    ")\n",
    "\n",
    "vit = vit.to(DEVICE)\n",
    "vit.eval()\n",
    "\n",
    "# Freeze all parameters (safety)\n",
    "for param in vit.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(\"ViT loaded.\")\n",
    "print(\"ViT output dim:\", vit.num_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35a590b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([WindowsPath('c:/Users/ADMIN/Documents/Alz_work/DATASET/ADNI FULLY PREPROCESSED/002_S_0295/sagittal_slices/sagittal_000.png'),\n",
       "  WindowsPath('c:/Users/ADMIN/Documents/Alz_work/DATASET/ADNI FULLY PREPROCESSED/002_S_0295/sagittal_slices/sagittal_001.png'),\n",
       "  WindowsPath('c:/Users/ADMIN/Documents/Alz_work/DATASET/ADNI FULLY PREPROCESSED/002_S_0295/sagittal_slices/sagittal_002.png'),\n",
       "  WindowsPath('c:/Users/ADMIN/Documents/Alz_work/DATASET/ADNI FULLY PREPROCESSED/002_S_0295/sagittal_slices/sagittal_003.png'),\n",
       "  WindowsPath('c:/Users/ADMIN/Documents/Alz_work/DATASET/ADNI FULLY PREPROCESSED/002_S_0295/sagittal_slices/sagittal_004.png')],\n",
       " 200)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Diagnostic: locate PNG slices for a known subject\n",
    "from pathlib import Path\n",
    "\n",
    "test_subject = \"002_S_0295\"\n",
    "\n",
    "png_matches = list(PROJECT_ROOT.glob(f\"**/{test_subject}/**/*.png\"))\n",
    "png_matches[:5], len(png_matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f3cbb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 639/639 [03:36<00:00,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT feature extraction completed.\n",
      "Subjects processed: 639\n",
      "Subjects skipped (already existed): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 6: ViT Feature Extraction Loop (FINAL)\n",
    "# =========================\n",
    "\n",
    "vit_features_dir = FEATURES_DIR\n",
    "vit_features_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "processed = 0\n",
    "skipped = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _, row in tqdm(labels_df.iterrows(), total=len(labels_df)):\n",
    "        subject_id = str(row[\"subject_id\"])\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # Output path (resume-safe)\n",
    "        # --------------------------------------------------\n",
    "        out_path = vit_features_dir / f\"{subject_id}.npy\"\n",
    "        if out_path.exists():\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # Subject slice directory (CONFIRMED PATH)\n",
    "        # --------------------------------------------------\n",
    "        subject_dir = (\n",
    "            PROJECT_ROOT\n",
    "            / \"DATASET\"\n",
    "            / \"ADNI FULLY PREPROCESSED\"\n",
    "            / subject_id\n",
    "            / \"sagittal_slices\"\n",
    "        )\n",
    "\n",
    "        if not subject_dir.exists():\n",
    "            print(f\"[WARNING] Subject directory missing: {subject_id}\")\n",
    "            continue\n",
    "\n",
    "        slice_paths = sorted(subject_dir.glob(\"*.png\"))\n",
    "\n",
    "        if len(slice_paths) == 0:\n",
    "            print(f\"[WARNING] No slices found for subject {subject_id}\")\n",
    "            continue\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # Deterministic slice sampling (K = 16)\n",
    "        # --------------------------------------------------\n",
    "        sampled_slices = sample_slices(slice_paths, num_slices=K_SLICES)\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # Load & preprocess slices\n",
    "        # --------------------------------------------------\n",
    "        imgs = []\n",
    "        for p in sampled_slices:\n",
    "            try:\n",
    "                img = load_and_preprocess_image(p)\n",
    "                imgs.append(img)\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Failed to load {p}: {e}\")\n",
    "                imgs = []\n",
    "                break\n",
    "\n",
    "        if len(imgs) != K_SLICES:\n",
    "            print(f\"[WARNING] Incomplete slice load for subject {subject_id}\")\n",
    "            continue\n",
    "\n",
    "        imgs = torch.stack(imgs, dim=0).to(DEVICE)  # (K, 3, 224, 224)\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # Forward through frozen ViT\n",
    "        # --------------------------------------------------\n",
    "        feats = vit(imgs)  # (K, 768)\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # Subject-level aggregation (mean pooling)\n",
    "        # --------------------------------------------------\n",
    "        subj_feat = feats.mean(dim=0)  # (768,)\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # Save subject feature\n",
    "        # --------------------------------------------------\n",
    "        np.save(out_path, subj_feat.cpu().numpy())\n",
    "        processed += 1\n",
    "\n",
    "print(f\"ViT feature extraction completed.\")\n",
    "print(f\"Subjects processed: {processed}\")\n",
    "print(f\"Subjects skipped (already existed): {skipped}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1021ca29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ViT feature files: 639\n",
      "002_S_0295.npy (768,)\n",
      "002_S_0413.npy (768,)\n",
      "002_S_0619.npy (768,)\n",
      "ViT feature integrity check PASSED.\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 7: ViT Feature Integrity Checks\n",
    "# =========================\n",
    "\n",
    "vit_feature_files = sorted(FEATURES_DIR.glob(\"*.npy\"))\n",
    "\n",
    "print(\"Total ViT feature files:\", len(vit_feature_files))\n",
    "assert len(vit_feature_files) == 639, \"ViT feature count mismatch!\"\n",
    "\n",
    "# Check shape of a few samples\n",
    "for f in vit_feature_files[:3]:\n",
    "    feat = np.load(f)\n",
    "    print(f.name, feat.shape)\n",
    "    assert feat.shape == (768,), \"Feature shape mismatch!\"\n",
    "\n",
    "print(\"ViT feature integrity check PASSED.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1260ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN subjects: 639\n",
      "ViT subjects: 0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "CNN and ViT subject IDs do NOT match!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNN subjects:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(cnn_ids))\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mViT subjects:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(vit_ids))\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m cnn_ids \u001b[38;5;241m==\u001b[39m vit_ids, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNN and ViT subject IDs do NOT match!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNN–ViT alignment check PASSED.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: CNN and ViT subject IDs do NOT match!"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 8: CNN–ViT Alignment Check\n",
    "# =========================\n",
    "\n",
    "cnn_dir = PROJECT_ROOT / \"features\" / \"cnn\"\n",
    "vit_dir = PROJECT_ROOT / \"features\" / \"vit\"\n",
    "\n",
    "cnn_ids = set(p.stem for p in cnn_dir.glob(\"*.npy\"))\n",
    "vit_ids = set(p.stem for p in vit_dir.glob(\"*.npy\"))\n",
    "\n",
    "print(\"CNN subjects:\", len(cnn_ids))\n",
    "print(\"ViT subjects:\", len(vit_ids))\n",
    "\n",
    "assert cnn_ids == vit_ids, \"CNN and ViT subject IDs do NOT match!\"\n",
    "\n",
    "print(\"CNN–ViT alignment check PASSED.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "363647c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects only in CNN features: 639\n",
      "Subjects only in ViT features: 0\n",
      "\n",
      "Examples only in CNN: ['002_S_0295', '002_S_0413', '002_S_0619', '002_S_0685', '002_S_0729', '002_S_0782', '002_S_0816', '002_S_0938', '002_S_0954', '002_S_1018']\n",
      "Examples only in ViT: []\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Diagnose CNN–ViT mismatch\n",
    "# =========================\n",
    "\n",
    "only_in_cnn = sorted(cnn_ids - vit_ids)\n",
    "only_in_vit = sorted(vit_ids - cnn_ids)\n",
    "\n",
    "print(\"Subjects only in CNN features:\", len(only_in_cnn))\n",
    "print(\"Subjects only in ViT features:\", len(only_in_vit))\n",
    "\n",
    "print(\"\\nExamples only in CNN:\", only_in_cnn[:10])\n",
    "print(\"Examples only in ViT:\", only_in_vit[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad7b7fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('c:/Users/ADMIN/Documents/Alz_work/features/cnn/002_S_0295.npy'),\n",
       " WindowsPath('c:/Users/ADMIN/Documents/Alz_work/features/cnn/002_S_0413.npy'),\n",
       " WindowsPath('c:/Users/ADMIN/Documents/Alz_work/features/cnn/002_S_0619.npy'),\n",
       " WindowsPath('c:/Users/ADMIN/Documents/Alz_work/features/cnn/002_S_0685.npy'),\n",
       " WindowsPath('c:/Users/ADMIN/Documents/Alz_work/features/cnn/002_S_0729.npy'),\n",
       " WindowsPath('c:/Users/ADMIN/Documents/Alz_work/features/cnn/002_S_0782.npy'),\n",
       " WindowsPath('c:/Users/ADMIN/Documents/Alz_work/features/cnn/002_S_0816.npy'),\n",
       " WindowsPath('c:/Users/ADMIN/Documents/Alz_work/features/cnn/002_S_0938.npy'),\n",
       " WindowsPath('c:/Users/ADMIN/Documents/Alz_work/features/cnn/002_S_0954.npy'),\n",
       " WindowsPath('c:/Users/ADMIN/Documents/Alz_work/features/cnn/002_S_1018.npy'),\n",
       " WindowsPath('c:/Users/ADMIN/Documents/Alz_work/features/cnn/002_S_1070.npy'),\n",
       " WindowsPath('c:/Users/ADMIN/Documents/Alz_work/features/cnn/002_S_1155.npy'),\n",
       " WindowsPath('c:/Users/ADMIN/Documents/Alz_work/features/cnn/002_S_1261.npy'),\n",
       " WindowsPath('c:/Users/ADMIN/Documents/Alz_work/features/cnn/002_S_1268.npy'),\n",
       " WindowsPath('c:/Users/ADMIN/Documents/Alz_work/features/cnn/002_S_1280.npy'),\n",
       " WindowsPath('c:/Users/ADMIN/Documents/Alz_work/features/cnn/003_S_0907.npy'),\n",
       " WindowsPath('c:/Users/ADMIN/Documents/Alz_work/features/cnn/003_S_0908.npy'),\n",
       " WindowsPath('c:/Users/ADMIN/Documents/Alz_work/features/cnn/003_S_0981.npy'),\n",
       " WindowsPath('c:/Users/ADMIN/Documents/Alz_work/features/cnn/003_S_1057.npy'),\n",
       " WindowsPath('c:/Users/ADMIN/Documents/Alz_work/features/cnn/003_S_1122.npy')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Locate actual CNN feature files\n",
    "from pathlib import Path\n",
    "\n",
    "list((PROJECT_ROOT / \"features\").glob(\"**/*.npy\"))[:20]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
